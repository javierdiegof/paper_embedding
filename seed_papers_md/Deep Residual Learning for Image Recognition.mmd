![](_page_0_Picture_0.jpeg)

# **Propuesta metodológica para el procesamiento de señales y videos aplicada a la detección y caracterización de la multiplicidad de descargas eléctricas atmosféricas**

**Diego Hernando Orozco Gómez**

Universidad Nacional de Colombia Facultad de Minas, Departamento de Energía Eléctrica y Automática Medellín, Colombia

# **Propuesta metodológica para el procesamiento de señales y videos aplicada a la detección y caracterización de la multiplicidad de descargas eléctricas atmosféricas**

### **Diego Hernando Orozco Gómez**

Tesis presentada como requisito parcial para optar al título de: **Magister en Ingeniería – Automatización Industrial**

Director:

Freddy Bolaños Martínez Ph.D. en Ingeniería Electrónica Codirector: Javier Gustavo Herrera Murcia Ph.D. en Ingeniería Eléctrica

Línea de Investigación: Procesamiento de Señales Visión Artificial Grupo de Investigación: GAUNAL

Universidad Nacional de Colombia Facultad de Minas, Departamento de Energía Eléctrica y Automática Medellín, Colombia 2022

![](_page_4_Picture_0.jpeg)

## **Declaración de obra original**

Yo declaro lo siguiente:

He leído el Acuerdo 035 de 2003 del Consejo Académico de la Universidad Nacional. «Reglamento sobre propiedad intelectual» y la Normatividad Nacional relacionada al respeto de los derechos de autor. Esta disertación representa mi trabajo original, excepto donde he reconocido las ideas, las palabras, o materiales de otros autores.

Cuando se han presentado ideas o palabras de otros autores en esta disertación, he realizado su respectivo reconocimiento aplicando correctamente los esquemas de citas y referencias bibliográficas en el estilo requerido.

He obtenido el permiso del autor o editor para incluir cualquier material con derechos de autor (por ejemplo, tablas, figuras, instrumentos de encuesta o grandes porciones de texto).

Por último, he sometido esta disertación a la herramienta de integridad académica, definida por la universidad.

Diego Hernando Orozco Gómez

21/10/2021

## **Agradecimientos**

Al director de la tesis profesor Ph.D. Freddy Bolaños Martínez por la motivación brindada, paciencia, dedicación, compromiso, profesionalismo y el suministrar aportes esenciales y asertivos a lo largo de todo este proceso.

Al codirector de la tesis profesor Ph.D. Javier Gustavo Herrera Murcia por la entereza y profesionalismo evidenciados en la realización de este proyecto y por los conocimientos provistos en la temática de descargas eléctricas atmosféricas.

Al profesor Ph.D. Albeiro Espinosa Bedoya por los consejos brindados en el área de procesamiento de imágenes los cuales fueron fundamentales en el desarrollo de este proyecto.

A todas aquellas personas que de una u otra forma aportaron emocional e intelectualmente en la consecución de este trabajo investigativo.

## <span id="page-8-0"></span>**Resumen**

### **Propuesta metodológica para el procesamiento de señales y videos aplicada a la detección y caracterización de la multiplicidad de descargas eléctricas atmosféricas**

Actualmente diversas investigaciones se han enfocado en analizar a partir de videos de alta velocidad, características de las descargas eléctricas atmosféricas con el fin de adquirir mejor comprensión del fenómeno, que conlleva entre otros aspectos el desarrollo de sistemas de protección robustos. La mayoría de las investigaciones han requerido de un observador que ante el suceso del evento provea un disparo manual a la cámara permitiendo almacenar la información visual del fenómeno. Por tanto, este trabajo se orientó en proponer una metodología para la detección de las descargas utilizando dos implementaciones basadas en procesamiento de señales y visión computacional, con el propósito que el sistema autónomamente sea el que suministre el disparo, apartando al observador de la realización de esta tarea. El sistema de detección basado en técnicas de procesamiento de imágenes requirió la adecuación de métodos de segmentación, representación, descripción y clasificación. El algoritmo de reconocimiento con visión computacional se implementó mediante la red neuronal convolucional EfficientNetB4. Fuera de línea, las técnicas basadas en procesamiento de imágenes suministraron una precisión del 81.81%, mientras que haciendo uso de visión computacional la precisión fue de 71.63%. Con el objeto de evaluar el desempeño en tiempo real, las técnicas de procesamiento se adaptaron en un ordenador de placa reducida correspondiente a la Raspberry Pi 3 modelo B+ obteniéndose una precisión de 86.95%. Adicionalmente, se evaluó la característica de multiplicidad la cual corresponde al número de descargas subsecuentes presentes en el canal de la descarga logrando una precisión de 66.66%.

**Palabras clave: descarga eléctrica atmosférica, descriptor, detección, multiplicidad, procesamiento imágenes, red neuronal convolucional, segmentación**

## **Abstract**

### **Methodological proposal for the signals and video processing applied to detection and multiplicity characterization of lightning**

Currently, several researches have conducted in processing high speed videos, in order to analyze lightning features and acquire a better phenomenon comprehension, which might lead to development of more robust protection systems. Most of the investigations have required a human observer, who, in the occurrence of the event, provides a manual trigger to the camera allowing the visual information of the phenomenon to be stored. Therefore, this work was aimed at proposing a methodology for the lightning detection using two implementations based on signal processing and computer vision, with the purpose that the system autonomously provides the trigger, avoiding the need of a human observer for performing this task. The detection system based on image processing techniques required the adaptation of segmentation, representation, description and classification methods. The computer vision recognition algorithm was implemented using the EfficientNetB4 convolutional neural network. Off-line, the techniques based on image processing provided an accuracy of 81.81%, using computer vision the accuracy was 71.63%. In order to evaluate the performance in real time, the processing techniques were adapted in a single-board computer corresponding to the Raspberry Pi 3 model B+, obtaining an accuracy of 86.95%. Additionally, the lightning multiplicity that refers to the number of strokes in a flash was evaluated, achieving an accuracy of 66.66%.

**Keywords: convolutional neural network, descriptor, detection, image processing, lightning, multiplicity, segmentation**

Contenido XI

## **Contenido**

| Pág.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |    |
|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----|
| Resumen                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | IX |
| Lista de figuras<br>XIII                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |    |
| Lista de tablas<br>XVII                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |    |
| Introducción<br>1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |    |
| 1.<br>Antecedentes<br>7<br>1.1<br>Conceptos relacionados a descargas eléctricas atmosféricas7<br>1.2<br>Estado del arte9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |    |
| 2.<br>Propuesta metodológica en la detección de descargas eléctricas atmosféricas<br>23                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |    |
| 2.1<br>Características de imágenes de descargas eléctricas atmosféricas23<br>2.1.1<br>Niveles de intensidad en imágenes de descargas<br>23<br>2.1.2<br>Análisis del espacio de color en imágenes de descargas<br>26<br>2.1.3<br>Morfología de las descargas31<br>2.2<br>Identificación de descargas utilizando técnicas de procesamiento de imágenes32<br>2.2.1<br>Preprocesamiento de imágenes de descargas<br>33<br>2.2.2<br>Segmentación en imágenes de descargas<br>35<br>2.2.3<br>Representación y descripción de imágenes de descargas60<br>2.2.4<br>Detección de la descarga<br>67<br>2.3<br>Identificación de descargas utilizando visión computacional<br>68                                                    |    |
| 3.<br>Propuesta metodológica en la caracterización de la multiplicidad77                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |    |
| 4.<br>Implementación en tiempo real de la solución propuesta para la detección de<br>descargas eléctricas atmosféricas<br>83<br>4.1<br>Características de los equipos<br>84<br>4.1.1<br>Plataforma de procesamiento<br>85<br>4.1.2<br>Cámara de video en el proceso de detección<br>86<br>4.1.3<br>Cámara de video de alta velocidad87<br>4.2<br>Detección en tiempo real de descargas utilizando técnicas de procesamiento de<br>imágenes y computadora personal<br>87<br>4.3<br>Detección en tiempo real de descargas utilizando visión artificial y computadora<br>personal90<br>4.4<br>Detección en tiempo real de descargas utilizando técnicas de procesamiento de<br>imágenes y ordenador de placa reducida<br>93 |    |
| 5.<br>Conclusiones y recomendaciones<br>99                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |    |

| 5.1<br>5.2 | Conclusiones<br>Recomendaciones                                                                | 99<br>102 |
|------------|------------------------------------------------------------------------------------------------|-----------|
| A.         | Anexo: Histogramas de imágenes en escala de grises correspondientes a videos<br>de descargas   | 105       |
| B.         | Anexo: Conversión a espacios de color de imágenes asociadas a videos de<br>descargas           | 109       |
| C.         | Anexo: Histogramas de imágenes en componentes de color seleccionados en<br>videos de descargas | 113       |
| D.         | Anexo: Histogramas de imágenes en canal de color en escala de grises y<br>componente Z<br>     | 117       |
|            | Bibliografía<br>                                                                               | 121       |

<span id="page-12-0"></span>Lista de figuras XIII

## **Lista de figuras**

|                           | Pág.                                                                                      |
|---------------------------|-------------------------------------------------------------------------------------------|
| Figura 1-1:               | Tipos de descargas<br><br>7                                                               |
| Figura 1-2:               | Descargas nube –<br>nube<br>7                                                             |
| Figura 1-3:               | Procesos asociados al desarrollo de una descarga negativa nube –<br>tierra                |
|                           | <br>8                                                                                     |
| Figura 1-4:               | Descarga bipolar<br><br>9                                                                 |
| Figura 2-1:               | Descarga eléctrica atmosférica en el espacio de color RGB y valores de                    |
| intensidad<br>Figura 2-2: | <br>24<br>Descarga eléctrica atmosférica en escala de grises y valores de                 |
| intensidad                | <br>25                                                                                    |
| Figura 2-3:               | Histogramas de imágenes en escala de grises de un video de descarga<br><br><br>25         |
| Figura 2-4:               | Diagrama de bloques correspondiente al proceso de selección de los                        |
| canales                   | de color<br>27                                                                            |
| Figura 2-5:               | Conversión a espacios de color de imagen asociada a video de descarga<br><br>27           |
| Figura 2-6:               | Histograma de imágenes en componentes de color seleccionados en                           |
|                           | video de descarga<br>29                                                                   |
| Figura 2-7:               | Histograma de imágenes en escala de grises y en el componente de                          |
|                           | color Z en Video-6<br>31                                                                  |
| Figura 2-8:               | Resultado de la detección<br>de bordes en imagen de descarga eléctrica                    |
| atmosférica               | <br>32                                                                                    |
| Figura 2-9:               | Diagrama de bloques de la propuesta metodológica para la detección de                     |
|                           | descargas eléctricas atmosféricas<br>33                                                   |
| Figura 2-10:              | Diagrama de flujo del preprocesamiento de imágenes de descargas<br><br>34                 |
| Figura 2-11:              | Diagrama de flujo de segmentación a partir de la variación de niveles de                  |
|                           | intensidad evaluados en la diferencia de cuadros consecutivos<br><br>37                   |
| Figura 2-12:              | Resultado de segmentación a partir de la variación de niveles de                          |
|                           | intensidad evaluados en la diferencia de cuadros consecutivos realizada al video 26<br>38 |
| Figura 2-13:              | Resultado de segmentación a partir de la variación de niveles de                          |
|                           | intensidad evaluados en la diferencia de cuadros consecutivos realizada al video 33<br>38 |
| Figura 2-14:              | Resultado de segmentación a partir de la variación de niveles de                          |
|                           | intensidad evaluados en la diferencia de cuadros consecutivos realizada al video 62<br>38 |
| Figura 2-15:              | Diagrama de flujo de segmentación en cuadros con fondo de diferente                       |
| intensidad                | <br>39                                                                                    |

| Figura 2-16:           | Diagrama de flujo de segmentación en cuadros con fondo de baja                                            |
|------------------------|-----------------------------------------------------------------------------------------------------------|
| intensidad             | 40                                                                                                        |
| Figura 2-17:           | Resultado de segmentación en cuadros con fondo de baja intensidad                                         |
| realizado al video 110 | 41                                                                                                        |
| Figura 2-18:           | Diagrama de flujo de segmentación a partir de la umbralización de la                                      |
|                        | diferencia de cuadros en canal de color Z42                                                               |
| Figura 2-19:           | Resultado de segmentación a partir de la umbralización de la diferencia                                   |
|                        | de cuadros en canal de color Z realizado al video 10843                                                   |
| Figura 2-20:           | Diagrama de flujo de segmentación a partir de la umbralización de la                                      |
|                        | diferencia de cuadros en canal de color gris<br>43                                                        |
| Figura 2-21:           | Resultado de segmentación a partir de la umbralización de la diferencia                                   |
|                        | de cuadros en canal de color gris realizado al video 72<br>44                                             |
| Figura 2-22:           | Diagrama de flujo de segmentación a partir de la umbralización del                                        |
|                        | cuadro actual en canal de color Z<br>44                                                                   |
| Figura 2-23:           | Resultado de segmentación a partir de la umbralización del cuadro actual                                  |
|                        | en canal de color Z realizado al video 18<br>45                                                           |
| Figura 2-24:           | Diagrama de flujo de segmentación en cuadros con fondo de media                                           |
| intensidad             | 46                                                                                                        |
| Figura 2-25:           | Resultado de segmentación en cuadros con fondo de media intensidad                                        |
| realizado al video 60  | 47                                                                                                        |
| Figura 2-26:           | Resultado de segmentación en cuadros con fondo de media intensidad                                        |
|                        | realizado a los videos 47 y 6248                                                                          |
| Figura 2-27:           | Diagrama de flujo de segmentación en cuadros con fondo de alta                                            |
| intensidad             | 49                                                                                                        |
| Figura 2-28:           | Resultado de segmentación en cuadros con fondo de alta intensidad                                         |
|                        | realizado a los videos 112 y 113<br>50                                                                    |
| Figura 2-29:           | Diagrama de flujo de segmentación a partir de la variación de niveles de                                  |
|                        | intensidad evaluados con operaciones aritméticas<br>51                                                    |
| Figura 2-30:           | Diagrama de flujo de segmentación del cuadro actual en canal de color Z                                   |
|                        | 51                                                                                                        |
| Figura 2-31:           | Diagrama de flujo de segmentación a partir de la diferencia de cuadros en                                 |
| canal de color Z       | 52                                                                                                        |
| Figura 2-32:           | Diagrama de flujo de segmentación a partir de la diferencia de cuadros en                                 |
|                        | canal de color gris52                                                                                     |
| Figura 2-33:           | Diagrama de flujo de segmentación a partir de operación AND entre                                         |
|                        | cuadros en canal de color Z y gris53                                                                      |
| Figura 2-34:           | Diagrama de flujo de segmentación a partir de la diferencia de                                            |
| Figura 2-35:           | histogramas en canal de color Z<br>54<br>Resultado de segmentación a partir de la variación de niveles de |
|                        | intensidad evaluados con operaciones aritméticas realizada al video 4<br>54                               |
| Figura 2-36:           | Resultado de segmentación a partir de la variación de niveles de                                          |
|                        | intensidad evaluados con operaciones aritméticas realizada al video 81<br>55                              |
| Figura 2-37:           | Resultado de segmentación a partir de la variación de niveles de                                          |
|                        | intensidad evaluados con operaciones aritméticas realizada al video 20<br>55                              |
|                        |                                                                                                           |

Lista de figuras XV

| Figura 4-11: | Ejemplos | de | objetos | negativos | detectados                                                                      | en | tiempo | real | como |
|--------------|----------|----|---------|-----------|---------------------------------------------------------------------------------|----|--------|------|------|
|              |          |    |         |           | descargas utilizando técnicas de procesamiento de imágenes y ordenador de placa |    |        |      |      |
| reducida     |          |    |         |           | 95                                                                              |    |        |      |      |

<span id="page-16-0"></span>Lista de tablas XVII

## **Lista de tablas**

|                     | Pág.                                                                                    |
|---------------------|-----------------------------------------------------------------------------------------|
| Tabla 1-1:          | Revisión de literatura relacionada al uso de imágenes y videos en la                    |
|                     | caracterización de descargas eléctricas atmosféricas<br><br>10                          |
| Tabla 2-1:          | Canales de color utilizados en el análisis de imágenes de descargas                     |
|                     | eléctricas atmosféricas<br>28                                                           |
| Tabla 2-2:          | Etiquetas utilizadas en los histogramas mostrados en la Figura 2-6<br>30                |
| Tabla 2-3:          | Sintonización realizada a la técnica de sustracción de fondo aplicada en                |
| videos de descargas | <br>58                                                                                  |
| Tabla 2-4:          | Valores mínimo<br>y<br>máximo<br>de<br>descriptores aplicados<br>en<br>descargas        |
|                     | eléctricas atmosféricas<br>63                                                           |
| Tabla 2-5:          | Resultado de la máquina de vectores de soporte<br>66                                    |
| Tabla 2-6:          | Resultado en la detección de la<br>descarga de acuerdo a la técnica utilizada<br><br>68 |
| Tabla 2-7:          | Sintonización<br>de<br>los<br>parámetros<br>de<br>modelos<br>de<br>redes<br>neuronales  |
|                     | convolucionales seleccionados y evaluación de éstos en el proceso de clasificación de   |
|                     | las descargas en el video 8<br><br>71                                                   |
| Tabla 2-8:          | Resultado del modelo EfficientNetB4<br><br>73                                           |
| Tabla 2-9:          | Resultado en el reconocimiento de la descarga utilizando la red neuronal                |
| EfficientNetB4      | <br>76                                                                                  |
| Tabla 2-10:         | Resultado en el reconocimiento de la descarga en videos propios                         |
|                     | utilizando la red neuronal EfficientNetB4<br><br>76                                     |
| Tabla 3-1:          | Resultados obtenidos en el proceso de caracterización de la multiplicidad82             |
| Tabla 4-1:          | Resultado en la detección en tiempo real de descargas utilizando técnicas               |
|                     | de procesamiento de imágenes y computadora personal<br>90                               |
| Tabla 4-2:          | Tiempo de cómputo en la detección en tiempo real de descargas utilizando                |
|                     | técnicas de procesamiento de imágenes y computadora personal<br>90                      |
| Tabla 4-3:          | Resultado en la detección en tiempo real de descargas utilizando visión                 |
|                     | artificial y computadora personal<br><br>92                                             |
| Tabla 4-4:          | Tiempo de cómputo en la detección en tiempo real de descargas utilizando                |
|                     | visión artificial y computadora personal<br><br>92                                      |
| Tabla 4-5:          | Resultado en la detección en tiempo real de descargas utilizando técnicas               |
|                     | de procesamiento de imágenes y ordenador de placa reducida<br><br>96                    |
| Tabla 4-6:          | Tiempo de cómputo en la detección en tiempo real de descargas utilizando                |
|                     | técnicas de procesamiento de imágenes y ordenador de placa reducida<br><br>97           |

<span id="page-18-0"></span>De acuerdo a lo definido en la literatura, la descarga eléctrica atmosférica es un evento transitorio de alta corriente con trayectoria longitudinal medida en kilómetros [1]. Debido a sus características eléctricas y a la elevada frecuencia en la que acontece el evento causan diversas clases de daños materiales en estructuras, dispositivos electrónicos y sistemas de información tecnológica generando pérdidas económicas considerables y en algunos casos contaminación al medio ambiente [2]–[4]. Adicionalmente, ponen en riesgo la vida de animales y personas [5]–[7], frecuentemente ocasionan desastres naturales [3], [8], y provocan grandes incendios en áreas forestales, residenciales e industriales [2]. Por consiguiente, tener conocimiento respecto a la detección de las descargas y a las características relacionadas a estos fenómenos naturales suscita un elevado interés en muchas industrias como las relacionadas a la medición y predicción del clima, energía eléctrica, telecomunicaciones, aeroespacial, aviación, petrolera y química; en consecuencia, se pondera la importancia de diseñar sistemas de protección de alta seguridad [2]–[5], [8]–[10].

Actualmente, las redes de localización de descargas suministran el método más preciso para determinar su ubicación a partir de la configuración de varias antenas. Estas redes utilizan varios tipos de técnicas las cuales tienen la capacidad de medir los diferentes fenómenos electromagnéticos asociados a las descargas [11]–[16]. Entre estas técnicas se encuentran: detección de dirección magnética (MDF, Magnetic Direction Finder), tiempo de arribo (TAO, Time of Arrival), interferometría (RFI, Radio Frequency Interferometer), mediciones de intensidad de campo (FSM, Field Strength Measurements) y mediciones de intensidad de radiofrecuencia (RF, Radio Frecuency Signal Strength Measurements). El desempeño de las redes se determina a partir de dos parámetros que se conocen como la exactitud en la localización y la eficiencia en la detección [17]. El primer parámetro se refiere al error estadístico de distancia en la localización de una gran cantidad de impactos de descargas y el segundo al porcentaje de impactos de las descargas localizadas. Estos parámetros están fuertemente

influenciados por la sensibilidad de las antenas, la ubicación y las distancias relativas respecto a las características geográficas del área bajo estudio. El resultado provee parámetros de desempeño de la red que distan mucho de ser ideales.

Por consiguiente, las redes de localización no siempre proveen información respecto a la detección y en algunos casos no son lo suficientemente adecuadas para analizar con mayor detalle diversos parámetros [11]–[13]. Adicionar mejoras en los procesos tecnológicos de medición, información y comunicaciones, permitirá desarrollar sistemas robustos que notifiquen la presencia de descargas y suministren información relacionada a características referentes a estos fenómenos naturales. Entre estas mejoras se pueden incluir sistemas equipados con cámaras fotográficas que proporcionen imágenes y videos de las descargas. El análisis fotográfico de las descargas se perfila como un método de obtención visual confiable de puntos de impacto en pequeñas áreas geográficas proporcionando una mejora respecto al conocimiento de la actividad de las descargas y adicionalmente suministra información con el objeto de caracterizar algunos parámetros de estos eventos [11], [12], [23]–[27], [13]–[15], [18]–[22]. La luminosidad observada en el canal de descarga en una imagen o video permite ser asociada con valores de corriente continua [24], [28]. Adicionalmente, correlacionar la información de las redes de localización de descargas con la información adquirida visualmente permite validar y evaluar la calidad y la eficiencia en la detección por parte de las redes [24]. Por tal motivo, el utilizar imágenes y videos de descargas permite caracterizar la actividad de estos fenómenos naturales en pequeñas áreas geográficas con altos niveles de confiabilidad.

A partir de lo anteriormente expuesto, este trabajo tiene como objetivo general proponer una metodología para la detección y caracterización de la multiplicidad de descargas eléctricas atmosféricas utilizando técnicas de procesamiento de señales y algoritmos de visión computacional.

Para lograr tal fin, se establecen los siguientes objetivos específicos:

• Identificar por medio de videos el canal de descarga empleando técnicas de procesamiento de señales y visión computacional.

• Caracterizar los picos de luminosidad en el canal de descarga con el objeto de establecer la multiplicidad.

• Evaluar el desempeño funcional de la metodología propuesta en la detección y caracterización de la multiplicidad de descargas.

El desarrollo del proyecto presentado empleó dos procesos metodológicos: la metodología experimental, y la metodología análisis - síntesis. La metodología experimental se utilizó con el objeto de adecuar a nivel de hardware los sistemas físicos que permitieron tanto adquirir y almacenar la información visual de las descargas, como aquellos enfocados en la realización de pruebas y validación de la eficiencia del proceso de detección de descargas propuesto. A nivel de software esta metodología permitió establecer las técnicas de procesamiento de señales y los algoritmos de visión computacional en los procesos de detección y caracterización de la multiplicidad de las descargas. La metodología análisis - síntesis se aplicó en el estudio funcional de cada uno de los procesos que componen el proyecto: grabación y almacenamiento del video del canal con registro en tiempo real, detección del canal de descarga y obtención de la multiplicidad.

Respecto a la detección del canal de descarga se buscó implementar algoritmos de procesamiento de bajo coste computacional con el fin de obtener un desfase temporal entre el suceso del evento y su detección que probablemente ofreciera la menor pérdida posible en la información visual a analizar. Como punto de partida para el desarrollo de este proceso se utilizaron técnicas de procesamiento que aunque no han sido aplicadas en la detección de la descarga si se han implementado en el proceso de aislarla de la imagen [28]. Inicialmente se utilizaron grabaciones de videos con descargas para evaluar el algoritmo de detección. Posteriormente el algoritmo se adaptó en el proceso de adquisición visual con el objeto de evaluar su eficiencia funcional en tiempo real.

El proceso de detección del canal sirve como elemento de disparo para la grabación del video en una cámara de alta velocidad. Con el objeto de asegurar que no existan pérdidas en el proceso de adquisición de información visual la grabación de los videos se debe realizar utilizando un buffer circular. El registro en tiempo real de los videos

adquiridos se lleva a cabo utilizando la marca temporal suministrada por la cámara de video de alta velocidad.

Si bien, a partir del análisis visual de las descargas es posible obtener el tiempo de duración de la corriente en la etapa inicial, el intervalo de tiempo entre descargas subsecuentes, la velocidad promedio de propagación, el tiempo que perduran las corrientes en descargas subsecuentes, el intervalo de tiempo entre descargas, el tiempo total de una descarga, el número de impactos a tierra de las descargas, así como otros parámetros, el proyecto únicamente se enfocó en determinar el número de descargas subsecuentes presentes en el evento.

De acuerdo a [20] la cámara a utilizar para el proceso de adquisición visual debe permitir ser ajustada a una tasa de muestreo igual o superior a 1000 cuadros (fotogramas) por segundo con el objeto de minimizar la probabilidad de pérdidas de descargas subsecuentes presentadas entre intervalos de descargas subsecuentes muy cortos. Por tanto, se hizo uso de videos adquiridos con una cámara que cumplió con esta especificación de forma que fue posible caracterizar la multiplicidad. Respecto a la resolución espacial de los videos no es un aspecto crítico el hecho que ésta no esté sintonizada con el objeto de proveer detalles finos en la imagen de acuerdo a las afirmaciones expresadas por los autores en [19], [20], [22].

Los avances expuestos en este trabajo en relación a técnicas de detección de la descarga utilizando información visual podrían servir a futuro como herramienta de validación y evaluación de la calidad y la eficiencia en la detección por parte de las redes. De acuerdo a lo anterior, se debe dar claridad respecto a que el presente proyecto no tuvo por objeto ubicar geográficamente el impacto de la descarga, así como tampoco ser adecuado en redes de localización de descargas como parte de un sistema de detección.

El presente documento abarca las siguientes secciones: en el Capítulo 1 se presenta teoría relacionada a las descargas y el estado del arte respectivo, el Capítulo 2 documenta las técnicas propuestas en la detección visual de la descarga, el Capítulo 3 detalla el procedimiento propuesto con el objeto de caracterizar la multiplicidad. Las pruebas de verificación del desempeño de las técnicas de detección en tiempo real se

exponen en el Capítulo 4. Finalmente, el Capítulo 5 provee las conclusiones y recomendaciones derivadas de este trabajo investigativo.

## <span id="page-24-0"></span>**1.Antecedentes**

### <span id="page-24-1"></span>**1.1 Conceptos relacionados a descargas eléctricas atmosféricas**

De acuerdo con [29] las descargas eléctricas atmosféricas pueden ser categorizadas según el líder que inicia la descarga en términos de su dirección, ascendente o descendente, y en términos de la polaridad de la carga, positivas o negativas. Así, se tienen cuatro tipos de descargas: descarga negativa nube – tierra, descarga positiva nube – tierra, descarga positiva tierra – nube, descarga negativa tierra – nube. La Figura 1-1 muestra estos cuatro tipos de descargas. Además, autores como [30] han descrito descargas nube – nube, la cual se indica en la figura 1-2.

<span id="page-24-2"></span>**Figura 1-1:** Tipos de descargas

![](_page_24_Picture_4.jpeg)

Fuente: imagen adaptada de [31]

<span id="page-24-3"></span>**Figura 1-2:** Descargas nube – nube

![](_page_24_Picture_7.jpeg)

Fuente: imagen adaptada de [32]

Dentro de las teorías más aceptadas en la actualidad, para que una descarga inicie se debe tener una nube cargada a partir del choque entre una corriente de aire cálido y una corriente de aire frío. Durante este choque se producen corrientes verticales ascendentes y descendentes que tienen la capacidad de separar los electrones en las moléculas de aire. Éstas cargas libres se alojan en las gotitas de agua o de granizo de la nube produciéndo así una separación efectiva de cargas [33].

Tomando el caso del proceso relacionado a una descarga negativa nube – tierra como la indicada en la Figura 1-3, inicialmente (t = 0) se genera en la nube una disrupción preliminar que provoca la formación del líder escalonado correspondiente a un canal ionizado negativamente que avanza a pasos hacia el terreno, el cual una vez cercano a la tierra induce cargas de polaridad positiva en los elementos que se encuentran conectados al terreno. Una vez avanza, en el último paso se origina un proceso de enlace ocasionando el impacto de la descarga y que da lugar a la primera descarga de retorno.

<span id="page-25-0"></span>**Figura 1-3:** Procesos asociados al desarrollo de una descarga negativa nube – tierra

Fuente: imagen adaptada de [34]

Antecedentes 9

Si existen cargas en la nube pueden presentarse una o más descargas de retorno subsecuentes que se desarrollan en la mayoría de los casos sobre la misma trayectoria del canal ionizado creado por la primera descarga de retorno. Usualmente tanto las descargas de retorno como las subsecuentes no exhiben ramificaciones [1].

Otros autores [12], [13] han detallado descargas bipolares. El término bipolar hace referencia a que la corriente que se establece después del líder tiene dos polaridades [35]. La Figura 1-4 detalla la formación de una descarga bipolar correspondiente a una secuencia de dos descargas tierra – nube separadas por un tiempo en el orden de los milisegundos.

<span id="page-26-1"></span>**Figura 1-4:** Descarga bipolar

![](_page_26_Picture_4.jpeg)

<span id="page-26-0"></span>Fuente: imagen extraída de [36]

### **1.2 Estado del arte**

Inicialmente, la revisión de la literatura se centró en la búsqueda de trabajos que utilizaron técnicas de procesamiento de imágenes y visión computacional aplicadas en la detección de las descargas eléctricas atmosféricas. Debido a que la investigación realizada no suministró amplia información al respecto, la búsqueda además se enfocó en determinar la utilidad de emplear imágenes y videos con el objeto de analizar características de estos fenómenos naturales. La Tabla 1-1 resume los trabajos orientados en el último aspecto mencionado.

Tal como se observa en la Tabla 1-1 y como lo indica la investigación [11] el uso de cámaras de video de alta velocidad suministra información visual que permite llevar a cabo con un alto grado de detalle el análisis y la caracterización de las descargas eléctricas atmosféricas. De esta forma se obtiene:

• Confirmación de polaridades sobre un mismo canal de descarga [11]–[14], [37].

<span id="page-27-0"></span>**Tabla 1-1**: Revisión de literatura relacionada al uso de imágenes y videos en la caracterización de descargas eléctricas atmosféricas

| Categoría<br>de la                   | Ref. | Características<br>de las cámaras |                   | CE | CM | Uso<br>de | Características de las descargas<br>analizando los vídeos |                            |                          |                                    |               |
|--------------------------------------|------|-----------------------------------|-------------------|----|----|-----------|-----------------------------------------------------------|----------------------------|--------------------------|------------------------------------|---------------|
| descarga<br>eléctrica<br>atmosférica |      | TM                                | RS                |    |    | GPS       | NS                                                        | TS                         | VP                       | TC                                 | TT            |
| Bipolar nube<br>– tierra             | [13] | 3200                              | 1280<br>x 800     | Si | Si | Si        | 4                                                         | 104.4<br>- 328             | 1.1x105<br>, 6.7x<br>106 | 80,<br>20                          | NI            |
|                                      | [14] | 3200                              | NI                | Si | No | No        | NI                                                        | NI                         | NI                       | NI                                 | NI            |
|                                      | [12] | 4000 -<br>10000                   | NI                | Si | No | No        | 3, 4                                                      | 141 -<br>318               | NI                       | 90,<br>163                         | NI            |
|                                      | [11] | NI                                | NI                | Sí | Sí | No        | 6                                                         | NI                         | NI                       | 400,<br>165,<br>230,<br>70,<br>100 | NI            |
|                                      | [37] | 1000                              | 832 x<br>600      | Si | No | Si        | 3                                                         | 20,<br>148                 | NI                       | NI                                 | NI            |
| Positivas<br>nube – tierra           | [38] | 50                                | 780 x<br>582      | Si | No | Si        | 1                                                         | NI                         | NI                       | 300                                | 1500          |
|                                      | [39] | 1000                              | 256 x<br>240      | Si | No | No        | 1, 2                                                      | NI                         | NI                       | NI                                 | 740 -<br>1250 |
|                                      | [23] | 10000                             | NI                | Si | No | Si        | NI                                                        | NI                         | 3.0x105                  | 298                                | NI            |
|                                      | [18] | 100 –<br>11800                    | NI                | Si | No | Si        | 1 –<br>3                                                  | 14 –<br>406                | 2.76x<br>105             | 5 –<br>800                         | 204           |
| Negativas<br>nube – tierra           | [40] | 30                                | NI                | Si | No | Si        | 8                                                         | 106<br>med                 | NI                       | NI                                 | 746           |
|                                      | [41] | 40000                             | NI                | Si | No | No        | NI                                                        | NI                         | NI                       | NI                                 | NI            |
|                                      | [38] | 20000                             | 1024<br>x<br>1024 | Si | No | Si        | 1                                                         | NI                         | NI                       | NI                                 | 266 –<br>306  |
|                                      |      | 1000                              | 1024<br>x<br>1024 |    |    |           |                                                           |                            |                          |                                    |               |
|                                      |      | 50                                | 780 x<br>582      |    |    |           |                                                           |                            |                          |                                    |               |
|                                      | [42] | 9060                              | 896 x<br>400      | Si | No | Si        | 6                                                         | 35.53<br>4 –<br>78.11<br>9 | 1.17x<br>106             | NI                                 | 501.2         |
|                                      |      |                                   |                   |    |    |           |                                                           |                            |                          |                                    |               |

Antecedentes 11

**Tabla 1-1**: Revisión de literatura relacionada al uso de imágenes y videos en la caracterización de descargas eléctricas atmosféricas (Continuación)

| Categoría<br>de la                   | Ref. | Características<br>de las cámaras |                                              | CE | CM | Uso<br>de | Características de las descargas<br>analizando los vídeos |             |                                                                           |                                     |              |
|--------------------------------------|------|-----------------------------------|----------------------------------------------|----|----|-----------|-----------------------------------------------------------|-------------|---------------------------------------------------------------------------|-------------------------------------|--------------|
| descarga<br>eléctrica<br>atmosférica |      | TM                                | RS                                           |    |    | GPS       | NS                                                        | TS          | VP                                                                        | TC                                  | TT           |
| Negativas<br>nube – tierra           | [43] | 5400                              | NI                                           | Si | No | No        | 3                                                         | NI          | 5.1x<br>104<br>,<br>1.1x<br>106 –<br>2.2x<br>106                          | Ni                                  | NI           |
|                                      | [44] | 10000                             | 1024<br>x<br>1024                            | Si | No | Si        | 4                                                         | Ni          | 1.83x1<br>7<br>0<br>3.7x107                                               | Ni                                  | 600          |
|                                      | [45] | 20000                             | NI                                           | Si | No | No        | 1, 2,<br>4                                                | Ni          | Ni                                                                        | Ni                                  | Ni           |
|                                      | [46] | 10000<br>20000                    | NI                                           | Si | No | Si        | 4, 5<br>8                                                 | Ni          | Ni                                                                        | Ni                                  | Ni           |
|                                      | [21] | 2500                              | 1200<br>x 500                                | No | No | Si        | 4.3<br>med                                                | 56.7<br>med | NI                                                                        | 16.5<br>–<br>751.<br>1              | 270.2<br>med |
|                                      | [47] | 2500 -<br>3600                    | 1280<br>x 800                                | No | No | Si        | Ni                                                        | Ni          | 0.72x<br>106 –<br>2.2x<br>106                                             | Ni                                  | Ni           |
|                                      | [20] | 1000<br>4000<br>8000              | 240 x<br>210<br>512 x<br>256<br>512 x<br>128 | No | No | Si        | 3.9<br>med                                                | 61.5<br>med | NI                                                                        | 4 –<br>16<br>med<br>,<br>400<br>max | 216,<br>229  |
|                                      | [22] | 5000<br>3000                      | 512 x<br>512<br>1024<br>x<br>1024            | Si | No | No        | 1 –<br>13                                                 | NI          | 1.8x105<br>, 2.2x<br>106                                                  | NI                                  | 822.4        |
|                                      | [24] | 1000                              | NI                                           | Si | No | Si        | NI                                                        | NI          | NI                                                                        | NI                                  | NI           |
|                                      | [48] | 1000,<br>10000,<br>50000          | NI                                           | Si | Si | Si        | 1                                                         | NI          | 4.1x105<br>-<br>14.6x1<br>5<br>0                                          | NI                                  | NI           |
|                                      | [49] | 25,<br>1000,<br>10000,<br>50000   | NI                                           | Si | No | Si        | 3                                                         | 22,<br>446  | 0.8x105<br>-<br>13.7x1<br>5<br>0<br>,<br>0.3x105<br>-<br>10.2x1<br>5<br>0 | NI                                  | 600          |
| Nube –<br>tierra                     | [50] | 650000                            | 1024<br>x<br>1024                            | Si | Si | No        | NI                                                        | NI          | NI                                                                        | NI                                  | NI           |
| Positivas<br>tierra – nube           | [51] | 1000 –<br>35000                   | NI                                           | Si | No | No        | NI                                                        | NI          | NI                                                                        | NI                                  | NI           |

113.6

| Categoría<br>de la                   | Ref. | Características<br>de las cámaras |                                | CE | CM | Uso<br>de |           |               | Características de las descargas<br>analizando los vídeos |          |              |
|--------------------------------------|------|-----------------------------------|--------------------------------|----|----|-----------|-----------|---------------|-----------------------------------------------------------|----------|--------------|
| descarga<br>eléctrica<br>atmosférica |      | TM                                | RS                             |    |    | GPS       | NS        | TS            | VP                                                        | TC       | TT           |
| Negativas<br>tierra – nube           | [52] | 300000                            | 104 x<br>128                   | No | No | No        | NI        | NI            | NI                                                        | NI       | NI           |
|                                      | [15] | 1000 –<br>35000                   | NI                             | Si | No | Si        | 2 –<br>4  | 16.3,<br>54.3 | NI                                                        | NI       | 363,<br>430  |
|                                      | [37] | 1000                              | 832 x<br>600                   | Si | No | Si        | 6         | 14 -<br>64    | 3.2x105                                                   | NI       | NI           |
| Tierra -<br>nube                     | [19] | 30                                | 640 x<br>480,<br>1280<br>x 720 | Si | No | No        | 1 -<br>14 | 68.1<br>med   | Ni                                                        | NI       | 1225         |
| Nube - nube                          | [30] | 5000                              | 512 x<br>512                   | No | No | No        | 1 -<br>4  | 15.8<br>–     | NI                                                        | ><br>500 | 180.8<br>med |

**Tabla 1-1**: Revisión de literatura relacionada al uso de imágenes y videos en la caracterización de descargas eléctricas atmosféricas (Continuación)

Fuente: diseño propio

#### **Abreviaturas:**

TM: tasa de muestreo en cuadros por segundo

RS: resolución de la cámara en píxeles CE: medición de campo eléctrico CM: medición de campo magnético GPS: sistema de posicionamiento global NS: número de descargas subsecuentes

TS: intervalo de tiempo ó tiempo promedio entre las descargas subsecuentes medido en ms

VP: velocidad promedio de propagación de las descargas subsecuentes medido en m/s

TC: tiempo de duración de las corrientes continuas en descargas subsecuentes medido en ms

TT: tiempo promedio total de la(s) descarga(s) medido en ms

NI: no indica med: media max: máximo

- Número de descargas subsecuentes [11], [12], [37]–[40], [42]–[46], [48], [13], [49], [53]–[57], [15], [18]–[22], [30]. Con el objeto de minimizar la probabilidad de pérdidas de descargas subsecuentes presentadas entre intervalos de descargas subsecuentes en el orden de los milisegundos, los autores en [20] sugirieron que las tasas de muestreo de las cámaras se deben ajustar igual o por encima de 1000 cuadros por segundo.
- Estimación del intervalo de tiempo entre descargas subsecuentes [12], [13], [49], [15], [18]–[21], [30], [37], [42]. De acuerdo a [15] este parámetro es 1.5 veces mayor en descargas positivas nube – tierra en comparación con descargas negativas nube – tierra.

Antecedentes 13

• Estimación de la velocidad promedio de propagación de las descargas subsecuentes [13], [15], [22], [23], [37], [43], [47]–[49], [58].

- Estimación del tiempo de duración de las corrientes continuas en descargas subsecuentes [11]–[13], [15], [20], [21], [23], [30], [38], [55].
- Estimación del tiempo total de las descargas [15], [18], [42], [44], [49], [55], [19]–[22], [30], [38]–[40].
- Estimación del tiempo de duración de descargas subsecuentes [30].
- Estimación del tiempo de duración del líder escalonado [59]. La transferencia de cargas en un líder escalonado con ramificaciones ocasiona que la velocidad de propagación sea menor comparada con un líder sin ramificaciones [22].
- Estimación del tiempo de duración del líder dardo [44].
- Estimación del tiempo de duración de la corriente en la etapa inicial [19].
- Estimación del tiempo de los intervalos entre picos de las corrientes en la descarga [41].
- Estimación del intervalo de tiempo entre el inicio del líder y la descarga de retorno [46].
- Estimación del tiempo entre los pasos del líder escalonado [48].
- Estimación de la velocidad promedio del líder principal [39], [45], [64]–[66], [52]–[54], [56], [60]–[63].
- Estimación de la velocidad promedio del líder escalonado [42], [44], [46], [59], [67], [68].
- Estimación de la velocidad promedio de los líderes dardo [35], [42], [44], [64], [67].

- Estimación de la velocidad promedio de las ramificaciones [42], [52], [60], [69].
- Estimación de las velocidades de líderes positivos ascendentes de conexión (UCPL) de tres eventos [70] los cuales utilizaron una cámara configurada a 647619 cuadros por segundo y a una resolución de 208 x 24 píxeles.
- Estimación del tiempo de duración de luminosidad en los líderes [39], [71].
- Número de impactos a tierra de las descargas [21], [38].

La precisión para estimar los tiempos asociados a los parámetros de las descargas descritos con anterioridad mejora en la medida en que se utilicen estampas de tiempo de alta precisión provistas por sistemas de posicionamiento global (GPS) [13], [15], [40], [42], [44], [47]–[49], [53], [55]–[57], [18], [62], [63], [65], [72]–[74], [20], [21], [23], [24], [35], [37], [38]. Esto debido a que la información visual se sincroniza con mediciones de campo eléctrico y/o campo magnético.

De otro lado, el uso de cámaras de video en conjunto con redes de localización de descargas permite estimar la distancia de la descarga con respecto a la cámara [11], [12], [15], [20], [24] y evaluar la eficiencia de las redes en el proceso de detección, las cuales no siempre proveen información exacta respecto al suceso del fenómeno natural [11]–[13], [37], [49], [75], [76]. Por ejemplo, la investigación documentada en [24] indicó que la red tuvo una eficiencia del 90% en la detección de las descargas negativas nube tierra y cerca de un 50% en la detección de descargas subsecuentes.

En algunos trabajos reportados en la literatura, se evidencia una correlación entre la información visual adquirida con datos provistos por mediciones de campos eléctricos y en menor medida con datos provistos por mediciones de campos magnéticos. Confrontar la información visual con datos del campo eléctrico de las descargas permitió estimar el tiempo que permanecen las corrientes continuas en descargas subsecuentes [11], [12], [46], [77], [13], [15], [20], [21], [23], [38], [42], [45]. De acuerdo a [20] este tiempo se infiere en los videos a partir de la luminosidad continúa en el canal que se presenta posterior a la descarga de retorno. Los autores [20], [21] afirmaron que esta duración es Antecedentes 15

clasificada como larga si es mayor a 40 ms, corta si está entre 10 ms y 40 ms y muy corta si se encuentra entre 4 ms y 10 ms.

Analizar los niveles de luminosidad de la descarga en imágenes y videos adquiridos con cámaras de alta velocidad provee robustez en la caracterización de diversos parámetros [51], [73], [76]. Utilizando videos adquiridos a 50000 y 12500 cuadros por segundo respectivamente [78], [79] determinaron a partir de la intensidad lumínica el líder ascendente de conexión. Con un video muestreado a 300000 cuadros por segundo los autores en [52] pudieron determinar cambios ligeros en luminosidad de la descarga, esto permitió estudiar con mayor detalle el canal, obtener varias características de propagación y analizar la formación de ramificaciones.

La frecuencia con la que se presentan ramificaciones en descargas eléctricas atmosféricas también ha sido estudiada. En [80] analizaron 282 líderes dardo de 72 descargas negativa nube – tierra mediante la información suministrada tanto por videos adquiridos con tasa de muestreo de 50000 cuadros por segundo y con resolución de 320 x 240 píxeles como por sensores de medición de campo eléctrico. Esta investigación indicó que 50 líderes dardo presentaron ramificaciones (17.7%), 41 descargas tuvieron al menos una ramificación en el líder dardo y nueve presentaron dos ramificaciones.

A partir de un video de descarga nube a tierra adquirido a 20000 cuadros por segundo y con una resolución de 1024 x 1024 píxeles, los autores en [81] implementaron un algoritmo basado en los niveles de luminosidad del canal del líder con el objeto de correlacionar la densidad de carga entre las diferentes ramificaciones de las descargas. Determinaron que existieron leves diferencias de densidad entre la primera y la segunda ramificación.

El brillo sostenido visualizado en las imágenes de la descarga y las pequeñas deflexiones visualizadas en las gráficas de los campos eléctrico y magnético permitió a los autores en [13] establecer que estas características están relacionadas a la presencia de componentes M. Fotografías del componente M adquiridas con cámaras de video de alta velocidad mostraron las direcciones en las cuales múltiples ondas de luz atravesaron el canal de la descarga [82].

Utilizando mediciones de campo eléctrico, interferómetro y videos adquiridos a 5000 cuadros por segundo y a una resolución 512 x 512 píxeles, los autores en [83] analizaron características de las corrientes de componentes M. A partir de la intensidad lumínica en descargas nube tierra adquiridas a 50000 cuadros por segundo y con resolución de 320 x 240 píxeles [84] estimaron las velocidades en dos dimensiones de componentes M. Esta variable según los autores es importante con el objeto de comprender la teoría relacionada a la propagación de dichos componentes.

Los valores de luminosidad de las descargas tienden a aumentar a medida que el líder se acerca a tierra [22]. Por otro lado, la variación de luminosidad en descargas nube - nube permitió a los autores en [30] estudiar y entender el proceso suscitado en este fenómeno, además infirieron que este tipo de descargas presenta mayor luminosidad que las descargas a tierra.

Además, el procesamiento realizado a imágenes y videos de descargas permite analizar los valores de luminosidad con el objeto de asociarlos a valores de corrientes del canal [24], [28], [81]. Esta luminosidad es detectable en las grabaciones de videos en la medida que la descarga disipe una cantidad mínima de energía que es dependiente de la corriente y la conductividad del líder [53]. Debido a esto no es posible visualizar líderes de baja corriente.

Varias investigaciones están enfocadas en la descripción de descargas bipolares nube – tierra. De acuerdo a [37] estas descargas no ocurren con frecuencia y por tanto los reportes en la literatura sobre ellas se encuentran en menor medida. Los videos de alta velocidad son necesarios en el proceso de caracterización de descargas bipolares debido a que al correlacionar la información visual con mediciones de campo eléctrico es posible validar si sobre un mismo canal de descarga se presenta en diferentes instantes de tiempo descargas subsecuentes tanto positivas como negativas [12]. Además, correlacionar la información provista por mediciones de campo eléctrico y el brillo en imágenes de descargas permite inferir el tipo de descarga [38].

La formación de las descargas bipolares normalmente ocurre al interior de la nube con solamente la parte descendente de la descarga desarrollándose debajo de su base [14]. Los autores argumentaron que cuando acontecen disrupciones preliminares en altitudes Antecedentes 17

de 2.7 km a 4.1 km se suscita la presencia de una capa con carga positiva significativa, aunque estas hipótesis están basadas en el análisis visual realizado únicamente a una descarga.

Confrontar la información visual adquirida con cámaras de alta velocidad y redes de localización de descargas permitió a los autores en [85] determinar diferencias en los niveles de luminosidad entre los líderes positivo y negativo en el desarrollo inicial de un líder bidireccional. El líder positivo suministró un nivel de alta intensidad al inicio y durante el evento, mientras que la luminosidad del líder negativo fue tenue, débil y al final del fenómeno no visible.

El uso de cámaras de alta velocidad en conjunto con sistemas de medición de señales eléctricas ha permitido detallar características no frecuentes en las descargas llamadas líderes caóticos. Este término se ha utilizado en relación a una secuencia relativamente continua de pulsos de campo eléctrico irregulares que se presentan en una ventana temporal de 2 ms antes de la descarga de retorno. El trabajo desarrollado por [72] tuvo como objeto analizar los líderes caóticos y compararlos con características provistas por líderes dardo. Afirmaron que es posible que los pulsos del líder dardo sean mucho más débiles que los suministrados por líderes caóticos.

Correlacionar la información provista por una cámara de alta velocidad y un interferómetro de banda ancha VHF (Very High Frequency) permitió a los autores en [44] reconstruir en tres dimensiones el canal de la descarga. Indicaron que esta relación posibilitó comprender con mayor profundidad el proceso relacionado a la evolución temporal y espacial del fenómeno.

La literatura además presenta trabajos enfocados en la implementación de hardware en la detección y el uso de software con el objeto de proveer mejoras en el análisis de las descargas. Investigaciones como la realizada por [50] destaca el uso de cámaras de alta velocidad con el objeto de validar el hardware acústico implementado para este propósito. El hardware se realizó mediante un arreglo de micrófonos y antenas que recibieron las señales acústicas de los truenos asociados al fenómeno y las señales electromagnéticas de las descargas de retorno respectivamente. Con la señal electromagnética obtuvieron el instante en que se presenta la descarga, y utilizando la diferencia entre la señal electromagnética y la acústica del trueno determinaron la distancia entre la fuente de medida y el fenómeno.

Además, las fotografías de las descargas permitieron correlacionar y validar los mapeos en 2 y 3 dimensiones de las descargas los cuales fueron implementados con la información provista por el arreglo de micrófonos. Indicaron que el sistema presenta imprecisiones cuando se presentan varias señales electromagnéticas debido a varias descargas de retorno asociadas a una misma descarga o cuando ocurren simultáneamente varias descargas, esto debido a que el arreglo de micrófonos no tiene la capacidad de discriminar ante estas situaciones.

El uso de software de edición fotográfica ha sido utilizado para mejorar la calidad visual de las descargas sin deteriorar las características de la forma original [41], [53]. Ambos trabajos resaltaron el brillo del canal mediante técnicas de inversión de color, mejoras de contraste, modificaciones en los niveles de exposición, y corrección gamma. La aplicación de estos métodos hizo más evidente la trayectoria de la descarga permitiendo analizar con mayor detalle el fenómeno.

Similar al procedimiento anterior, se han utilizado técnicas de procesamiento de imágenes provistas por el software Matlab con el objeto de mejorar el contraste de canales de descargas débiles [30]. A partir de este proceso fue posible promediar los niveles de luminosidad en cada imagen de la descarga y determinar que la variación de luminosidad del canal presenta una distribución gaussiana. Por otro lado, el uso de software con el objeto de llevar a cabo inversión de color y mejora de contraste en fotografías de descargas, permitió a los autores en [70] resaltar las características ópticas en el proceso de unión del líder dardo escalonado con la tierra.

Algoritmos de procesamiento se han utilizado con el objeto de segmentar la descarga. Basado en la investigación previa detallada en [86], los autores en [28] propusieron un método para analizar el brillo del canal de descarga a partir de la aplicación del concepto de sistema de magnitudes utilizado en fotometría astronómica. Este sistema relaciona valores de magnitud con valores de brillo de una estrella, aunque los autores indicaron que no ubicaron información respecto a su uso en descargas. Los valores de magnitud Antecedentes 19

se determinaron con valores de luminosidad de los píxeles de la imagen convertida a escala de grises en el rango de 0 a 255 que incluyó únicamente el canal de descarga.

La imagen de la descarga fue adquirida a una resolución de 3000 x 2000 píxeles. La segmentación se realizó utilizando técnicas de umbralización, adelgazamiento, engrosamiento y detección de bordes a partir del filtro de Sobel provistas por la librería de procesamiento de imágenes OpenCV. Este proceso utilizó correcciones manuales debido a que la imagen procesada presentaba ruido relacionado a luces artificiales y luminiscencia de las nubes. La investigación indicó que el decremento en el brilló del canal estuvo relacionado al incremento de los valores de magnitud. A partir de lo anterior, los autores concluyeron que valores de corrientes altos en el canal de descarga correspondieron a valores de magnitud bajos, y valores de corrientes bajos en el canal estuvieron relacionados a valores de magnitud altos.

Además, sugirieron que, así como existen estándares utilizados en las evaluaciones del brillo de las estrellas se deben realizar investigaciones que permitan normalizar las relaciones entre la magnitud y el brillo del canal de descarga. Si bien propusieron un algoritmo con el objeto de separar la descarga de la imagen, este proceso únicamente fue aplicado a una imagen con la descarga adquirida previamente.

Los autores en [87] aplicaron la matriz de co-ocurrencia de niveles de grises (GLCM - Gray Level Co-occurrence Matrix) con el objeto de detectar descargas eléctricas atmosféricas en videos provistos por cámaras de seguridad y vigilancia. La GLCM se utilizó para determinar los cambios de contraste y homogeneidad entre fotogramas consecutivos. La limitación de este método se reflejó en que el algoritmo asoció como descarga diversas variaciones en luminosidad que se presentaron en la adquisición del video. Los autores utilizaron el canal luma en el proceso de detección y no brindaron información respecto a la precisión de la técnica.

Los trabajos en [88], [89] establecen un procedimiento basado en umbralización con el objeto de llevar a cabo la detección de la descarga. El método propuesto se basa en leer el cuadro del video, convertirlo a escala de grises y segmentar la imagen de la descarga con un nivel de umbral establecido. La desventaja de este proceso radica en que diversos objetos diferentes a la descarga pueden proveer niveles de intensidad

semejantes, además que en ambas investigaciones no se realizó un análisis morfológico con el propósito de clasificar correctamente el objeto detectado.

Similar a estos trabajos, los autores en [90] utilizaron también como técnica de segmentación de la descarga el método de umbralización. Sin embargo, haciendo uso del procedimiento de detección de bordes aplicando el operador morfológico de Sobel pudieron establecer tanto discontinuidades que posiblemente se presenten en la descarga segmentada como clasificar las descargas de acuerdo a su orientación ya sea vertical u horizontal. En ésta y en las dos investigaciones previamente mencionadas, los autores no suministraron datos relacionados a la precisión en el proceso de detección de la descarga.

Respecto a métodos de visión computacional, [91] utilizaron segmentación semántica a partir del entrenamiento de cinco redes neuronales con el objeto de clasificar descargas en 111 videos correspondientes a 48381 fotogramas en escala de grises. Los videos se adquirieron en un entorno de visión invariable y con una cámara de alta velocidad Vision Phantom v310 ajustada a una tasa de muestreo entre 5000 y 23000 cuadros por segundo y a una resolución de 512 x 256 y 512 x 352 píxeles. La precisión en la detección por parte de cada una de las redes correspondió a 74.1% con AlexNet, 87.5% con DeepLabv3+, 65.2% con FCN8s, 60.4% con SegNet y 51.2% con U-Net. Los autores indicaron que la técnica presentada podría no ser adecuada bajo otras condiciones diferentes a las utilizadas respecto al ángulo de visión y resolución de la imagen, además, el algoritmo clasifica ruido como descarga en imágenes muy oscuras y asocia a la descarga píxeles cercanos al evento. Establecen que bajo estos escenarios el sistema no está ajustado y por tanto no provee robustez en el proceso de detección.

Otros trabajos han indicado el procedimiento utilizado para dar inicio a la grabación visual de las descargas. Este proceso lo ha realizado de forma manual una persona que sirve como observador [22], [63]. Los autores en ambas investigaciones realizaron la grabación de la información visual de la descarga mediante el uso de un búfer circular. Por otro lado, este proceso también ha sido implementado haciendo uso de un fotodiodo que ante un cambio fuerte en la luz ambiente suministró el disparo para la adquisición de la información visual [21].

Antecedentes 21

La literatura destaca la importancia de utilizar cámaras de alta velocidad con el objeto de adquirir videos que permitan describir, analizar y caracterizar las descargas eléctricas atmosféricas. Sin embargo, en la revisión de la literatura realizada, aún no se ha encontrado información que indique de forma autónoma el proceso de disparo para la adquisición de los videos a partir del mismo video, y se presenta una cantidad limitada de trabajos relacionados a técnicas de procesamiento de imágenes y algoritmos de visión computacional utilizadas en la detección de las descargas que indiquen la presencia del fenómeno natural en tiempo real de forma tal que se almacene únicamente la información visual pertinente. Debido a esto, la investigación tiene por objeto proponer una metodología de procesamiento digital de imágenes y videos que permita detectar las descargas, analizar los valores de luminosidad del canal y suministrar información respecto al número de descargas subsecuentes que tienen lugar en un mismo evento.

# <span id="page-40-0"></span>**2.Propuesta metodológica en la detección de descargas eléctricas atmosféricas**

Uno de los objetivos de este trabajo es identificar en videos el canal de la descarga empleando técnicas de procesamiento de imágenes y visión computacional. El interés por tanto está enfocado en desarrollar un algoritmo que indique la presencia de la descarga en alguno de los fotogramas del video. Con el objeto de poder desarrollar una herramienta orientada a la detección, es necesario conocer las características de imágenes de la descarga.

### <span id="page-40-1"></span>**2.1 Características de imágenes de descargas eléctricas atmosféricas**

La caracterización de las descargas se lleva a cabo a partir del análisis realizado a los niveles de intensidad y a la forma indicada en las imágenes.

#### <span id="page-40-2"></span>**2.1.1 Niveles de intensidad en imágenes de descargas**

La Figura 2-1 muestra una imagen de una descarga en el espacio de color RGB y valores de intensidad a una resolución de 8 bits (rango de 0 a 255) de algunos píxeles de la descarga. Este proceso fue realizado con el toolbox procesamiento de imágenes [92] del software Matlab versión R2020b [93].

Se observa en la imagen que los valores de intensidad de los colores R (rojo), G (verde) y B (azul) relacionados a la descarga presentan un nivel alto de intensidad. Se infiere que, al combinar los colores se genera una tonalidad cercana al blanco puro. Debido a un análisis similar realizado a otras imágenes de descargas y a que no existe un predominio significativo en los niveles de intensidad de un canal de color sobre los otros, se realiza el análisis en imágenes en escala de grises.

<span id="page-41-0"></span>**Figura 2-1:** Descarga eléctrica atmosférica en el espacio de color RGB y valores de intensidad

Fuente: imagen obtenida mediante código implementado en Matlab

La Figura 2-2 muestra la descarga en escala de grises con sus valores de intensidad, se observa que éstos se encuentran cercanos al máximo valor del rango. Debido a esto, y teniendo en cuenta que haciendo uso de videos se realiza el proceso de detección, se utiliza como herramienta el histograma con el objeto de representar gráficamente la distribución de píxeles – intensidad en cada cuadro del video.

La Figura 2-3 muestra cuadros en escala de grises de un video de descarga con sus respectivos histogramas en los instantes antes y durante el suceso del evento, etiquetados como casos (a), (b), (c) y (d). En el Anexo A se suministran más ejemplos gráficos de este proceso. Se hizo uso de 113 videos nombrados en este trabajo como Video 1 a Video 113, de los cuales 83 son propios, dos publicados en plataforma de videos en la Internet [94], 23 fueron adquiridos del banco de videos libres y en línea Pexels [95], uno se adquirió del banco de videos libres y en línea Pixabay [96] y cuatro en el banco de videos libres y en línea Videvo [97]. Este proceso y los posteriormente descritos se realizaron con el lenguaje de programación Python versión 3.8 [98] utilizando la librería OpenCV versión 4.4.0 [99].

<span id="page-42-0"></span>**Figura 2-2:** Descarga eléctrica atmosférica en escala de grises y valores de intensidad

Fuente: imagen obtenida mediante código implementado en Matlab

![](_page_42_Figure_5.jpeg)

<span id="page-42-1"></span>**Figura 2-3:** Histogramas de imágenes en escala de grises de un video de descarga

Fuente: imagen obtenida mediante código implementado en Python

En el histograma de la Figura 2-3 (a) se observa que, ante la ausencia de la descarga, los valores más altos relacionados al nivel de intensidad están cercanos a 200. Se observa en la Figura 2-3 (b) que el instante relacionado al impacto del líder de la descarga produce una alta luminosidad en la imagen, ocasionando que un porcentaje alto de píxeles se localicen al extremo derecho del histograma. Este evento no siempre es visible en los fotogramas del video y debido a las características de alta luminosidad y forma física de la descarga en este instante, este fotograma no es utilizado como elemento diferenciador de la descarga con otros objetos.

En los histogramas de la Figura 2-3 (c) y (d) se observa, con la presencia de la descarga, un incremento de píxeles por encima del valor de intensidad 200. Este incremento de píxeles entre cuadros secuenciales del video, en este caso con un umbral cercano a 200, sirve como elemento diferenciador con el propósito de evaluar el cuadro del video en el que posiblemente se encuentre la descarga.

Se realiza un análisis similar en otros videos y se obtiene que tanto el umbral de intensidad como la cantidad de los píxeles asociados a la descarga difieren. Se ha descrito que los valores de intensidad de la descarga corresponden a un nivel alto, en algunos casos estos valores son cercanos a 255, y en otros casos están alejados de este valor. Esta incertidumbre respecto a los valores de intensidad de la descarga provee complejidad en la selección de un único valor umbral que indique el instante en el cual acontece el evento. Debido a esto, se realiza un análisis del espacio de color en imágenes de descargas a fin de establecer si existen representaciones alternativas de la información del color que a través de su histograma suministren datos significativos respecto a la intensidad y el número de píxeles.

### <span id="page-43-0"></span>**2.1.2 Análisis del espacio de color en imágenes de descargas**

El análisis del espacio de color en imágenes de descargas se realiza con el propósito de determinar los componentes que son altamente sensibles ante el suceso del fenómeno natural. La Figura 2-4 muestra la representación en bloques relacionado a este proceso.

Inicialmente, cada video es fragmentado en un conjunto de fotogramas secuenciales. Seguidamente, se seleccionan únicamente los cuadros que contienen información de la descarga. Una vez seleccionados los cuadros, la descarga es segmentada manualmente, de esta forma el posterior procesamiento se realiza únicamente con los píxeles asociados al evento, sin tener en cuenta aquellos que pertenecen al fondo de la imagen.

<span id="page-44-0"></span>**Figura 2-4:** Diagrama de bloques correspondiente al proceso de selección de los canales de color

![](_page_44_Figure_4.jpeg)

Fuente: diseño propio

Luego, cada cuadro con la segmentación de la descarga es convertido a cada espacio de color incluyendo la separación de canales de color sobre aquellos modelos de color que poseen varios componentes. Este proceso permite establecer los canales de color que proveen información relevante de la descarga. Posteriormente, cada grabación de video se convierte a cada componente de color elegido.

Finalmente, se determinan y se analizan los histogramas de cada cuadro secuencial del video convertido a los componentes de color seleccionados a fin de establecer los canales de color más sensibles ante el suceso de la descarga. La Figura 2-5 muestra las imágenes obtenidas mediante estas conversiones. La Tabla 2-1 indica los canales de color correspondiente a cada caso mostrado en la Figura 2-5. En el Anexo B se suministran más ejemplos gráficos de este proceso.

<span id="page-44-1"></span>**Figura 2-5:** Conversión a espacios de color de imagen asociada a video de descarga

![](_page_44_Figure_9.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

A partir del análisis visual realizado a cada componente de color se establece lo siguiente:

<span id="page-45-0"></span>**Tabla 2-1**: Canales de color utilizados en el análisis de imágenes de descargas eléctricas atmosféricas

| Caso | Imagen                          | Caso | Imagen                         |
|------|---------------------------------|------|--------------------------------|
| (a)  | Modelo de color RGB             | (b)  | Segmentada manualmente         |
| (c)  | Escala de grises                | (d)  | Componente rojo -<br>color RGB |
| (e)  | Componente verde -<br>color RGB | (f)  | Componente azul -<br>color RGB |
| (g)  | Modelo de color XYZ             | (h)  | Componente X -<br>color XYZ    |
| (i)  | Componente Y -<br>color XYZ     | (j)  | Componente Z -<br>color XYZ    |
| (k)  | Modelo de color YCbCr           | (l)  | Componente Y -<br>color YCbCr  |
| (m)  | Componente Cb -<br>color YCbCr  | (n)  | Componente Cr -<br>color YCbCr |
| (o)  | Modelo de color HSV             | (p)  | Componente H -<br>color HSV    |
| (q)  | Componente S -<br>color HSV     | (r)  | Componente V -<br>color HSV    |
| (s)  | Modelo de color HLS             | (t)  | Componente H -<br>color HLS    |
| (u)  | Componente L -<br>color HLS     | (v)  | Componente S -<br>color HLS    |
| (w)  | Modelo de color Lab             | (x)  | Componente L -<br>color Lab    |
| (y)  | Componente a -<br>color Lab     | (z)  | Componente b -<br>color Lab    |
| (aa) | Modelo de color Luv             | (ab) | Componente L -<br>color Luv    |
| (ac) | Componente u -<br>color Luv     | (ad) | Componente v -<br>color Luv    |

Fuente: diseño propio

Las imágenes con los componentes Cb (caso (m)) y Cr (caso (n)) del modelo de color YCbCr, a (caso (y)) y b (caso (z)) del modelo de color Lab, u (caso (ac)) y v (caso (ad)) del modelo de color Luv son descartadas, debido a que en algunas no es visible la descarga y en otras al ser de color gris tanto la descarga como el fondo dificulta realizar sobre ellas un posterior procesamiento. Las imágenes con el componente H de los modelos de color HSV y HLS (caso (p) y caso (t)) y el componente S de los modelos de color HSV y HLS (caso (q) y caso (v)) proveen información visual deficiente de la descarga, por tanto, son descartadas.

Debido a esto, las imágenes en escala de grises (caso (c)) y con los componentes rojo (caso (d)), verde (caso (e)) y azul (caso (f)) del modelo de color RGB, X (caso (h)), Y (caso (i)), Z (caso (j)) del modelo de color XYZ, Y (caso (l)) del modelo de color YCbCr, V (caso (r)) del modelo de color HSV y L (caso (u), caso (x), caso (ab)) de los modelos de color HLS, Lab, Luv respectivamente son seleccionadas.

Las conversiones a los canales de color seleccionados fueron aplicadas al conjunto de videos de prueba, y se calcularon los histogramas respectivos. La Figura 2-6 muestra los histogramas de cuadros secuenciales de un video antes y durante la presencia de la descarga. La Tabla 2-2 indica los rótulos utilizados en cada histograma. En el Anexo C se suministran más ejemplos gráficos de este proceso.

<span id="page-46-0"></span>**Figura 2-6:** Histograma de imágenes en componentes de color seleccionados en video de descarga

![](_page_46_Figure_5.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

Debido a las características en relación a la luminosidad de las descargas, se confrontan los histogramas de cada canal de color con el objeto de seleccionar los componentes que proveen una cantidad relevante de píxeles para niveles altos de intensidad. En los histogramas de la Figura 2-6 se observa que el componente Z del modelo de color XYZ provee mayor selectividad sobre los demás componentes en este aspecto.

<span id="page-47-0"></span>**Tabla 2-2**: Etiquetas utilizadas en los histogramas mostrados en la Figura 2-6

| Rótulo | Canal de color                  | Rótulo  | Canal de color                 |
|--------|---------------------------------|---------|--------------------------------|
| gris   | Escala de grises                | rojo    | Componente rojo -<br>color RGB |
| verde  | Componente verde -<br>color RGB | azul    | Componente azul -<br>color RGB |
| X      | Componente X -<br>color XYZ     | Y_XYZ   | Componente Y -<br>color XYZ    |
| Z      | Componente Z -<br>color XYZ     | Y_YCbCr | Componente Y -<br>color YCbCr  |
| valor  | Componente V -<br>color HSV     | L_HLS   | Componente L -<br>color HLS    |
| L_Lab  | Componente L -<br>color Lab     | L_Luv   | Componente L -<br>color Luv    |

Fuente: diseño propio

La Ecuación 2.1 modela el componente Z en términos de los canales de color rojo, verde y azul. Se observa en la ecuación que este componente pondera de manera importante la componente azul (B) del espacio de colores RGB [100].

$$Z = 0.019334R + 0.119193G + 0.950227B (2.1)$$

Al realizar un análisis más detallado en cada video respecto a la información suministrada por el histograma del componente Z, se encuentra que en el rango de niveles de intensidad 200 – 255 se ubica una cantidad considerable de píxeles relacionados a la descarga. La Figura 2-7 muestra los histogramas de los cuadros de la Figura 2-6 tanto en escala de grises como el del canal de color Z en el rango de niveles de intensidad indicado. En el Anexo D se suministran más ejemplos gráficos de este proceso.

En los histogramas de la Figura 2-7 se observa que existe aleatoriedad en relación a la distribución de los píxeles del canal de color Z y variabilidad respecto a la cantidad de píxeles asociados a la descarga, por tanto, dificulta establecer un valor especifico de umbral. No obstante, el hecho que sea un canal sensible a la descarga permite seleccionar esta representación como base en el procesamiento realizado sobre los cuadros del video.

![](_page_48_Figure_2.jpeg)

<span id="page-48-1"></span>**Figura 2-7:** Histograma de imágenes en escala de grises y en el componente de color Z en Video-6

<span id="page-48-0"></span>Fuente: imagen obtenida mediante código implementado en Python

### **2.1.3 Morfología de las descargas**

Como se ha observado en figuras anteriores, las descargas eléctricas atmosféricas proveen una forma física que tiende a ser delgada y elongada con un camino aleatorio que usualmente incluye varias curvas. Al ser delgada, la descarga en una imagen ocupa un espacio reducido, por tanto, la cantidad de píxeles asociados al fenómeno natural comparada con la cantidad de píxeles del fondo de la imagen es también reducida. El hecho que el canal de la descarga provea un camino aleatorio, implica que la descripción del mismo requiera el uso de varias métricas que permitan estimar su forma física. Ambas características evaluadas en conjunto con los niveles altos de intensidad son utilizadas como elemento identificador de una posible descarga presente en la imagen.

### <span id="page-49-0"></span>**2.2 Identificación de descargas utilizando técnicas de procesamiento de imágenes**

A partir de la caracterización relacionada a los niveles de intensidad y a la forma física de las descargas, se implementan y se evalúan un conjunto de algoritmos basados en técnicas de procesamiento de imágenes con el objeto de realizar la identificación del fenómeno natural. Este proceso inicia con la adecuación de métodos enfocados en detección de bordes con el propósito de identificar si existen elementos diferenciadores entre la descarga y otros objetos presentes en la imagen.

La Figura 2-8 muestra el resultado de la técnica de detección de bordes aplicada a un fotograma de un video de descarga. En (a) se encuentra la imagen en el espacio de color RGB, en (b) se muestran los bordes de la imagen utilizando las derivadas Sobel [101], en (c) los bordes obtenidos con el operador Laplaciano [102], y en (d) los adquiridos con el algoritmo de Canny [103].

<span id="page-49-1"></span>**Figura 2-8:** Resultado de la detección de bordes en imagen de descarga eléctrica atmosférica

![](_page_49_Figure_6.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

Se observa que las derivadas Sobel no acentúan por completo el contorno del objeto de interés y proveen una intensidad similar para resaltar todos los bordes, lo cual dificulta diferenciar objetos de alta luminosidad como es el caso de las descargas. El operador Laplaciano no resalta adecuadamente los bordes de los objetos y por tanto éstos no son visualmente diferenciados. Por último, el algoritmo de Canny, aunque visiblemente suministra una mejor eficacia, realza parte de los bordes de otros objetos con intensidad similar a la de la descarga.

Al analizar este proceso en otras imágenes se determina que la técnica provee resultados aceptables en situaciones en las cuales la descarga presenta un nivel de intensidad considerable en un fondo homogéneo. No es el caso en imágenes con descargas de nivel bajo de intensidad, o con descargas de nivel alto de intensidad que realcen luminosidad en otros objetos, o en imágenes con descargas, elementos y fondo de diferentes tonalidades como la indicada en la Figura 2-8. Ante lo anteriormente expuesto no es recomendable el uso de técnicas basadas en la obtención de bordes en la identificación de descargas en imágenes.

Basado en las características de la descarga descritas en la Sección 2.1 y debido a que la técnica anterior funciona parcialmente, se propone un procedimiento con el objeto de mejorar la eficiencia en la detección de la descarga. La Figura 2-9 detalla la representación en bloques en relación a esta propuesta.

<span id="page-50-1"></span>**Figura 2-9:** Diagrama de bloques de la propuesta metodológica para la detección de descargas eléctricas atmosféricas

![](_page_50_Figure_5.jpeg)

Fuente: diseño propio

El método desarrollado se basa en adecuar diversos algoritmos de procesamiento que son ejecutados de acuerdo a variaciones presentadas en los niveles de intensidad en fotogramas consecutivos de los videos. A continuación, se describe cada etapa del procedimiento propuesto.

#### <span id="page-50-0"></span>**2.2.1 Preprocesamiento de imágenes de descargas**

El objetivo de llevar a cabo el preprocesamiento es obtener información, tanto en datos como visual, asociada al fenómeno de la descarga. El desarrollo de esta etapa indicado en el diagrama de flujo de la Figura 2-10 se fundamenta en los requerimientos demandados por el proceso de segmentación. A continuación, se realiza la descripción.

![](_page_51_Figure_2.jpeg)

<span id="page-51-0"></span>**Figura 2-10:** Diagrama de flujo del preprocesamiento de imágenes de descargas

Fuente: diseño propio

Inicialmente, el video es fraccionado en cuadros y cada imagen convertida a los canales de color gris y Z respectivamente. Posteriormente, se crean las variables, v1 y v2 que hacen referencia a vectores con datos del histograma normalizado del canal de color Z relacionados a los cuadros a procesar previo y actual respectivamente, así como las variables v1a y v2a que contienen los datos de v1 y v2 en el rango de niveles de intensidad 200 – 255 y las variables v1b y v2b que contienen los datos de v1 y v2 en el rango de niveles de intensidad 230 – 255 respectivamente. Se hace uso de estos dos rangos debido a la variabilidad en los niveles de intensidad de la descarga.

Los datos almacenados en los vectores v1a, v2a, v1b y v2b son sumados, de esta forma se obtienen las variables sv1a, sv2a, sv1b y sv2b respectivamente. Los datos suministrados por estas últimas variables son operados y almacenados en las variables da, db y fb con el objeto de establecer si entre cuadros consecutivos se han presentado cambios en niveles de intensidad, los cuales pueden estar asociados a la descarga.

Posteriormente, con el objeto de adquirir una imagen que provea información visual significativa respecto a cambios en niveles de intensidad entre fotogramas consecutivos del video, se obtiene la diferencia rZ entre los cuadros actual y previo desde la perspectiva del canal de color Z, y el vector vZ correspondiente a los datos del histograma normalizado de esta diferencia. Finalmente, se determina el valor umbral thvZ correspondiente al nivel más bajo de variación de intensidad y si el cuadro analizado corresponde al 1 se almacena el valor umbral inicial thvZ\_in. La información relacionada al cuadro 1 (previo) se actualiza con la información del cuadro 2 (actual) durante la ejecución del algoritmo conforme sea requerido en el proceso de segmentación.

#### <span id="page-52-0"></span>**2.2.2 Segmentación en imágenes de descargas**

La segmentación es un proceso que permite subdividir una imagen en sus regiones u objetos de interés [104]. El análisis realizado a la información provista en la etapa de preprocesamiento posibilitó proyectar diversos escenarios, a fin de separar en los fotogramas objetos con características de intensidad similares a las suministradas por las descargas. La segmentación realizada en los procesos que se detallan en esta sección está basada en el método de umbralización [105], específicamente la operación umbral a cero. La Ecuación 2.2 indica el modelo matemático de dicha operación.

$$dst(x,y) = \begin{cases} src(x,y); si \ src(x,y) > umbral \\ 0; en \ otro \ caso \end{cases}$$
 (2.2)

#### Donde:

(, ) es la matriz de datos del cuadro a procesar.

(, ) es la matriz de datos del cuadro segmentado.

La Ecuación 2.2 indica que si (, ) es más bajo al dato almacenado en la variable , el valor del nuevo píxel en (, ) será establecido a 0. El valor de corresponde a un índice del vector de datos del histograma del cuadro procesado, el cual está asociado al número de píxeles que contiene la información de la imagen segmentada. Es de resaltar que este proceso se adecuó buscando menores pérdidas en fotogramas con información visual de descargas a costa de un incremento en fotogramas con objetos segmentados no asociados a este fenómeno natural. A continuación, se realiza la descripción de cada escenario.

**Variación de niveles de intensidad evaluados en la diferencia de cuadros consecutivos.** Debido a que el histograma normalizado asociado a la diferencia entre los cuadros actual y previo desde la perspectiva del canal de color Z suministra diversas escalas de variaciones en los niveles de intensidad ante el suceso de la descarga, se procedió a realizar la segmentación del cuadro actual basado en esta característica. La sintonización de los coeficientes relacionados a estas escalas se realizó de forma experimental garantizando que abarcara un amplio rango de niveles de intensidad. La Figura 2-11 detalla el diagrama de flujo respectivo asignando los siguientes valores a los coeficientes: C1a = 6, C1b = 4, C2a = 5.5, C2b = 5, C2c = 4.5, C2d = 4, C2e = 3.3, C2f = 2.6, C2g = 2, C3 = 0.015.

La Figura 2-12 indica el resultado de la segmentación realizada a un fotograma (imagen (a)) del video 26. Las imágenes (b) a (e) se obtuvieron sintonizando C1 a 6 y variando C2 a 5.5, 5, 4.5 y 4 respectivamente. Se observa que el decremento del coeficiente C2 incrementa la cantidad de píxeles en la imagen segmentada asociados tanto al objeto de interés como a ruido, esto se debe a que el decremento en dicho coeficiente es proporcional al decremento del valor umbral utilizado en el método de umbralización.

La imagen (a) de la Figura 2-13 muestra el resultado de la segmentación realizada a un fotograma del video 33. Las imágenes (b) a (e) se obtuvieron bajo las condiciones descritas en relación a la Figura 2-12. La imagen (f) corresponde al fotograma posterior al indicado en la imagen (a). Las imágenes (g) a (i) se obtuvieron sintonizando C1 a 4 y variando C2 a 3.3, 2.6 y 2 respectivamente. El decremento de los coeficientes C1 y C2 permite que una imagen con una descarga más tenue a la de su predecesora sea segmentada bajo esta técnica obteniendo características en niveles de intensidad similares a las indicadas con anterioridad.

En algunos casos es necesario recurrir al valor más bajo del coeficiente C2 con el objeto de obtener una adecuada segmentación, tal situación es detallada en la Figura 2-14. Las imágenes (b) a (d) se obtuvieron sintonizando C1 a 4 y variando C2 a 3.3, 2.6 y 2 respectivamente. Se observó con esta técnica que bajo diferentes condiciones de luminosidad es posible obtener una imagen adecuada de la descarga segmentada a partir de la sintonización apropiada de los coeficientes.

<span id="page-54-0"></span>**Figura 2-11:** Diagrama de flujo de segmentación a partir de la variación de niveles de intensidad evaluados en la diferencia de cuadros consecutivos

![](_page_54_Figure_3.jpeg)

Fuente: diseño propio

<span id="page-55-0"></span>**Figura 2-12:** Resultado de segmentación a partir de la variación de niveles de intensidad evaluados en la diferencia de cuadros consecutivos realizada al video 26

![](_page_55_Figure_3.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

<span id="page-55-1"></span>**Figura 2-13:** Resultado de segmentación a partir de la variación de niveles de intensidad evaluados en la diferencia de cuadros consecutivos realizada al video 33

![](_page_55_Figure_6.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

<span id="page-55-2"></span>**Figura 2-14:** Resultado de segmentación a partir de la variación de niveles de intensidad evaluados en la diferencia de cuadros consecutivos realizada al video 62

![](_page_55_Figure_9.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

**Cuadros con fondo de diferente intensidad.** De acuerdo a diversos análisis visuales realizados a fotogramas de los videos de las descargas se determinó que su fondo ante el fenómeno natural presenta variabilidad en niveles de intensidad. Por tanto, se

desarrolló un algoritmo que evaluó los cambios de un fotograma a otro en relación a niveles de intensidad que pueden estar asociados a descargas y a partir de los datos suministrados se establece si la imagen a segmentar posee fondo de baja, de media o de alta intensidad. La Figura 2-15 detalla el diagrama de flujo respectivo asignando el valor 0.00001 al coeficiente C4.

<span id="page-56-0"></span>**Figura 2-15:** Diagrama de flujo de segmentación en cuadros con fondo de diferente intensidad

![](_page_56_Figure_4.jpeg)

Fuente: diseño propio

**Cuadros con fondo de baja intensidad.** Se presenta cuando las variaciones en el fondo entre los cuadros actual y previo proveen baja intensidad con tonalidades oscuras u opacas. La evaluación respecto a la información suministrada por los histogramas de ambos cuadros se utilizó con el objeto de establecer esta característica y realizar la posterior segmentación. La Figura 2-16 muestra el diagrama de flujo respectivo asignando los siguientes valores a los coeficientes: C5 = 0.001, C6 = 0.0025, C7 = 0.025, C8 = 0.005, C9 = 211.

Este proceso inicia confrontando la información obtenida a partir de la suma de los datos del histograma en el rango 230 - 255 del cuadro previo con el coeficiente C5, el cual almacena un valor relacionado a baja intensidad. Si se establece que en este cuadro no

existe este nivel de intensidad se procede a evaluar otros escenarios. De presentarse este nivel de intensidad se evalúan tres situaciones que pueden manifestarse: variaciones de intensidad considerables entre los cuadros, leves variaciones en los niveles altos de intensidad entre los cuadros, y variaciones de intensidad entre los cuadros, estos dos últimos casos pueden deberse al suceso de la descarga.

<span id="page-57-0"></span>**Figura 2-16:** Diagrama de flujo de segmentación en cuadros con fondo de baja intensidad

![](_page_57_Figure_4.jpeg)

Fuente: diseño propio

La verificación respecto a leves variaciones en los niveles altos de intensidad entre los cuadros se establece bajo cualquiera de las siguientes dos condiciones. La primera corresponde a determinar que la variable db no supere el valor almacenado en el coeficiente C6, La segunda es garantizando que todos los datos del histograma en el rango de niveles de intensidad 238 – 255 del cuadro evaluado sean iguales a cero. Si acontece cualquiera de estas dos situaciones se realizan tres procesos de segmentación, los cuales se describirán posteriormente, a fin de establecer si el cuadro actual contiene la descarga. Si la variable db no supera el valor almacenado en el coeficiente C7 se procede a segmentar la imagen, esto como consecuencia a cambios de intensidad entre los cuadros que pueden deberse al suceso de la descarga.

La imagen (f) de la Figura 2-17 indica el resultado de la segmentación realizada a un fotograma (imagen (a)) del video 110. Las imágenes (b) a (e) se obtuvieron a partir de la segmentación descrita en el caso 1 sintonizando C1 a 6 y variando C2 a 5.5, 5, 4.5 y 4 respectivamente. Se observa una mejora significativa en este proceso bajo la técnica de segmentación indicada.

<span id="page-58-0"></span>**Figura 2-17:** Resultado de segmentación en cuadros con fondo de baja intensidad realizado al video 110

![](_page_58_Figure_5.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

Si el dato almacenado en la variable db supera el valor almacenado en el coeficiente C7 existen cambios de intensidad considerables entre los cuadros. Esta variabilidad se debe a dos circunstancias que pueden manifestarse en el cuadro a procesar. La primera está relacionada al impacto del líder de la descarga que conlleva a que se presente saturación asociada a alta luminosidad. La segunda corresponde a saturación presente en el sensor óptico de la cámara. A causa de esto no se realiza segmentación en el cuadro actual y no se actualizan tanto los cuadros como los histogramas. A continuación, se describen los tres procesos adicionales de segmentación indicados previamente.

**Segmentación a partir de la umbralización de la diferencia de cuadros en canal de color Z**. Este proceso se realizó umbralizando la diferencia entre los cuadros actual y previo a la descarga bajo la perspectiva del canal Z. La Figura 2-18 muestra el diagrama de flujo respectivo asignando los siguientes valores a los coeficientes: C10 = 50, C11 = 0.0008, C12 = 0.025. Si la imagen resultante no provee una cantidad de píxeles que puedan ser asociados a la descarga ésta no se guarda y se continúa con el siguiente proceso de segmentación.

<span id="page-59-0"></span>**Figura 2-18:** Diagrama de flujo de segmentación a partir de la umbralización de la diferencia de cuadros en canal de color Z

![](_page_59_Figure_4.jpeg)

Fuente: diseño propio

La imagen (f) de la Figura 2-19 indica el resultado de la segmentación realizada a un fotograma (imagen (a)) del video 108. Las imágenes (b) a (e) se obtuvieron a partir de la segmentación descrita en el caso 1 sintonizando C1 a 6 y variando C2 a 5.5, 5, 4.5 y 4 respectivamente. Igual al caso anterior, se observa una mejora significativa en este proceso bajo la técnica de segmentación indicada.

**Segmentación a partir de la umbralización de la diferencia de cuadros en canal de color gris.** Este proceso se realizó umbralizando la diferencia entre los cuadros actual y previo a la descarga bajo la perspectiva del canal gris. La Figura 2-20 muestra el diagrama de flujo respectivo asignando los siguientes valores a los coeficientes: C13 = 10, C14 = 80. Si la imagen resultante no provee una cantidad de píxeles que puedan ser asociados a la descarga ésta no se guarda y se continúa con el siguiente proceso de segmentación.

<span id="page-60-0"></span>**Figura 2-19:** Resultado de segmentación a partir de la umbralización de la diferencia de cuadros en canal de color Z realizado al video 108

![](_page_60_Figure_4.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

<span id="page-60-1"></span>**Figura 2-20:** Diagrama de flujo de segmentación a partir de la umbralización de la diferencia de cuadros en canal de color gris

![](_page_60_Figure_7.jpeg)

Fuente: diseño propio

La imagen (f) de la Figura 2-21 indica el resultado de la segmentación realizada a un fotograma (imagen (a)) del video 72. Las imágenes (b) a (e) se obtuvieron a partir de la segmentación descrita en el caso 1 sintonizando C1 a 6 y variando C2 a 5.5, 5, 4.5 y 4 respectivamente. Igual al caso anterior, se observa una mejora significativa en este proceso bajo la técnica de segmentación indicada.

<span id="page-61-0"></span>**Figura 2-21:** Resultado de segmentación a partir de la umbralización de la diferencia de cuadros en canal de color gris realizado al video 72

![](_page_61_Picture_3.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

**Segmentación a partir de la umbralización del cuadro actual en canal de color Z.** La Figura 2-22 muestra el diagrama de flujo asociado a este proceso. Si la imagen resultante no provee una cantidad de píxeles que puedan ser asociados a la descarga ésta no se guarda y se realizan actualizaciones respecto a los datos tanto en cuadros en escala de grises y en el canal de color Z como en histogramas normalizados.

<span id="page-61-1"></span>**Figura 2-22:** Diagrama de flujo de segmentación a partir de la umbralización del cuadro actual en canal de color Z

![](_page_61_Figure_7.jpeg)

Fuente: diseño propio

La imagen (d) de la Figura 2-23 indica el resultado de la segmentación realizada a un fotograma (imagen (a)) del video 18. La imagen (b) se obtuvo a partir de la segmentación descrita en el caso 1 sintonizando C1 a 6 y C2 a 5.5. La imagen (c) se obtuvo a partir de la segmentación basada en la umbralización de la diferencia de cuadros en canal de color Z. Los demás procesos de segmentación no suministran información visual asociada al fenómeno. Se aprecia en la figura lo fundamental de recurrir a diferentes procesos de segmentación a fin de obtener una imagen adecuada de la descarga.

<span id="page-62-0"></span>**Figura 2-23:** Resultado de segmentación a partir de la umbralización del cuadro actual en canal de color Z realizado al video 18

![](_page_62_Figure_3.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

**Cuadros con fondo de media intensidad.** Se presenta cuando las variaciones en el fondo entre los cuadros actual y previo proveen un nivel de intensidad moderado. Igual al caso anterior, la evaluación respecto a la información suministrada por los histogramas de ambos cuadros es utilizada con el objeto de establecer esta característica y realizar la posterior segmentación. La Figura 2-24 muestra el diagrama de flujo respectivo asignando los siguientes valores a los coeficientes: C15 = 0.2, C16 = 0.01, C17 = 0.0012, C18 = 0.0001, C19 = 0.0022, C20 = 0.0004, C21 = 55, C22 = 0.002, C23 = 201.

Este proceso inicia comparando la información obtenida a partir de la suma de los datos del histograma en el rango 230 - 255 del cuadro actual con el coeficiente C15, el cual almacena un valor relacionado a intensidad moderada. Si se establece que en este cuadro no existe este nivel de intensidad se procede a evaluar otros escenarios. De presentarse este nivel de intensidad se evalúan tres situaciones que pueden manifestarse: variaciones de intensidad no significativas entre los cuadros, variaciones de intensidad considerables entre los cuadros y variaciones de intensidad entre los cuadros que pueden deberse al suceso de la descarga.

La verificación respecto a los cambios de intensidad no significativos entre los cuadros se establece bajo cualquiera de las siguientes tres condiciones. La primera es garantizando que el dato del histograma en el nivel de intensidad 255 del cuadro evaluado sea mayor al valor en el coeficiente C16. La segunda corresponde a determinar que la variable db no supere el valor almacenado en el coeficiente C17. La tercera es determinando que la suma de los datos del histograma en el rango 251 - 255 del cuadro actual no esté por encima del valor en el coeficiente C18.

![](_page_63_Figure_2.jpeg)

<span id="page-63-0"></span>**Figura 2-24:** Diagrama de flujo de segmentación en cuadros con fondo de media intensidad

Fuente: diseño propio

De acontecer las dos primeras condiciones no se segmenta el cuadro actual y se realizan actualizaciones respecto a los datos tanto en cuadros en escala de grises y en el canal de color Z como en el vector asociado a histogramas normalizados. Si no suceden estas dos condiciones y se presenta la tercera condición se realiza, adicional a las actualizaciones indicadas, actualización de la información relacionada a la suma de los datos del histograma en el rango de niveles de intensidad 230 – 255.

Si el valor asociado a la suma de los datos del histograma en el rango 251 - 255 del cuadro actual supera el valor almacenado en el coeficiente C19 indica que existen cambios de intensidad considerables entre los cuadros. Esto se debe a objetos con una cantidad considerable de píxeles entre los cuales pueden estar presentes descargas de un grueso considerable y aún no bien definidas respecto a su forma para un posterior procesamiento. A causa de esto no se realiza segmentación en el cuadro actual ni se actualizan tanto los cuadros como los histogramas, por tanto, se procede a leer el siguiente cuadro.

Si el valor asociado a la suma de los datos del histograma en el rango 251 - 255 del cuadro actual se encuentra entre los valores de los coeficientes C18 y C19 se compara la variable db con el valor almacenado en el coeficiente C20 y la variable fb con el valor almacenado en el coeficiente C21. De superar la variable db el valor almacenado en el coeficiente C20 y la variable fb estar por debajo del valor almacenado en el coeficiente C21 se realizan actualizaciones respecto a los datos tanto en cuadros en escala de grises y en el canal de color Z como en histogramas normalizados. En caso contrario se procede a segmentar la imagen, esto como consecuencia a cambios de intensidad entre los cuadros que pueden deberse al suceso de la descarga.

La imagen (f) de la Figura 2-25 indica el resultado de la segmentación realizada a un fotograma (imagen (a)) del video 60. Las imágenes (b) a (e) se obtuvieron a partir de la segmentación descrita en el caso 1 sintonizando C1 a 6 y variando C2 a 5.5, 5, 4.5 y 4 respectivamente. Comparando ambas técnicas se observa que segmentan diferentes píxeles asociados a la descarga, presentando la actualmente descrita, información de niveles más bajos de intensidad lo cual conlleva en algunos casos presencia de ruido en la imagen, tal como se observa además en la Figura 2-26 la cual muestra el resultado de la segmentación de la descarga con esta técnica.

<span id="page-64-0"></span>**Figura 2-25:** Resultado de segmentación en cuadros con fondo de media intensidad realizado al video 60

![](_page_64_Figure_6.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

<span id="page-65-0"></span>**Figura 2-26:** Resultado de segmentación en cuadros con fondo de media intensidad realizado a los videos 47 y 62

![](_page_65_Figure_3.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

**Cuadros con fondo de alta intensidad.** Se presenta cuando las variaciones en el fondo entre los cuadros actual y previo proveen un nivel de intensidad en un rango cercano al de las descargas. Tomando en consideración que los píxeles de la descarga presentan valores de niveles altos de intensidad éstos pueden ser asociados con los píxeles del fondo de la imagen. El confrontar la información suministrada por los histogramas de ambos cuadros provee información respecto al suceso de la descarga, aunque, debido a las características de intensidad previamente indicadas, no constituye un criterio suficientemente robusto para determinar la aplicabilidad de la técnica de umbralización. Se hace necesario implementar un algoritmo de procesamiento de mayor complejidad a fin de segmentar apropiadamente la descarga. La Figura 2-27 muestra el diagrama de flujo respectivo asignando los siguientes valores a los coeficientes: C24 = 6, C25 = 38, C26 = 200, C27 = 1000, C28 = 15, C29 = 0.015, C30 = 0.001, C31 = 0, C32 = 75.

Este proceso inicia verificando que el dato almacenado en la variable fb se encuentre dentro del rango establecido por los coeficientes C24 y C25. Esta comprobación se realiza a fin de determinar si los cuadros previo y actual incluyen información relacionada a niveles altos de intensidad. En caso contrario se procede a evaluar otras condiciones de esta variable con el fin de establecer si se requieren o no realizar actualizaciones respecto a los datos tanto en cuadros en escala de grises y en el canal de color Z como en histogramas normalizados.

De presentarse este nivel de intensidad se convierten ambos cuadros del modelo de color RGB a escala de grises y se procede a evaluar la diferencia entre la información de cada píxel de ambos cuadros a fin de obtener el valor umbral asociado al máximo valor de esta diferencia el cual debe estar localizado en el rango de niveles de intensidad de la descarga. Seguidamente, utilizando el valor umbral se binariza la imagen del cuadro actual bajo la perspectiva del canal Z y se extrae una imagen a partir de una operación AND a nivel de bits entre la imagen binarizada y la imagen asociada a la diferencia de cuadros en escala de grises previamente obtenida. Finalmente, esta última imagen es segmentada y se evalúa la cantidad de píxeles con el objeto de ser considerada como una posible imagen de descarga.

<span id="page-66-0"></span>**Figura 2-27:** Diagrama de flujo de segmentación en cuadros con fondo de alta intensidad

![](_page_66_Figure_4.jpeg)

Fuente: diseño propio

La Figura 2-28 expone el resultado de la segmentación de la descarga con esta técnica. Se observa que el fondo en la imagen (a) provee alta claridad, mientras que la tonalidad de la nube en la imagen (c) es comparable al nivel de intensidad de la descarga. En ambos casos y en videos de descargas con similares características esta técnica es adecuada debido a que permite extraer una cantidad considerable de píxeles asociados al objeto de interés.

<span id="page-67-0"></span>**Figura 2-28:** Resultado de segmentación en cuadros con fondo de alta intensidad realizado a los videos 112 y 113

![](_page_67_Picture_3.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

**Variación de niveles de intensidad evaluados con operaciones aritméticas.** Basado en resultados provistos por las técnicas de segmentación anteriormente descritas se determinó que éstas no siempre entregan información válida respecto al suceso del fenómeno natural. Por tanto, se desarrolló un algoritmo respaldado en operaciones aritméticas realizadas a los cuadros del video que posibilitó segmentar la descarga bajo otras características visuales diferentes a las previamente detalladas, suministrando así mayor robustez al método propuesto.

La Figura 2-29 detalla el diagrama de flujo respectivo asignando los siguientes valores a los coeficientes: C33 = 0.00001, C34 = 0.025. A diferencia de las técnicas previas, los niveles de intensidad de los cuadros a evaluar vistos desde la perspectiva del canal Z se encuentran en el rango de 200 a 255. A continuación, se describen los procesos de segmentación bajo este método los cuales son efectuados de manera secuencial. Si en alguno de estos la imagen resultante no provee una cantidad de píxeles que puedan ser asociados a la descarga ésta no se guarda y se continúa con el siguiente proceso de segmentación.

**Segmentación del cuadro actual en canal de color Z.** Este proceso se realizó utilizando como umbral de segmentación el máximo valor asociado a los datos del histograma normalizado del canal de color Z en el rango 200 a 255 del cuadro actual. La Figura 2-30 muestra el diagrama de flujo respectivo asignando el valor 0.015 al coeficiente C35.

**Segmentación a partir de la diferencia de cuadros en canal de color Z.** Este proceso se realizó utilizando como umbrales de segmentación el máximo valor relacionado a los datos del histograma de la imagen obtenida a partir de la diferencia entre los cuadros actual y previo a la descarga bajo la perspectiva del canal Z. La Figura 2-31 muestra el diagrama de flujo respectivo asignando el valor al coeficiente C36 = 50.

<span id="page-68-0"></span>**Figura 2-29:** Diagrama de flujo de segmentación a partir de la variación de niveles de intensidad evaluados con operaciones aritméticas

![](_page_68_Figure_4.jpeg)

Fuente: diseño propio

<span id="page-68-1"></span>**Figura 2-30:** Diagrama de flujo de segmentación del cuadro actual en canal de color Z

![](_page_68_Figure_7.jpeg)

Fuente: diseño propio

<span id="page-69-0"></span>**Figura 2-31:** Diagrama de flujo de segmentación a partir de la diferencia de cuadros en canal de color Z

Fuente: diseño propio

**Segmentación a partir de la diferencia de cuadros en canal de color gris.** Este proceso se realizó segmentando la diferencia entre los cuadros actual y previo a la descarga bajo la perspectiva del canal gris. La selección de los valores umbrales se realizó de manera experimental. La Figura 2-32 muestra el diagrama de flujo respectivo asignando los siguientes valores a los coeficientes: C37 = 10, C38 = 80.

<span id="page-69-1"></span>**Figura 2-32:** Diagrama de flujo de segmentación a partir de la diferencia de cuadros en canal de color gris

![](_page_69_Figure_7.jpeg)

Fuente: diseño propio

**Segmentación a partir de operación AND entre cuadros en canal de color Z y gris.** Este proceso se realizó segmentando la imagen obtenida mediante la operación AND a nivel de bits entre la imagen umbralizada del cuadro actual en canal de color Z y la imagen relacionada a la diferencia de cuadros en escala de grises. La selección del valor umbral se realizó de manera experimental. La Figura 2-33 muestra el diagrama de flujo respectivo asignando el valor al coeficiente C39 = 15.

<span id="page-70-0"></span>**Figura 2-33:** Diagrama de flujo de segmentación a partir de operación AND entre cuadros en canal de color Z y gris

![](_page_70_Figure_4.jpeg)

Fuente: diseño propio

**Segmentación a partir de la diferencia de histogramas en canal de color Z.** Este proceso inicia con la umbralización del cuadro actual bajo la perspectiva del canal Z utilizando como umbral el máximo valor asociado a la diferencia de los datos de los histogramas normalizados del canal de color Z en el rango 200 a 255. Posteriormente a la imagen obtenida se le realiza una operación AND a nivel de bits con la imagen relacionada a la diferencia de cuadros en escala de grises. Finalmente, esta última imagen es segmentada con un umbral seleccionado de manera experimental. La Figura 2-34 muestra el diagrama de flujo respectivo asignando los siguientes valores a los coeficientes: C40 = 200, C41 = 1000, C42 = 15.

La Figura 2-35 muestra los resultados de la segmentación realizada a un fotograma del video 4. La imagen (b) corresponde a la segmentación del cuadro actual en canal de color Z, en tanto que las imágenes (c) y (d) pertenecen a la segmentación a partir de la diferencia de cuadros en canal de color Z y gris respectivamente. Se observa que el último proceso de segmentación indicado provee mejor eficacia, esto debido a que se utiliza un rango diferencial en escala de grises de niveles bajos de intensidad en el cual se encuentran localizadas descargas tenues u opacas como la indicada en la imagen (a).

<span id="page-71-0"></span>**Figura 2-34:** Diagrama de flujo de segmentación a partir de la diferencia de histogramas en canal de color Z

Fuente: diseño propio

<span id="page-71-1"></span>**Figura 2-35:** Resultado de segmentación a partir de la variación de niveles de intensidad evaluados con operaciones aritméticas realizada al video 4

![](_page_71_Picture_6.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

Esta situación es también visualizada en la Figura 2-36 y Figura 2-37. Las imágenes (f), (g) y (h) de la Figura 2-36 y las imágenes (e), (f) y (g) de la Figura 2-37 presentan el resultado de la segmentación realizada a un fotograma con los métodos basados en el cuadro actual en canal de color Z, y la diferencia de cuadros en canal de color Z y gris respectivamente. Las imágenes (b) a (e) de la Figura 2-36 se obtuvieron a partir de la segmentación descrita en el caso 1 sintonizando C1 a 6 y variando C2 a 5.5, 5, 4.5 y 4 respectivamente. Las imágenes (b) a (d) de la Figura 2-37 se determinaron sintonizando C1 a 4 y variando C2 a 3.3, 2.6 y 2 respectivamente. Se observa una mejora significativa en este proceso bajo la técnica de segmentación indicada.

<span id="page-72-0"></span>**Figura 2-36:** Resultado de segmentación a partir de la variación de niveles de intensidad evaluados con operaciones aritméticas realizada al video 81

![](_page_72_Figure_3.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

<span id="page-72-1"></span>**Figura 2-37:** Resultado de segmentación a partir de la variación de niveles de intensidad evaluados con operaciones aritméticas realizada al video 20

![](_page_72_Figure_6.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

En descargas con mayor luminosidad a la indicada con anterioridad la segmentación a partir de la diferencia de cuadros en canal de color gris no provee resultados. En estos casos los demás métodos descritos suministran información afín acerca de la descarga. Tal situación se observa en la Figura 2-38. La imagen (b) corresponde a la segmentación del cuadro actual en canal de color Z, la imagen (c) pertenece a la segmentación a partir

de la diferencia de cuadros en canal de color Z, las imágenes (d) y (e) hacen referencia a la segmentación a partir de operación AND entre cuadros en canal de color Z y gris y a la segmentación a partir de la diferencia de histogramas en canal de color Z respectivamente. Se observa que todos los métodos proveen resultados aceptables, siendo el último de estos el de mejor eficacia, esto debido a que la segmentación con base en operar en conjunto cuadros tanto en escala de grises como desde la perspectiva del canal Z es más sensible al brillo de la descarga.

<span id="page-73-0"></span>**Figura 2-38:** Resultado de segmentación a partir de la variación de niveles de intensidad evaluados con operaciones aritméticas realizada al video 6

![](_page_73_Figure_4.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

**Invariabilidad en los niveles altos de intensidad en cuadros consecutivos.** Este escenario consiste en determinar si el cuadro del video que se está procesando no presenta cambios significativos respecto a su antecesor en relación a niveles altos de intensidad. Se hace uso de los datos de los histogramas de ambos cuadros previamente adquiridos con el objeto de establecer esta variación, más no se evalúa el valor de cada píxel de las imágenes, por tanto, este proceso demanda menos gasto computacional al no requerir procesar la matriz de datos de ambos cuadros. La Figura 2-39 detalla el diagrama de flujo respectivo asignando el valor al coeficiente C43 = 0.00001.

La invariabilidad respecto a cambios en los niveles altos de intensidad entre los cuadros se establece verificando que se cumpla cualquiera de las siguientes dos condiciones. La primera corresponde a determinar que la diferencia entre los datos de los histogramas de ambos cuadros en el rango de niveles de intensidad 230 – 255 no supere el valor almacenado en el coeficiente C43. La segunda es garantizando que todos los datos del histograma en el rango de niveles de intensidad 200 – 255 del cuadro evaluado sean iguales a cero. Si la invariabilidad persiste no se segmenta el cuadro actual y se realizan actualizaciones respecto a los datos tanto en cuadros en escala de grises y en el canal

de color Z como en histogramas normalizados, de existir variaciones el proceso de segmentación reinicia.

<span id="page-74-0"></span>**Figura 2-39:** Diagrama de flujo de invariabilidad en los niveles altos de intensidad en cuadros consecutivos

![](_page_74_Figure_4.jpeg)

Fuente: diseño propio

Al evaluar la eficiencia del proceso de segmentación propuesto se determinó que funciona adecuadamente en 99 de los 113 videos, equivalente a una precisión del 87.61%. Con el objeto de mejorar este resultado se incorpora la técnica sustracción de fondo la cual permite extraer objetos en movimiento de una secuencia de video adquirido por medio de una cámara estática [106]. Esta técnica se había considerado previamente, aunque no se utilizó inicialmente debido a que sintonizarla demanda el uso de varios cuadros previos y requiere una alta variedad de combinaciones.

A fin de aplicar la opción previamente mencionada, la librería OpenCV provee la función createBackgroundSubtractorMOG2 [107] la cual se basa en el modelo de mezcla gaussiana [106]. La función tiene los siguientes parámetros de entrada: el número de cuadros previos que son utilizados para construir el modelo del fondo; el valor umbral que determina si un píxel está bien descrito por su modelo de fondo; y un indicador que permite establecer si las sombras tienen importancia en la escena. El ajuste de los parámetros indicado en la Tabla 2-3 se realizó buscando segmentar la descarga en los restantes 14 videos en los cuales los procesos de segmentación anteriormente descritos no suministraron resultados aceptables.

<span id="page-75-1"></span>**Tabla 2-3**: Sintonización realizada a la técnica de sustracción de fondo aplicada en videos de descargas

| Sintonización | Número de cuadros previos | Valor umbral | Indicador de sombras |
|---------------|---------------------------|--------------|----------------------|
| 1             | 10                        | 20           | Indiferente (Si/No)  |
| 2             | 10                        | 50           | Indiferente (Si/No)  |
| 3             | 10                        | 1000         | Indiferente (Si/No)  |
| 4             | 25                        | 20           | Indiferente (Si/No)  |

Fuente: diseño propio

La Figura 2-40 muestra el resultado de este proceso realizado a un fotograma del video 31 utilizando la sintonización 1. Este ajuste se utiliza en imágenes con descargas tenues, debido a esta característica se manifiesta ruido en la imagen segmentada. Respecto a esta sintonización el aumento de cuadros previos no provee modificaciones en la imagen segmentada, valores más altos al umbral establecido no permiten segmentar la descarga y valores más bajos segmentan la descarga con la adición de mayor ruido.

<span id="page-75-0"></span>**Figura 2-40:** Resultado de la técnica sustracción de fondo realizada al video 31

![](_page_75_Picture_8.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

La Figura 2-41 detalla el resultado sobre un fotograma del video 28 utilizando la sintonización 2, la cual se ajusta a imágenes con descargas no tan tenues como el caso anterior, por tanto, si bien se presenta ruido éste es menor. Respecto a esta sintonización el aumento de cuadros previos no provee modificaciones en la imagen segmentada y valores más altos o más bajos al umbral establecido no permiten segmentar la descarga.

La imagen (a) en la Figura 2-42 corresponde al fotograma previo a la descarga (imagen (c)) en el video 57. Con el objeto de realizar la segmentación se utiliza la sintonización 3

la cual aplica en imágenes con descargas que proveen mayor luminosidad. Esta característica puede causar que otros objetos presentes como es el caso de la nube también aumenten el nivel de intensidad y por tanto no sea segmentada. Respecto a la sintonización el aumento de cuadros previos segmenta la descarga con la adición de mayor ruido y valores más bajos al umbral establecido no permiten segmentarla. Debido a la alta cantidad de píxeles en la imagen resultante los procesos anteriormente descritos no proveen información en relación al suceso de la descarga.

<span id="page-76-0"></span>**Figura 2-41:** Resultado de la técnica sustracción de fondo realizada al video 28

![](_page_76_Picture_4.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

<span id="page-76-1"></span>**Figura 2-42:** Resultado de la técnica sustracción de fondo realizada al video 57

![](_page_76_Picture_7.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

Existen escenarios en los que la baja tonalidad de la descarga hace que las sintonizaciones 1 y 2 no provean resultados válidos. En estos casos se hace uso de la sintonización 4. La Figura 2-43 muestra la segmentación realizada a un fotograma del video 56. Respecto a esta sintonización una menor cantidad de cuadros previos y valores más altos al umbral establecido no permiten segmentar la descarga.

<span id="page-76-2"></span>**Figura 2-43:** Resultado de la técnica sustracción de fondo realizada al video 56

![](_page_76_Picture_11.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

Adicionando la técnica sustracción de fondo a los procesos anteriormente descritos, la descarga se segmentó adecuadamente en 108 de los 113 videos. Por tanto, la precisión incrementó a 95.57%.

#### <span id="page-77-0"></span>**2.2.3 Representación y descripción de imágenes de descargas**

Una vez las imágenes son segmentadas, éstas son representadas y descritas. El proceso de descripción caracteriza la región segmentada basada en su representación [104]. Debido a que las imágenes resultantes están binarizadas, éstas son representadas en función de propiedades externas basadas en contornos y en internas relacionadas a la cantidad de píxeles de los objetos segmentados. Los descriptores son métricas que permiten extraer información discriminatoria provista en un vector de características con el fin de especificar el objeto.

Como se ha observado en las figuras relacionadas al proceso de segmentación, el resultado de esta etapa suministra imágenes que contienen únicamente información de la descarga, o información de ruido, o una mezcla de ambos elementos. Con el propósito de diferenciar estos conjuntos se realizó manualmente una clasificación en dos clases: imágenes positivas (descargas) e imágenes negativas (otros objetos). A las imágenes con descarga y ruido se le eliminó el ruido para clasificarlas en la clase positiva y se les suprimió la descarga con el objeto de categorizarlas como negativas. De esta forma se obtuvieron 633 imágenes positivas y 10054 imágenes negativas. La Figura 2-44 indica ejemplos de imágenes negativas.

<span id="page-77-1"></span>**Figura 2-44:** Ejemplos de objetos segmentados no relacionados a descargas eléctricas atmosféricas

![](_page_77_Picture_7.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

Las imágenes una vez clasificadas fueron visualmente analizadas con el objeto de establecer los descriptores a utilizar. Un conjunto significativo de imágenes de descargas posee una geometría delgada, elongada y curvilínea, aunque también existe un grupo de descargas de menor tamaño. Por otro lado, las imágenes negativas están divididas en aquellas con una cantidad de píxeles inferior a la descarga, otras con características similares al último grupo de descargas mencionadas y otras con formas diversas y diferentes a la geometría de las descargas. Basado en este análisis se seleccionaron los siguientes seis descriptores [108]:

Área (A). Se determina a partir del número de píxeles al interior del contorno del objeto.

**Perímetro** (*P*). Corresponde a la longitud del contorno del objeto.

**Elongación** ( $\varepsilon$ ). También conocido como excentricidad, es una medida respecto a que tan alargado puede ser un contorno. Se puede calcular a partir de los momentos del contorno. Los momentos corresponden a características calculadas a partir de contornos que permiten una reconstrucción geométrica del objeto.

$$\varepsilon = \sqrt{1 - \frac{\frac{(mu_{20} + mu_{02})}{2} - \sqrt{\frac{4.mu_{11}^2 + (mu_{20} - mu_{02})^2}{2}}}{\frac{(mu_{20} + mu_{02})}{2} + \sqrt{\frac{4.mu_{11}^2 + (mu_{20} - mu_{02})^2}{2}}}}$$
(2.3)

#### Donde:

 $mu_{ji}$  son momentos centrales usados con el fin de reconocer una imagen independientemente de su forma y ubicación en un eje de coordenadas, obtenidos a partir de:

$$mu_{ji} = \sum_{x,y} (f(x,y).(x-\bar{x})^{j}.(y-\bar{y})^{i})$$
 (2.4)

#### Donde:

(x, y) son las coordenadas del píxel.

f(x,y) es el valor del píxel.

 $(\bar{x}, \bar{y})$  es el centroide o centro de masas, el cual se obtiene a partir de los momentos espaciales de orden 1 y de orden 0.

$$\bar{x} = \frac{m_{10}}{m_{00}} \tag{2.5}$$

$$\bar{y} = \frac{m_{01}}{m_{00}} \tag{2.6}$$

Donde:

 $m_{ii}$  se obtienen a partir de:

$$m_{ii} = \sum_{x,y} \left( f(x,y) \cdot x^j \cdot y^i \right) \tag{2.7}$$

El centroide de una figura viene determinado por las coordenadas (x, y) de forma que el área de la figura que queda a la derecha e izquierda del punto x es la misma, al igual que el área que queda por encima y por debajo del punto y.

**Redondez** (k). Medida relacionada a que tan cerca un contorno se acerca al contorno de un círculo perfecto.

$$k = \frac{P^2}{4.4.\pi} \tag{2.8}$$

Relación de aspecto (r). Relación entre el ancho (w) y la altura (h) del rectángulo delimitador del contorno.

$$r = \frac{w}{h} \tag{2.9}$$

**Curvatura total** (*c*). Se establece mediante la sumatoria de los cambios de orientación en la trayectoria del contorno.

La librería OpenCV provee la función findContours [109] con el fin de determinar el contorno de una región y diversas funciones que permiten establecer algunos de los descriptores requeridos. Cada descriptor fue aplicado en la clase positiva, de esta forma se obtuvieron seis vectores de características de descargas. La Tabla 2-4 indica los valores normalizados mínimo y máximo de cada métrica.

Posteriormente, a cada vector se le amplió el rango 10% tanto por encima como por debajo con el fin de utilizar estos nuevos rangos como información discriminatoria en la aplicación de los descriptores en la clase negativa. Una vez evaluados los descriptores,

se redujo la cantidad de imágenes negativas a 1443. La Figura 2-45 muestra la respuesta de los descriptores relacionados uno con respecto a otro, los puntos en color azul corresponden a la clase positiva, los de color rojo a la clase negativa.

<span id="page-80-0"></span>**Tabla 2-4**: Valores mínimo y máximo de descriptores aplicados en descargas eléctricas atmosféricas

| Descriptor          | Valor mínimo    | Valor máximo |
|---------------------|-----------------|--------------|
| Área                | 6.5104x10-6     | 0.02351      |
| Perímetro           | 0.0001299       | 0.01145      |
| Elongación          | 0.3093          | 1.0818       |
| Redondez            | x10-5<br>1.3754 | 0.003066     |
| Relación de aspecto | 0.07359         | 7.6666       |
| Curvatura total     | 7               | 1056         |

Fuente: diseño propio

Se observa en la gráfica Perímetro y Área que, si bien el vector área asociado a los elementos de ambas clases recorre prácticamente todo el rango, existe una diferencia visual en los vectores perímetro, los objetos positivos por lo general tienen un perímetro mayor que los objetos negativos, esto se debe a que la forma de un conjunto de elementos no asociados a descargas tiende a ser circular, en tanto las descargas poseen una geometría tendiente a rectangular, por tanto, en el caso de áreas similares entre ambas clases el perímetro será menor en la negativa. Estas dos características son también visibles en las demás gráficas que las relacionan con otros descriptores.

Además, se observa que la elongación, al ser una característica afín a las descargas, por lo general provee valores más altos en comparación con los demás objetos. No así la relación de aspecto, ya que suministra valores más bajos en elementos con forma rectangular la cual puede estar asociada a la morfología de las descargas.

Respecto a la redondez, varias descargas no son lo suficientemente alargadas y existen elementos en la clase negativa que también conservan esta propiedad, debido a esto la diferencia entre ambas es levemente distante. De manera similar sucede con la curvatura total que es por lo general ligeramente mayor en la clase positiva.

<span id="page-81-0"></span>**Figura 2-45:** Resultado de los descriptores

![](_page_81_Figure_3.jpeg)

![](_page_82_Figure_2.jpeg)

**Figura 2-45:** Resultado de los descriptores (Continuación)

Fuente: imagen obtenida mediante código implementado en Python

Debido a que la información asociada a los descriptores no provee una diferencia destacada que permita separar ambas clases, se procedió a utilizar un clasificador basado en máquina de vectores de soporte [110]. Inicialmente, empleando la librería csv [111] se creó un archivo con el objeto de almacenar las etiquetas, los vectores de los descriptores y la clase respectiva. Una vez creado el archivo éste es leído para llevar a cabo el entrenamiento haciendo uso de diversas funciones kernel provistas por la librería scikit-learn [112]. Se empleó el 20% de los datos como prueba de verificación de la eficiencia. Los resultados obtenidos del entrenamiento son descritos en la Tabla 2-5 basados en la matriz de confusión y con las métricas de evaluación Precision, Recall y F1-score [113].

<span id="page-83-0"></span>**Tabla 2-5**: Resultado de la máquina de vectores de soporte

| Kernel       | TP  | TN  | FP | FN  | Clase | Precision | Recall | F1-   |
|--------------|-----|-----|----|-----|-------|-----------|--------|-------|
|              |     |     |    |     |       | (%)       | (%)    | score |
|              |     |     |    |     |       |           |        | (%)   |
| Lineal       | 111 | 293 | 6  | 6   | 1     | 95        | 95     | 95    |
|              |     |     |    |     | 0     | 98        | 98     | 98    |
| Polinómico   | 14  | 289 | 6  | 107 | 1     | 70        | 12     | 20    |
|              |     |     |    |     | 0     | 73        | 98     | 84    |
| Gaussiano de | 110 | 291 | 4  | 11  | 1     | 96        | 91     | 94    |
| base radial  |     |     |    |     | 0     | 96        | 99     | 97    |
| Sigmoidal    | 63  | 232 | 63 | 58  | 1     | 50        | 52     | 51    |
|              |     |     |    |     | 0     | 80        | 79     | 79    |

Fuente: diseño propio

**Abreviaturas:**

TP: verdadero positivo TN: verdadero negativo FP: falso positivo FN: falso negativo

**Notas:**

Clase 1: imágenes positivas Clase 0: imágenes negativas

De acuerdo a los resultados se observa que los kernel lineal y gaussiano de base radial proveen una mejor eficacia. Aunque la función gaussiana presenta menor cantidad de falsos positivos, la selección se realiza con base en los falsos negativos debido a que corresponden a la no detección de la descarga, por tanto, se hace uso del kernel lineal, es decir se ponderan las situaciones en las cuales el sistema puede cometer errores

identificando erróneamente un objeto como descarga, sobre aquellas en las que una descarga real deja de ser detectada. Por último, utilizando la librería joblib [114], el resultado del clasificador es guardado.

#### <span id="page-84-0"></span>**2.2.4 Detección de la descarga**

A cada fotograma de video de descarga se le realiza el proceso de segmentación utilizando las técnicas previamente descritas. Si el algoritmo provee una imagen segmentada ésta es evaluada por el clasificador lineal. La detección de la descarga se realiza si el clasificador indica la existencia de ésta en la imagen. De darse esta situación la imagen es almacenada y el proceso reinicia con el siguiente fotograma. En caso contrario se continúa con la siguiente técnica de segmentación. La Figura 2-46 muestra ejemplos de la detección de la descarga resaltando su contorno en color verde.

<span id="page-84-1"></span>**Figura 2-46:** Ejemplos de detección de descarga eléctrica atmosférica

Fuente: imagen obtenida mediante código implementado en Python

Previamente se indicó que el proceso de segmentación se estableció buscando menores pérdidas en fotogramas con información visual de descargas a costa de un incremento en fotogramas con objetos segmentados asociados a ruido. Con el propósito de validar esta afirmación se realizó, a partir del uso de la matriz de confusión, la evaluación de la eficiencia en la detección de la descarga, con y sin la inclusión de la técnica sustracción de fondo. La Tabla 2-6 muestra los resultados.

Debido a que el interés en detectar el suceso de la descarga se relaciona en causar un disparo que permita grabar un video con el fin de almacenar el fenómeno natural y aunque la exactitud, precisión y especificidad mejoran haciendo uso de todas las técnicas de segmentación sin tener en cuenta la técnica sustracción de fondo, la selección de la técnica se establece buscando un compromiso entre la detección del evento (sensibilidad) y el ruido previo a la detección que, de acuerdo a la Tabla 2-6 corresponde a R1. Por tanto, los ruidos presentes durante (R2) y posteriores (R3) a la detección no son considerados según el criterio establecido.

<span id="page-85-1"></span>**Tabla 2-6**: Resultado en la detección de la descarga de acuerdo a la técnica utilizada

| T  | TP  | TN | FP | FN | Exactitud | Precisión | Sensibilidad | Especificidad | R1      | R2      | R3      |
|----|-----|----|----|----|-----------|-----------|--------------|---------------|---------|---------|---------|
|    |     |    |    |    | (%)       | (%)       | (%)          | (%)           | (%)     | (%)     | (%)     |
| T1 | 106 | 64 | 49 | 7  | 75.2212   | 68.3870   | 93.8053      | 56.6371       | 12.3894 | 29.2035 | 17.6991 |
| T2 | 99  | 91 | 22 | 14 | 84.0707   | 81.8181   | 87.6106      | 80.5309       | 7.9646  | 9.7345  | 9.7345  |

Fuente: diseño propio

#### **Abreviaturas:**

T: técnica

T1: todas las técnicas de segmentación

T2: todas las técnicas de segmentación excluyendo la técnica sustracción de fondo

TP: verdadero positivo TN: verdadero negativo FP: falso positivo

FN: falso negativo

R1: ruido en fotogramas previos a la detección de la descarga

R2: ruido en algunos fotogramas relacionados a la detección de la descarga

R3: ruido en fotogramas posteriores a la detección de la descarga

De acuerdo a los resultados, el incremento en la detección haciendo uso de ambos procesos corresponde a 6.1947% frente a un incremento de ruido previo de 4.4248%. Como el porcentaje de incremento en la detección es mayor al porcentaje de incremento en ruido previo se considera inicialmente hacer uso de todas las técnicas de segmentación con el fin de determinar la eficiencia en tiempo real de la metodología propuesta, los resultados obtenidos se exponen en el Capítulo 4.

## <span id="page-85-0"></span>**2.3 Identificación de descargas utilizando visión computacional**

Otras técnicas utilizadas en la tarea de reconocimiento se basaron en la exploración de algoritmos de aprendizaje profundo (red neuronal convolucional) pertenecientes al área de visión artificial, que tuvieron por objeto extraer de cada fotograma de videos de descargas características que permitieran realizar la respectiva clasificación. La Figura 2- 47 detalla la arquitectura de aprendizaje profundo enfocada en la aplicación descrita.

<span id="page-86-0"></span>**Figura 2-47:** Arquitectura de red neuronal convolucional

Fuente: diseño propio

Actualmente, se han venido desarrollando diversos modelos de aprendizaje profundo con el objeto de mejorar el desempeño en el proceso de reconocimiento. En este trabajo se exploraron tres modelos de redes neuronales supervisadas: ResNet-50 [115], EfficientNetB4 y EfficientNetB7 [116]. Estos modelos se seleccionaron debido a que, comparado con modelos precedentes, proveen un mejor rendimiento [115], [116]. Cada modelo se entrenó con el framework TensorFlow [117], esto demandó hacer uso de tres conjuntos de datos y la sintonización de tres parámetros:

**Conjunto de imágenes de entrenamiento (training dataset)**, utilizadas en el proceso de aprendizaje de la red.

**Conjunto de imágenes de validación (validation dataset)**, utilizadas con el objeto de validar el modelo durante el entrenamiento.

**Conjunto de imágenes de prueba (test dataset)**, utilizadas en la evaluación del desempeño del modelo posterior al entrenamiento.

**Tasa de aprendizaje (learning rate)**, parámetro que establece el tamaño de paso en cada iteración en el proceso de entrenamiento.

**Tamaño de lote (batch size)**, parámetro asociado a la cantidad de muestras de entrenamiento utilizadas en una iteración.

**Épocas (Epoch)**, parámetro relacionado al número de veces que el algoritmo recorre todo el conjunto de imágenes de entrenamiento.

Se utilizaron dos conjuntos de datos de clasificación en el proceso de entrenamiento, uno correspondiente a 556 imágenes de descargas (positivas) y otro con una cantidad igual de imágenes relacionadas a escenarios donde pueden hacer presencia las descargas (negativas). Ambos conjuntos fueron construidos a partir de imágenes con una resolución espacial diversa obtenidas de los bancos de videos libres previamente indicados en este capítulo. La Figura 2-48 muestra ejemplos de imágenes positivas, en tanto que la Figura 2-49 indica ejemplos de imágenes negativas.

<span id="page-87-0"></span>**Figura 2-48:** Ejemplos de imágenes positivas utilizadas en el proceso de aprendizaje de la red

![](_page_87_Picture_4.jpeg)

Fuente: diseño propio

<span id="page-87-1"></span>**Figura 2-49:** Ejemplos de imágenes negativas utilizadas en el proceso de aprendizaje de la red

![](_page_87_Picture_7.jpeg)

Fuente: diseño propio

A fin de establecer el modelo apropiado en el reconocimiento de la descarga se aplicó un método exploratorio. En todos los entrenamientos se utilizó el 75% del total de imágenes como conjunto de imágenes de entrenamiento, de éstas el 10% se emplearon en el proceso de validación. El 25% restante se destinaron con el objeto de llevar a cabo las pruebas del modelo. Inicialmente, se realizaron tres entrenamientos con los tres modelos anteriormente indicados con igual sintonización de los parámetros. Cada modelo entrenado se evaluó en algunos de los videos de descargas descritos con anterioridad suministrando resultados inadecuados en relación a su reconocimiento. Buscando este objetivo se efectuaron un total de 35 entrenamientos. La Tabla 2-7 indica el ajuste realizado a cada modelo y los resultados obtenidos en la evaluación de éstos en el video 8.

<span id="page-88-0"></span>**Tabla 2-7**: Sintonización de los parámetros de modelos de redes neuronales convolucionales seleccionados y evaluación de éstos en el proceso de clasificación de las descargas en el video 8

| Modelo red     | Tasa de     | Tamaño  | Número |                | Valor porcentual de |
|----------------|-------------|---------|--------|----------------|---------------------|
| neuronal       | aprendizaje | de lote | de     | reconocimiento | de la descarga      |
| convolucional  |             |         | épocas | En cuadros     | En cuadros sin      |
|                |             |         |        | con descarga   | descarga            |
|                | 1e-2        | 16      | 20     | 100            | 100                 |
|                | 1e-3        | 16      | 20     | 99             | 97 –<br>99          |
|                | 1e-3        | 32      | 20     | 99             | 94 –<br>97          |
|                | 1e-3        | 64      | 20     | 99             | 95 –<br>98          |
|                | 1e-3        | 128     | 20     | 99             | 96 –<br>98          |
|                | 1e-3        | 16      | 50     | 99             | 99                  |
|                | 1e-3        | 16      | 100    | 99<br>–<br>100 | 99                  |
| ResNet-50      | 1e-3        | 16      | 200    | 100            | 99<br>–<br>100      |
|                | 1e-4        | 16      | 20     | 98 –<br>99     | 90 –<br>95          |
|                | 1e-4        | 32      | 20     | 95 –<br>98     | 84<br>–<br>90       |
|                | 1e-4        | 64      | 20     | 96 –<br>98     | 96 –<br>98          |
|                | 1e-4        | 128     | 20     | 92 –<br>96     | 79<br>–<br>83       |
|                | 1e-4        | 32      | 50     | 99             | 97 –<br>98          |
|                | 1e-4        | 32      | 100    | 99             | 99                  |
|                | 1e-5        | 16      | 20     | 93 –<br>94     | 87<br>–<br>91       |
|                | 1e-6        | 16      | 20     | 53<br>–<br>70  | 69<br>–<br>73       |
|                | 1e-3        | 16      | 20     | 95 –<br>99     | 83<br>–<br>90       |
|                | 1e-3        | 32      | 20     | 89<br>–<br>98  | 80<br>–<br>89       |
|                | 1e-3        | 64      | 20     | 95 –<br>99     | 83<br>–<br>90       |
| EfficientNetB4 | 1e-3        | 128     | 20     | 89<br>–<br>96  | 72<br>–<br>83       |
|                | 1e-3        | 32      | 50     | 99             | 98 –<br>99          |
|                | 1e-3        | 32      | 100    | 89<br>–<br>99  | 82 –<br>93          |
|                | 1e-4        | 16      | 20     | 89<br>–<br>97  | 81<br>–<br>87       |

**Tabla 2-7**: Sintonización de los parámetros de modelos de redes neuronales convolucionales seleccionados y evaluación de éstos en el proceso de clasificación de las descargas en el video 8 (Continuación)

| Modelo red     | Tasa de     | Tamaño  | Número | Valor porcentual de           |                |
|----------------|-------------|---------|--------|-------------------------------|----------------|
| neuronal       | aprendizaje | de lote | de     | reconocimiento de la descarga |                |
| convolucional  |             |         | épocas | En cuadros                    | En cuadros sin |
|                |             |         |        | con descarga                  | descarga       |
|                | 1e-4        | 32      | 20     | 87 –<br>94                    | 70<br>–<br>75  |
| EfficientNetB4 | 1e-4        | 64      | 20     | 87<br>–<br>93                 | 78<br>–<br>83  |
|                | 1e-4        | 128     | 20     | 90 –<br>96                    | 81<br>–<br>83  |
|                | 1e-3        | 16      | 20     | 99 –<br>100                   | 99             |
|                | 1e-3        | 32      | 20     | 99                            | 95 –<br>97     |
|                | 1e-3        | 64      | 20     | 97 –<br>99                    | 91 –<br>92     |
|                | 1e-3        | 32      | 50     | 99                            | 99             |
| EfficientNetB7 | 1e-3        | 32      | 100    | 99 –<br>100                   | 99             |
|                | 1e-4        | 16      | 20     | 96 –<br>99                    | 93 –<br>94     |
|                | 1e-4        | 32      | 20     | 91 –<br>99                    | 86<br>–<br>88  |
|                | 1e-4        | 64      | 20     | 92 –<br>99                    | 88<br>–<br>89  |
|                | 1e-4        | 64      | 50     | 95 –<br>99                    | 90 –<br>91     |

Fuente: diseño propio

De acuerdo a los valores porcentuales al reconocimiento indicados en la Tabla 2-7 se deduce que todos los modelos clasifican como descarga todos los cuadros no asociados al fenómeno natural. Al analizar otros videos se observa que en la mayoría de éstos los resultados descritos en la Tabla 2.7 son similares en relación a la diferencia porcentual entre cuadros con y sin descarga. Los valores altos en cuadros sin descargas provistos por cada modelo entrenado pueden deberse al bajo número de imágenes utilizadas en el entrenamiento, a que la descarga provee una tonalidad de alta uniformidad y al ser delgada posee un reducido número de píxeles en comparación con el total de la imagen, por tanto, pueden presentarse limitaciones respecto a la extracción de características durante el entrenamiento que generen complejidad en el proceso de clasificación.

Debido a los resultados obtenidos, el criterio utilizado en la selección del modelo se basó en aquel que suministró en la mayor cantidad de videos analizados una diferencia considerable entre los valores porcentuales de reconocimiento entre ambas clases. Este análisis indicó que diversos entrenamientos con tasas de aprendizaje inicial de 1e-2 y 1e-3 y número de épocas iguales a 20 suministraron diferencias mayores a 5% entre fotogramas con descargas y sin descargas. Al seleccionar los modelos con estos parámetros sintonizados a estos valores y evaluándose en otros videos se determinó que la red neuronal EfficientNetB4 con una tasa de aprendizaje de 1e-3 , tamaño de lote de 64 y número de épocas igual a 20 es la que provee mejor diferenciación entre ambas clases. Los resultados obtenidos en el entrenamiento de este modelo son descritos en la Tabla 2-8 basados en las métricas de evaluación Precision, Recall y F1-score, en tanto que la Figura 2-50 describe de forma gráfica la evolución en el entrenamiento de este modelo.

<span id="page-90-1"></span>**Tabla 2-8**: Resultado del modelo EfficientNetB4

| Clase       | Precision (%) | Recall (%) | F1-score (%) |
|-------------|---------------|------------|--------------|
| Descarga    | 95            | 91         | 93           |
| No descarga | 91            | 95         | 93           |

Fuente: diseño propio

<span id="page-90-0"></span>**Figura 2-50:** Resultado del entrenamiento con el modelo EfficientNetB4 en cada época

![](_page_90_Figure_7.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

Como ejemplo gráfico, la Figura 2-51 muestra los valores porcentuales de reconocimiento provistos por el modelo seleccionado en cada fotograma del video 25. Se observa que este video es fraccionado en 120 fotogramas. La descarga en este video se presenta en los fotogramas 65 a 68 con un valor porcentual de reconocimiento entre 96.88% y 99.59%. En los restantes fotogramas este valor se encuentra ubicado por debajo de 88.15%.

Una vez cargado el modelo entrenado de la red neuronal EfficientNetB4 en diversos videos y analizando la respuesta gráfica tal como la indicada en la Figura 2-51, se determinó que no existe un único valor porcentual de reconocimiento que establezca el instante en que la descarga está localizada en el fotograma. Como se ha indicado anteriormente, se presentan en un conjunto amplio de videos diferencias de valores entre ambas clases, aunque para diversos rangos en cada clase, posiblemente debido a que las características de luminosidad previas y durante la descarga generan al modelo de la red neuronal inconsistencias en el proceso de reconocimiento.

<span id="page-91-0"></span>**Figura 2-51:** Valores porcentuales de reconocimiento provistos por el modelo EfficientNetB4 en el video 25

![](_page_91_Figure_5.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

Por tanto, el algoritmo implementado se basó inicialmente en distinguir las características de luminosidad del entorno donde posiblemente se presente la descarga a partir de la evaluación del promedio relacionado al valor porcentual de reconocimiento de los cinco primeros fotogramas del video, garantizando que en estos fotogramas iniciales no se encuentre la descarga. Con el objeto de establecer si la descarga se presenta en algún fotograma, cada valor promedio obtenido es evaluado simultáneamente con el valor porcentual de reconocimiento del fotograma analizado. La Figura 2-52 muestra el diagrama de flujo de este proceso, asignando los valores a los coeficientes C44 = 95, C45 = 98, C46 = 80, C47 = 75, C48 = 92, C49 = 88.

<span id="page-92-0"></span>**Figura 2-52:** Diagrama de flujo de reconocimiento de la descarga a partir del modelo EfficientNetB4

![](_page_92_Figure_4.jpeg)

Fuente: diseño propio

Por último, haciendo uso de la matriz de confusión se evaluó en los 113 videos el desempeño del modelo de red neuronal EfficientNetB4 seleccionado. La Tabla 2-9 describe los resultados. Los valores indicados en la Tabla 2-9 se deben a que el modelo entrenado provee información errónea en el reconocimiento debido a la cantidad de diferentes objetos en diversos cuadros que son reconocidos como descargas. Al analizar el resultado provisto por el modelo entrenado en cada video se determinó una mejora en el desempeño en 75 de los 83 videos propios. Si bien, estos videos proveen cuadros con tonalidades diversas en su fondo, dos características que los distinguen de los demás

videos y de las imágenes utilizadas en el proceso de entrenamiento es la relación de aspecto y el uso de una sola cámara en el proceso de adquisición. La relación de aspecto de estos videos propios es 16:3, mientras que en las imágenes utilizadas en el proceso de entrenamiento la más cercana, que aun así dista de ésta, es 16:9. La Tabla 2-10 describe los resultados del modelo en estos videos.

<span id="page-93-0"></span>**Tabla 2-9**: Resultado en el reconocimiento de la descarga utilizando la red neuronal EfficientNetB4

| TP  | TN | FP | FN | Exactitud (%) | Precisión (%) | Sensibilidad (%) | Especificidad (%) |
|-----|----|----|----|---------------|---------------|------------------|-------------------|
| 101 | 73 | 40 | 12 | 76.9911       | 71.6312       | 89.3805          | 64.6017           |

Fuente: diseño propio

**Abreviaturas:**

TP: verdadero positivo TN: verdadero negativo FP: falso positivo FN: falso negativo

<span id="page-93-1"></span>**Tabla 2-10**: Resultado en el reconocimiento de la descarga en videos propios utilizando la red neuronal EfficientNetB4

| TP | TN | FP | FN | Exactitud (%) | Precisión (%) | Sensibilidad (%) | Especificidad (%) |
|----|----|----|----|---------------|---------------|------------------|-------------------|
| 64 | 66 | 9  | 11 | 86.6666       | 87.6712       | 85.3333          | 88.3333           |

Fuente: diseño propio

**Abreviaturas:**

TP: verdadero positivo TN: verdadero negativo FP: falso positivo FN: falso negativo

Respecto a los resultados provistos en la Tabla 2-10 y a lo enunciado con anterioridad se infiere que el hacer uso de este modelo entrenado como parte de una técnica en el proceso de detección dependerá más de la parametrización realizada al elemento sensor que de las condiciones previamente definidas en relación al campo visual.

# <span id="page-94-0"></span>**3.Propuesta metodológica en la caracterización de la multiplicidad**

La multiplicidad corresponde al número de descargas subsecuentes, las cuales en general no proveen ramificaciones y que en su mayoría se desarrollan sobre la trayectoria del canal ionizado creado por la primera descarga de retorno [1]. De acuerdo a la literatura revisada el intervalo de tiempo filmado entre descargas subsecuentes se encuentra entre 14 ms y 446 ms [12], [13], [49], [15], [18]–[21], [30], [37], [42]. Lo anterior implica que, con el objeto de hacer una captura apropiada de un fenómeno de multiplicidad de descargas, es necesario un periodo de muestreo, o tiempo entre fotogramas. Se cuenta con 12 videos de prueba que cumplen con esta característica temporal debido a que fueron adquiridos con un tiempo entre fotogramas consecutivos de 0.22273 ms, por tanto, estos videos son empleados en la adecuación del algoritmo que permite determinar la multiplicidad.

La Figura 3-1 detalla el diagrama de flujo correspondiente haciendo uso del coeficiente C35 igual a 0.015 previamente establecido en el proceso de identificación de la descarga y asignando a los coeficientes C50, C51 y C52 los valores 0.003, 50 y 2010 respectivamente. Este proceso comienza con la inicialización de las siguientes variables en cero:

n: variable que almacena el número de canales de descarga que pueden estar presentes en un video.

d\_seg: vector que almacena los datos asociados a las imágenes segmentadas del canal de descarga.

d\_x: vector que almacena los números de cada fotograma asociado a la imagen segmentada de cada canal de descarga.

d\_y: vector que almacena el número de píxeles de cada imagen segmentada asociada a cada canal de descarga.

x: vector que almacena los números de cada fotograma asociado a descargas subsecuentes presentes en cada canal de descarga.

y: vector que almacena valores iguales a uno los cuales representan las descargas subsecuentes presentes en cada canal de descarga.

m: variable que almacena el número de descargas subsecuentes de cada canal de descarga.

<span id="page-95-0"></span>**Figura 3-1:** Diagrama de flujo asociado al proceso de caracterización de la multiplicidad

![](_page_95_Figure_7.jpeg)

Fuente: diseño propio

Posterior a la inicialización de las variables se hace lectura de cada video fraccionándolo en fotogramas. A cada fotograma se le realiza el proceso de identificación de la descarga utilizando las técnicas de procesamiento de imágenes descritas en la sección 2.2. Si se detectan objetos en los fotogramas clasificados como descargas y si la cantidad de píxeles de los objetos no supera el valor almacenado en el coeficiente C35 se continua con el proceso. En caso contrario, se realiza nuevamente la identificación de la descarga a cada fotograma y su respectiva evaluación hasta completar la lectura del video.

La información de la imagen segmentada asociada al primer fotograma caracterizado como descarga, así como los datos respecto al número de este fotograma y la cantidad de píxeles de los objetos segmentados en esta imagen son almacenados en las variables respectivas. Posteriormente una operación AND es realizada con las siguientes imágenes segmentadas y la imagen segmentada previamente almacenada con el propósito de establecer si cada objeto segmentado está asociado a ruido o a un canal de descarga. La cantidad de píxeles de las imágenes resultantes son evaluadas con el coeficiente C50 con el fin de asociar los objetos segmentados y categorizados como descargas a cada canal de descarga respectivo.

Una vez evaluados todos los fotogramas y obtenidos los canales de descarga se determina la multiplicidad en cada canal evaluando el tiempo transcurrido entre las imágenes segmentadas adquiridas. Teniendo en cuenta que cada fotograma se adquirió cada 0.22273 ms y que de acuerdo a la literatura el tiempo entre descargas subsecuentes se encuentra entre 14 ms y 446 ms, el rango de fotogramas consecutivos entre descargas subsecuentes se determinó así:

$$\frac{TMNDS}{TMV} \le FDS \le \frac{TMXDS}{TMV} \tag{3.1}$$

#### Donde:

: valor de fotogramas consecutivos entre descargas subsecuentes

: tiempo mínimo entre descargas subsecuentes : tiempo máximo entre descargas subsecuentes

: periodo de muestreo del video

Reemplazando los valores en la Ecuación 3.1 se tiene:

$$\frac{14 \, ms}{0.22273 \, ms} \le FDS \le \frac{446 \, ms}{0.22273 \, ms}$$

$$62.9 \le FDS \le 2002.4$$

Este resultado indica que aquellas imágenes con objetos categorizados como descargas pertenecientes a un idéntico canal y acontecidas en un tiempo relacionado a este intervalo de fotogramas consecutivos corresponden a diferentes descargas subsecuentes. Con el objeto de establecer un margen que minimice la posibilidad de datos erróneos en la medición de esta característica se sintonizan empíricamente a 50 (coeficiente C51) y 2010 (coeficiente C52) los valores mínimo y máximo de fotogramas consecutivos entre descargas subsecuentes respectivamente. Con este ajuste el rango de tiempo entre descargas subsecuentes queda fijado entre 11.1365 ms y 447.68 ms.

La Figura 3-2 indica gráficamente los resultados obtenidos de este proceso en uno de los videos. Las imágenes (a) y (b) muestran los dos canales de descarga presentes en este video. Las imágenes (c) y (d) detallan la distribución de los fotogramas correspondientes a los objetos segmentados y categorizados como descargas en cada canal. En tanto que las imágenes (e) y (f) especifican la correspondiente multiplicidad.

La Tabla 3-1 resume los resultados obtenidos en el proceso de caracterización de la multiplicidad en cada uno de los 12 videos. En ocho de estos videos el algoritmo propuesto funciona adecuadamente, por tanto, la precisión es 66.66%. En dos videos el método implementado no provee el número exacto de descargas subsecuentes debido a que algunas descargas tienen niveles de luminosidad tenues, por tanto, las técnicas propuestas de identificación de descargas no suministran información relacionada al suceso del evento. Por último, en los restantes dos videos se presenta ruido debido a la alta luminosidad de la escena, el cual el algoritmo lo asocia como descarga.

El método propuesto que se ha descrito respecto a la caracterización de la multiplicidad es dependiente de la previa identificación del canal de descarga la cual está detallada en el Capítulo 2. Este proceso de identificación demandó una exploración exhaustiva y la aplicación de diversas técnicas de segmentación, además de un análisis morfológico de la descarga con el fin de establecer los descriptores que permitieron especificarla. Por tanto, el hacer uso de este procedimiento si bien, en situaciones puntuales trajo consigo errores en la cantidad inexacta de descargas subsecuentes ya sea por la no identificación del evento, o porque en otros casos algunos objetos por su luminosidad y morfología fueron categorizados como descargas, tuvo como ventaja que facilitó el desarrollo de la propuesta metodológica presentada.

<span id="page-98-0"></span>**Figura 3-2:** Representación gráfica asociada al proceso de caracterización de la multiplicidad

![](_page_98_Figure_4.jpeg)

Fuente: gráficas obtenidas mediante código implementado en Python

<span id="page-99-0"></span>**Tabla 3-1**: Resultados obtenidos en el proceso de caracterización de la multiplicidad

| Video | Canales de | Descargas    | Observaciones                                                                          |  |  |
|-------|------------|--------------|----------------------------------------------------------------------------------------|--|--|
|       | descargas  | subsecuentes |                                                                                        |  |  |
| 1     | 1          | 2            | Ninguna                                                                                |  |  |
| 2     | 1          | 4            | Ninguna                                                                                |  |  |
| 3     | 2          | 5, 1         | Ninguna                                                                                |  |  |
| 4     | 1          | 6            | Dos descargas subsecuentes no son identificadas                                        |  |  |
| 5     | 2          | 4, 1         | Ninguna                                                                                |  |  |
| 6     | 2          | 5, 1         | Ninguna                                                                                |  |  |
| 7     | 1          | 9            | Ocho<br>descargas subsecuentes no son identificadas                                    |  |  |
| 8     | 1          | 4            | Ninguna                                                                                |  |  |
| 9     | 1          | 7            | Presencia de ruido en imágenes no correspondientes al<br>canal de descarga             |  |  |
| 10    | 1          | 11           | Presencia de ruido en imágenes asociadas y no<br>correspondientes al canal de descarga |  |  |
| 11    | 1          | 12           | Ninguna                                                                                |  |  |
| 12    | 1          | 10           | Ninguna                                                                                |  |  |

Fuente: diseño propio

# <span id="page-100-0"></span>**4.Implementación en tiempo real de la solución propuesta para la detección de descargas eléctricas atmosféricas**

Las descargas eléctricas atmosféricas son fenómenos naturales que se originan bajo ciertas condiciones climáticas presentes en temporadas de lluvias y específicamente en tormentas eléctricas. En una ubicación geográfica como la colombiana estos eventos suceden ocasionalmente en temporadas específicas del año suscitando que existan limitaciones temporales para llevar a cabo pruebas de desempeño de las técnicas de detección propuestas. Además, debido a los múltiples confinamientos de la pandemia COVID-19 designadas por el gobierno Nacional, Departamental, Municipal y las instancias universitarias, y acatando las normas de bioseguridad, no se ha tenido acceso permanente al campus universitario con el fin de realizar tanto reuniones presenciales con el director y codirector de la presente tesis como el efectuar actividades prácticas investigativas y pruebas funcionales con equipos y dispositivos ubicados en la Universidad, los cuales son requeridos en la ejecución del proyecto. Por tanto, la implementación y evaluación del sistema en tiempo real en el proceso de detección de la descarga se realizó haciendo uso de una cámara de video conectada a una plataforma de procesamiento y orientada a un monitor con despliegue de videos del fenómeno.

Si bien las pruebas se realizaron bajo este enfoque, el diseño del sistema propuesto está constituido por una plataforma de procesamiento y dos cámaras de video. El diagrama del sistema se muestra en la Figura 4-1. La plataforma de procesamiento contiene los códigos asociados a las técnicas de detección y se comunica con una cámara de video que cumple con los requisitos técnicos de conexionado, esta parte del sistema constituye el sensado visual de la descarga. La otra cámara tiene como característica grabar el video a alta velocidad ubicando en cada cuadro la respectiva marca temporal. Esto

asegura por tanto almacenar una cantidad considerable de información visual de la descarga con registro en tiempo real.

<span id="page-101-1"></span>**Figura 4-1:** Diagrama del sistema propuesto

Fuente: diseño propio

En el instante en que una descarga es detectada la plataforma de procesamiento provee un disparo a la cámara de video de alta velocidad la cual se configura con el objeto de grabar el video haciendo uso de un buffer circular. Esta estructura de grabación garantiza que no existan pérdidas en la información visual de la descarga ya que se almacenan cuadros de video antes, durante y posterior al fenómeno.

### <span id="page-101-0"></span>**4.1 Características de los equipos**

Como se ha descrito en el Capítulo 2 las técnicas propuestas con el objeto de llevar a cabo la detección de la descarga se implementaron haciendo uso del lenguaje de programación Python. Al ser Python un lenguaje de código abierto permite ser instalado sin costo para su uso en diversos sistemas operativos entre los que se encuentran Windows, Linux/Unix y Mac OS [118]. Además, los programas escritos en Python pueden ser ejecutados en diversas placas de desarrollo de código abierto como lo son Raspberry Pi [119], Jetson Nano [120], Google Coral [121] y Orange Pi [122]. La evaluación respecto al desempeño de las técnicas de detección en tiempo real se realizó haciendo uso de dos plataformas, a continuación, se describen los equipos que hacen parte del sistema propuesto.

#### <span id="page-102-0"></span>**4.1.1 Plataforma de procesamiento**

Para las pruebas reportadas en este capítulo, dos opciones de plataforma de procesamiento fueron utilizadas en el proceso de detección de la descarga: una computadora personal y un ordenador de placa reducida.

**Computadora personal.** Con sistema operativo Windows 10; procesador referencia Intel Core I7-5557U a una frecuencia de procesamiento de 3.10GHz; memoria RAM de 16 GB.

**Ordenador de placa reducida.** Correspondiente a Raspberry Pi 3 modelo B+ con sistema operativo Raspberry Pi OS (previamente llamado Raspbian). Algunas de las especificaciones de este ordenador son: procesador referencia Broadcom BCM2837B0 con arquitectura Cortex-A53 de 64 bits a una frecuencia de procesamiento de 1.4 GHz; memoria LPDDR2 SDRAM de 1 GB; 40 pines de entrada/salida de propósito general; puerto con interfaz serial CSI para conectividad de cámara de video; fuente de alimentación requerida 5V/2.5A DC [123].

<span id="page-102-1"></span>![](_page_102_Picture_7.jpeg)

**Figura 4-2:** Raspberry Pi 3 modelo B+

Fuente: extraído de [https://static.raspberrypi.org/files/product](https://static.raspberrypi.org/files/product-briefs/200206+Raspberry+Pi+3+Model+B+plus+Product+Brief+PRINT&DIGITAL.pdf)[briefs/200206+Raspberry+Pi+3+Model+B+plus+Product+Brief+PRINT&DIGITAL.pdf](https://static.raspberrypi.org/files/product-briefs/200206+Raspberry+Pi+3+Model+B+plus+Product+Brief+PRINT&DIGITAL.pdf)

#### <span id="page-103-0"></span>**4.1.2 Cámara de video en el proceso de detección**

Se emplearon dos cámaras de video en este proceso: una cámara web y un módulo Pi Camera v2.

**Cámara web.** Referencia Genius FaceCam 310. Algunas de las especificaciones de esta cámara son: conectividad alámbrica por puerto USB; sensor de imagen CMOS; formato de video digital WMV; máxima resolución 640 x 480; captura de video a 30 fps con resoluciones 640 x 480 y 352 x 288; ajuste focal manual [124]. La cámara web se utilizó únicamente con la computadora personal en el proceso de detección de la descarga.

<span id="page-103-1"></span>**Figura 4-3:** Cámara web Genius FaceCam 310

![](_page_103_Picture_6.jpeg)

Fuente: extraído de

[https://www.nodevice.es/static/device\\_images/o/fb2/5d5/fb25d50d4cf6a5ba787ad9d0](https://www.nodevice.es/static/device_images/o/fb2/5d5/fb25d50d4cf6a5ba787ad9d0db5ff7cd33a4a9b5.jpg) [db5ff7cd33a4a9b5.jpg](https://www.nodevice.es/static/device_images/o/fb2/5d5/fb25d50d4cf6a5ba787ad9d0db5ff7cd33a4a9b5.jpg)

**Módulo Pi Camera v2.** Algunas de las especificaciones de esta cámara son: conectividad por puerto serial CSI con Raspberry Pi; sensor referencia Sony IMX219; resolución de 8 MP; captura de video a 30 fps con resolución 1080p, 60 fps con resolución 720p y 90 fps con resolución 640 x 480 [125]. El módulo Pi Camera v2 se utilizó únicamente con el ordenador de placa reducida en el proceso de detección de la descarga.

<span id="page-103-2"></span>**Figura 4-4:** Módulo Pi Camera v2

![](_page_103_Picture_11.jpeg)

Fuente: extraído de<https://www.raspberrypi.org/products/camera-module-v2/>

#### <span id="page-104-0"></span>**4.1.3 Cámara de video de alta velocidad**

La referencia de la cámara de video de alta velocidad corresponde a la Chronos 1.4 fabricada por Kron Technologies Inc. Algunas de las especificaciones de esta cámara son: sensor de imagen global shutter electrónico; formatos de video H.264 y CinemaDNG Raw; captura de video a 1069 fps con resolución 1280 x 1024; tiempo de grabación a 4, 8 y 16 segundos; dos entradas de disparo, disparo con umbral de entrada ajustable entre 0V y 6.6V, entrada auxiliar de disparo aislado eléctricamente; grabación de video en buffer circular; fuente de alimentación requerida 17-20V 40W DC [126].

<span id="page-104-2"></span>**Figura 4-5:** Cámara de video de alta velocidad Chronos 1.4

![](_page_104_Picture_5.jpeg)

Fuente: extraído de [https://www.krontech.ca/store/Chronos-1-4-high-speed-camera](https://www.krontech.ca/store/Chronos-1-4-high-speed-camera-p92268927)[p92268927](https://www.krontech.ca/store/Chronos-1-4-high-speed-camera-p92268927)

A continuación, se describen los resultados obtenidos en el proceso de detección en tiempo real de la descarga haciendo uso de las dos plataformas de procesamiento. Este proceso se realizó a partir de 20 videos de descargas adquiridos de la Internet [94] desplegados en un monitor. En los casos expuestos se utilizaron todas las técnicas de detección propuestas sin la inclusión de la técnica sustracción de fondo debido a que las pruebas realizadas con esta técnica indicaron la presencia de ruido persistente.

### <span id="page-104-1"></span>**4.2 Detección en tiempo real de descargas utilizando técnicas de procesamiento de imágenes y computadora personal**

Inicialmente, la evaluación respecto a la identificación de la descarga se realizó utilizando la cámara web conectada al computador personal. Las pruebas de desempeño realizadas haciendo uso de este sistema de detección suministraron una cantidad considerable de cuadros de video con detecciones equivocadas de descargas. Estos resultados pueden deberse a tres características: La primera está relacionada a las especificaciones técnicas del sensor de imagen de la cámara de video condicionando a que las imágenes adquiridas sean de baja calidad, la segunda característica está asociada a las propiedades de iluminación provistas por el monitor que despliega los videos y la tercera es debida al ángulo que resulta de la ubicación del monitor con respecto a la cámara de video.

Bajo las situaciones anteriormente indicadas se obtuvieron a partir de los 20 videos 578 cuadros con objetos clasificados por el sistema de detección como descargas con un porcentaje significativo de cuadros con elementos incorrectamente categorizados al fenómeno. La Figura 4-6 muestra diferentes ejemplos relacionados a la respuesta del sistema de detección, se observa que si bien la descarga es correctamente aislada se presenta un ruido significativo en el proceso de segmentación.

<span id="page-105-0"></span>**Figura 4-6:** Ejemplos de detección en tiempo real de descargas utilizando técnicas de procesamiento de imágenes y computadora personal

![](_page_105_Figure_5.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

La Figura 4-7 detalla cuadros de videos con elementos negativos identificados como descargas. Debido a la limitada sensibilidad a la luz que provee la cámara se presenta ocasionalmente alta saturación en las imágenes adquiridas. Esta particularidad genera que la eficiencia del proceso de segmentación disminuya presentando por consiguiente un incremento considerable de ruido que a su vez puede hacer que el método basado en el descriptor propuesto genere resultados erróneos, al clasificar dicho ruido como descarga.

<span id="page-106-0"></span>**Figura 4-7:** Ejemplos de objetos negativos detectados en tiempo real como descargas utilizando técnicas de procesamiento de imágenes y computadora personal

![](_page_106_Figure_4.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

La Tabla 4-1 provee los resultados haciendo uso de la matriz de confusión en la detección de la descarga con el sistema descrito. Los valores indicados respecto a la precisión, exactitud, sensibilidad y especificidad se deben a que, si bien el sistema determinó correctamente el fenómeno en los 20 videos, categorizó además objetos negativos como descargas en todos los videos, esto debido a las características previamente indicadas del sistema de detección.

<span id="page-107-1"></span>**Tabla 4-1**: Resultado en la detección en tiempo real de descargas utilizando técnicas de procesamiento de imágenes y computadora personal

| TP | TN | FP | FN | Exactitud (%) | Precisión (%) | Sensibilidad (%) | Especificidad (%) |
|----|----|----|----|---------------|---------------|------------------|-------------------|
| 20 | 0  | 20 | 0  | 50.0000       | 50.0000       | 100.0000         | 0.0000            |

Fuente: diseño propio

**Abreviaturas:**

TP: verdadero positivo TN: verdadero negativo FP: falso positivo FN: falso negativo

De acuerdo a las pruebas realizadas el tiempo máximo que requiere el sistema en realizar la detección utilizando las técnicas de procesamiento de imágenes es 476 ms, mientras que el tiempo promedio corresponde a 85 ms. De acuerdo a la literatura revisada el tiempo de duración de las descargas se encuentra entre 180.8 ms y 1500 ms [14], [15], [44], [49], [18], [20]–[22], [30], [38], [39], [42]. Debido a que el tiempo máximo se ubica en el rango indicado y el tiempo promedio por debajo del mínimo valor del rango, haciendo uso de este sistema no debería presentarse una cantidad significativa de cuadros que no pudieran ser analizados, reduciendo la probabilidad de imprecisiones en el proceso de identificación. La Tabla 4-2 suministra la información indicada.

<span id="page-107-2"></span>**Tabla 4-2**: Tiempo de cómputo en la detección en tiempo real de descargas utilizando técnicas de procesamiento de imágenes y computadora personal

| N   | Tmin (s)   | Tmax<br>(s) | Tprom<br>(s) |
|-----|------------|-------------|--------------|
| 578 | 0.00652242 | 0.47610712  | 0.08509775   |

Fuente: diseño propio

#### **Abreviaturas:**

N: número de imágenes con objetos identificados como descargas

Tmin: tiempo de cómputo mínimo en la detección de objetos asociados a descargas Tmax: tiempo de cómputo máximo en la detección de objetos asociados a descargas Tprom: tiempo de cómputo promedio en la detección de objetos asociados a descargas

### <span id="page-107-0"></span>**4.3 Detección en tiempo real de descargas utilizando visión artificial y computadora personal**

De forma similar al sistema de detección anteriormente descrito los resultados obtenidos con este arreglo suministraron, aunque en una cantidad menor, un porcentaje significativo en la caracterización de objetos negativos como descargas. Además, en algunas de las pruebas realizadas, la red neuronal convolucional no proporcionó información certera respecto al reconocimiento del fenómeno. La respuesta de este sistema como se ha indicado previamente es dependiente de las características de la cámara de video y la adecuación del proceso de sensado, así como del número de ejemplos y la sintonización de los parámetros requeridos en el proceso de entrenamiento de la red.

En los 20 videos utilizados con el objeto de llevar a cabo las pruebas de desempeño el sistema suministró correcta e incorrectamente un total de 163 cuadros con reconocimiento de la descarga. La Figura 4-8 muestra cuadros con la descarga adecuadamente identificada mediante este método.

<span id="page-108-0"></span>**Figura 4-8:** Ejemplos de detección en tiempo real de descargas utilizando visión artificial y computadora personal

![](_page_108_Picture_5.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

La técnica por otro lado clasifica erróneamente diversos cuadros con elementos de alta luminosidad como imágenes con descargas. Ejemplos relacionados a esta particularidad son observados en la Figura 4-9.

La Tabla 4-3 indica los resultados utilizando la matriz de confusión en el reconocimiento de la descarga con el sistema basado en redes neuronales. Se observa que este modelo computacional en comparación al método anteriormente descrito no identifica la descarga en todas las pruebas realizadas, por tanto, los valores de exactitud, precisión y sensibilidad son menores. El incremento en el valor de la especificidad está relacionado a que el sistema en algunos casos indicó correctamente el no suceso del fenómeno.

<span id="page-109-0"></span>**Figura 4-9:** Ejemplos de imágenes negativas clasificadas en tiempo real como descargas utilizando visión artificial y computadora personal

![](_page_109_Picture_3.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

<span id="page-109-1"></span>**Tabla 4-3**: Resultado en la detección en tiempo real de descargas utilizando visión artificial y computadora personal

| TP | TN | FP | FN | Exactitud (%) | Precisión (%) | Sensibilidad (%) | Especificidad (%) |
|----|----|----|----|---------------|---------------|------------------|-------------------|
| 15 | 3  | 17 | 5  | 45.0000       | 46.8750       | 75.0000          | 15.0000           |

Fuente: diseño propio

**Abreviaturas:**

TP: verdadero positivo TN: verdadero negativo FP: falso positivo FN: falso negativo

La Tabla 4-4 detalla los tiempos mínimo, máximo y promedio que demanda la técnica basada en redes neuronales convolucionales en realizar el reconocimiento. El valor promedio corresponde a 212 ms el cual es más elevado al tiempo mínimo de duración de la descarga (180.8 ms), por tanto, comparado con el sistema de detección previamente descrito es posible que una cantidad mayor de cuadros no sean analizados aumentando la probabilidad de equivocaciones por parte del sistema de reconocimiento.

<span id="page-109-2"></span>**Tabla 4-4**: Tiempo de cómputo en la detección en tiempo real de descargas utilizando visión artificial y computadora personal

| N   | Tmin (s)  | Tmax<br>(s) | Tprom<br>(s) |
|-----|-----------|-------------|--------------|
| 163 | 0.1536262 | 0.36779141  | 0.21208135   |

Fuente: diseño propio

**Abreviaturas:**

N: número de imágenes con objetos identificados como descargas

Tmin: tiempo de cómputo mínimo en la detección de objetos asociados a descargas Tmax: tiempo de cómputo máximo en la detección de objetos asociados a descargas Tprom: tiempo de cómputo promedio en la detección de objetos asociados a descargas Teniendo en cuenta que el reconocimiento de la descarga bajo este modelo provee mayor imprecisión y además demanda más tiempo de cómputo en comparación con las técnicas de procesamiento de imágenes, ocasionando que probablemente una cantidad mayor de cuadros no sean examinados, este método de detección no es implementado en el ordenador de placa reducida.

### <span id="page-110-0"></span>**4.4 Detección en tiempo real de descargas utilizando técnicas de procesamiento de imágenes y ordenador de placa reducida**

La configuración de este sistema de detección lo conforman el módulo Pi Camera v2 conectado a la tarjeta de desarrollo Raspberry Pi 3 modelo B+. De acuerdo a las especificaciones técnicas del sensor de imagen y a las pruebas de desempeño realizadas, esta cámara provee cuadros de video de mejor calidad en comparación con la cámara web, por otra parte, la placa utilizada posee una rapidez de procesamiento menor que la computadora personal. Debido a estas dos características y con el objeto de verificar en tiempo real la funcionalidad de las técnicas de procesamiento tanto individual como conjuntamente, se desarrolló un menú que le permite al usuario seleccionar el método de detección a utilizar. Basado en esto, y de acuerdo a los procesos de segmentación de las descargas descritos en el Capítulo 2, las técnicas a seleccionar por el usuario son las siguientes:

Técnica 1 (T1): variación de niveles de intensidad evaluados en la diferencia de cuadros consecutivos.

Técnica 2 (T2): cuadros con fondo de diferente intensidad.

Técnica 3 (T3): variación de niveles de intensidad evaluados con operaciones aritméticas.

La Figura 4-10 muestra diferentes ejemplos relacionados a la respuesta del sistema en condiciones acertadas de detección. Comparando visualmente el desempeño de esta configuración con el sistema conformado por la computadora personal y la cámara web se observa un decremento en el nivel de ruido presente en las imágenes asociadas al proceso de segmentación, permitiendo al descriptor evaluar una menor cantidad de objetos segmentados y por consiguiente la probabilidad de disminuir la imprecisión en relación a la clasificación de las descargas.

<span id="page-111-0"></span>**Figura 4-10:** Ejemplos de detección en tiempo real de descargas utilizando técnicas de procesamiento de imágenes y ordenador de placa reducida

![](_page_111_Picture_4.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

La Figura 4-11 suministra cuadros de videos con objetos negativos identificados como descargas. En comparación con el sistema configurado por la computadora personal y la cámara web se observa la no presencia de niveles altos de brillo en las imágenes adquiridas, por tanto, se obtiene una menor cantidad de cuadros con información erróneamente clasificada.

La Tabla 4-5 provee los resultados haciendo uso de la matriz de confusión en la detección de la descarga con el sistema descrito. Los resultados son presentados con las técnicas de procesamiento evaluadas tanto individual como conjuntamente. Se observa que empleando únicamente la técnica T1 no se caracterizan objetos negativos como descargas, por tanto, la precisión y la especificidad se ubican en el máximo valor, sin embargo, una limitada cantidad de descargas es identificada condicionando a que el sistema provea baja exactitud y sensibilidad, de acuerdo a estos resultados el utilizar individualmente esta técnica no garantiza un óptimo desempeño.

<span id="page-112-0"></span>**Figura 4-11:** Ejemplos de objetos negativos detectados en tiempo real como descargas utilizando técnicas de procesamiento de imágenes y ordenador de placa reducida

![](_page_112_Figure_4.jpeg)

Fuente: imagen obtenida mediante código implementado en Python

Las técnicas T2 y T3 evaluadas individualmente proveen entre ellas iguales resultados. Aunque ambas técnicas indican una baja cantidad de objetos negativos clasificados como descargas, se observa una mejora significativa en la correcta detección del fenómeno en comparación con la técnica T1.

Las pruebas realizadas indican que evaluar conjuntamente las técnicas mejora el desempeño del sistema en relación a un incremento de objetos clasificados correctamente como descargas, sin embargo, exceptuando la combinación de las técnicas T1 y T2, se presenta un incremento en la cantidad de objetos negativos erróneamente clasificados.

El objetivo de llevar a cabo estas pruebas es seleccionar un método de detección que suministre la menor pérdida en la correcta identificación a costa de una cantidad baja de objetos negativos categorizados como descargas. Basado en este criterio, si bien, la combinación de las técnicas T1 y T2 provee mejores resultados respecto a exactitud y precisión, el unificar en el método de detección las tres técnicas proporciona una mayor probabilidad en la consecución del objetivo planteado.

<span id="page-113-0"></span>**Tabla 4-5**: Resultado en la detección en tiempo real de descargas utilizando técnicas de procesamiento de imágenes y ordenador de placa reducida

| T          | TP | TN | FP | FN | Exactitud (%) | Precisión (%) | Sensibilidad (%) | Especificidad (%) |
|------------|----|----|----|----|---------------|---------------|------------------|-------------------|
| T1         | 3  | 20 | 0  | 17 | 57.5000       | 100.0000      | 15.0000          | 100.0000          |
| T2         | 17 | 18 | 2  | 3  | 87.5000       | 89.4736       | 85.0000          | 90.0000           |
| T3         | 17 | 18 | 2  | 3  | 87.5000       | 89.4736       | 85.0000          | 90.0000           |
| T1, T2     | 19 | 19 | 1  | 1  | 95.0000       | 95.0000       | 95.0000          | 95.0000           |
| T1, T3     | 18 | 17 | 3  | 2  | 87.5000       | 85.7142       | 90.0000          | 85.0000           |
| T2, T3     | 20 | 16 | 4  | 0  | 90.0000       | 83.3333       | 100.0000         | 80.0000           |
| T1, T2, T3 | 20 | 17 | 3  | 0  | 92.5000       | 86.9565       | 100.0000         | 85.0000           |

Fuente: diseño propio

#### **Abreviaturas:**

T: técnica

T1: variación de niveles de intensidad evaluados en la diferencia de cuadros consecutivos

T2: cuadros con fondo de diferente intensidad

T3: variación de niveles de intensidad evaluados con operaciones aritméticas

TP: verdadero positivo TN: verdadero negativo FP: falso positivo

FN: falso negativo

La Tabla 4-6 indica los tiempos mínimo, máximo y promedio necesarios para que la Raspberry Pi 3 modelo B+ realice el proceso de detección basado en las técnicas de procesamiento de imágenes evaluadas tanto individual como conjuntamente. Entre todos los valores indicados el tiempo máximo es 475 ms correspondiente a las técnicas T2 y T3 evaluadas unificadamente, mientras que el tiempo promedio más elevado equivale a 126 ms el cual es provisto por la evaluación sincrónica de las técnicas T1 y T3. Previamente se había enunciado que de acuerdo a la literatura revisada la descarga mínimamente tiene un tiempo de duración de 180 ms, por tanto, tal como se describió en el proceso de detección haciendo uso de la computadora personal y de estas técnicas, no debería presentarse una cantidad significativa de cuadros que no pudieran ser analizados, reduciendo la probabilidad de imprecisiones en el proceso de identificación.

<span id="page-114-0"></span>**Tabla 4-6**: Tiempo de cómputo en la detección en tiempo real de descargas utilizando técnicas de procesamiento de imágenes y ordenador de placa reducida

| T          | N  | Tmin (s)   | Tmax<br>(s) | Tprom<br>(s) |
|------------|----|------------|-------------|--------------|
| T1         | 5  | 0.04970455 | 0.11238861  | 0.066294     |
| T2         | 34 | 0.03792572 | 0.41931701  | 0.08660563   |
| T3         | 26 | 0.04761362 | 0.2076211   | 0.10349356   |
| T1, T2     | 35 | 0.02931666 | 0.25806952  | 0.09047196   |
| T1, T3     | 32 | 0.03379631 | 0.24665427  | 0.12650969   |
| T2, T3     | 46 | 0.02931476 | 0.47555065  | 0.09555794   |
| T1, T2, T3 | 40 | 0.03519034 | 0.45993495  | 0.11948896   |

Fuente: diseño propio

#### **Abreviaturas:**

T: técnica

T1: variación de niveles de intensidad evaluados en la diferencia de cuadros consecutivos

T2: cuadros con fondo de diferente intensidad

T3: variación de niveles de intensidad evaluados con operaciones aritméticas

N: número de imágenes con objetos identificados como descargas

Tmin: tiempo de cómputo mínimo en la detección de objetos asociados a descargas Tmax: tiempo de cómputo máximo en la detección de objetos asociados a descargas

Tprom: tiempo de cómputo promedio en la detección de objetos asociados a descargas

De acuerdo a los resultados obtenidos con las pruebas realizadas a los tres sistemas se establece que el llevar a cabo la detección en tiempo real de las descargas utilizando las técnicas de procesamiento de imágenes implementadas en la Raspberry Pi 3 modelo B+ y haciendo uso del módulo Pi Camera v2 provee un mejor desempeño. Además, al ser utilizadas las tres técnicas de detección de manera secuencial con este sistema afianza el objetivo requerido. Adicionalmente, el utilizar un ordenador de placa reducida como la Raspberry Pi 3 modelo B+ a diferencia de una computadora personal, posibilita movilizar los elementos de forma más cómoda y garantiza que el montaje del sistema ocupe un menor espacio.

Los tiempos que demandan el despliegue de las imágenes correspondientes a cada etapa como lo son el cuadro a procesar, la imagen segmentada y la imagen de salida con el objeto segmentado, resaltado y categorizado como descarga en el caso del uso de las técnicas de procesamiento de imágenes y en la imagen resultante del proceso de reconocimiento a partir de redes neuronales, no se tuvieron en cuenta en los tiempos de procesamiento indicados en cada caso de detección expuesto. La presentación de estas imágenes se realizó antes de evaluar el siguiente cuadro del video, por tanto, el tiempo requerido en el despliegue de las imágenes probablemente interfiere con el tiempo mínimo que cada sistema exige entre lecturas de cuadros. De haber acontecido esta situación posiblemente algunos cuadros no se analizaron suscitando imprecisiones en el proceso de detección.

En el procedimiento que se ha descrito las imágenes requerían ser desplegadas con el objeto de evaluar visualmente cada proceso, sin embargo, al implementar el sistema no es preciso presentar las imágenes ya que solamente es necesario determinar el suceso del evento y generar el disparo a la cámara de alta velocidad.

Lo anterior implica que los desempeños registrados a lo largo del presente capítulo son correctos, ya que no es necesario desplegar visualmente las imágenes segmentadas para hacer la detección. La visualización de los eventos detectados podría implementarse o habilitarse como una característica opcional en la aplicación final, teniendo en cuenta que dicha visualización reduce el desempeño del procesamiento de los datos y puede llevar a que se pierdan algunos eventos.

## <span id="page-116-0"></span>**5.Conclusiones y recomendaciones**

### <span id="page-116-1"></span>**5.1 Conclusiones**

Se ha establecido a partir de la literatura la importancia que proveen los videos adquiridos con cámaras de alta velocidad en los procesos de análisis y caracterización de las descargas eléctricas atmosféricas. En la literatura consultada no se encontró referentes que indicaran que esta herramienta visual haya sido utilizada como dispositivo de sensado, ya que como lo han expresado los autores en [22], [63] el disparo que suministra el inicio de la adquisición de la información visual lo provee un observador, por tanto, este proceso es realizado de forma manual. Con el desarrollo de este trabajo se buscó solventar este inconveniente, es debido a esto que la investigación se enfocó en proponer una metodología para la detección de descargas utilizando técnicas de procesamiento de señales y algoritmos de visión computacional con la finalidad de poder prescindir del observador en la ejecución de esta tarea, posibilitando que el disparo lo provea de manera automática el sistema en el instante en que éste reconozca visualmente el fenómeno natural.

En relación a los videos de descargas utilizados en la adecuación de las técnicas de detección alojados en diversos bancos, no se obtuvo información respecto a las características de la cámara y su configuración. Este desconocimiento no generó inconvenientes al hacer uso de estos videos, justificado en parte por las afirmaciones provistas por los autores en [19], [20], [22] que indican que la sintonización del parámetro correspondiente a la resolución espacial no necesariamente debe ser aquella que provea detalles finos en la imagen.

Al realizar el análisis de los espacios de color en imágenes de descargas se determinó que el componente Z del modelo de color XYZ fue el que suministró una mayor cantidad de píxeles a niveles altos de intensidad asociados al fenómeno natural. Sin embargo, los niveles de intensidad de la descarga provistos por éste y los demás componentes varían en relación a las características de luminosidad del entorno donde acontece el fenómeno, generando por tanto que exista incertidumbre en la selección de un valor específico de umbral para llevar a cabo el proceso de segmentación. No obstante, al ser el componente Z el más sensible ante el suceso de la descarga, éste se seleccionó como base en la tarea de establecer las técnicas de detección.

Es inadecuado hacer uso de técnicas basadas en detección de bordes aplicadas en el proceso de segmentación de las descargas. Estos métodos tienen una alta probabilidad que funcionen adecuadamente en imágenes con fondo uniforme, sin embargo, proveen una cantidad considerable de ruido en imágenes con fondos heterogéneos.

Debido a que las imágenes de descargas proveen variabilidad en los niveles de intensidad, el proceso de segmentación demandó la adecuación de diversas técnicas, las cuales fueron nombradas en el presente trabajo como: variación de niveles de intensidad evaluados en la diferencia de cuadros consecutivos (T1), cuadros con fondo de diferente intensidad (T2) y variación de niveles de intensidad evaluados con operaciones aritméticas (T3). Al evaluar globalmente el desempeño de las tres técnicas se obtuvo una precisión en el proceso de segmentación del 87.61%.

Adicional a las técnicas previamente mencionadas se incorporó la técnica sustracción de fondo con el fin de establecer la posibilidad de mejorar la eficiencia en el proceso de segmentación de las descargas. Si bien la precisión incrementó a 95.57% se determinó que esta técnica provee dos desventajas, la primera está relacionada a que la sintonización de este método de segmentación requirió como mínimo 10 cuadros previos, en comparación con las otras técnicas que necesitan únicamente un cuadro previo, esto por tanto representa un mayor tiempo de procesamiento. El segundo inconveniente está relacionado a que esta técnica provee un alto número de objetos segmentados no asociados a descargas ocasionando que la tarea posterior correspondiente al descriptor tenga una alta probabilidad de clasificar erróneamente objetos negativos como descargas. A raíz de lo descrito, esta técnica no se adecuó en el sistema de detección propuesto.

El hacer uso de descriptores ajustados con seis métricas correspondientes a área, perímetro, elongación, redondez, relación de aspecto y curvatura total, permitió que una cantidad significativa de objetos segmentados con características morfológicas opuestas a una geometría delgada, elongada y curvilínea que están asociadas a las descargas fueran descartadas, por tanto, estos elementos no fueron utilizados en el proceso de clasificación.

Al analizar las gráficas provistas por los descriptores se estableció que para efectos de separar ambas clases (descargas y no descargas) se requirió hacer uso de un clasificador basado en máquina de vectores de soporte. Los resultados del clasificador indicaron que los kernel lineal y la función gaussiana de base radial suministraron un mejor desempeño. La selección del kernel se realizó basado en aquel que suministrara una cantidad menor de falsos negativos con el fin de garantizar menores pérdidas en el proceso de detección, basado en este criterio se seleccionó el kernel lineal.

El ajuste del sistema de detección de descargas propuesto incluyó el uso de métodos basados en procesamiento de imágenes y herramientas de visión computacional. Ambos métodos se evaluaron en condiciones fuera de línea y en tiempo real. Fuera de línea las técnicas basadas en procesamiento de imágenes suministraron una precisión del 81.81%, mientras que haciendo uso de visión computacional la precisión fue de 71.63%. Debido a que el algoritmo de visión computacional demandó un tiempo de procesado que probablemente ocasione pérdidas en el análisis de cuadros, éste no se adecuó en el ordenador de placa reducida. En este ordenador las técnicas basadas en procesamiento de imágenes suministraron una precisión de 86.95% en la detección de las descargas.

De acuerdo a la literatura revisada el intervalo de tiempo entre descargas es de 14 ms a 446 ms [12], [13], [49], [15], [18]–[21], [30], [37], [42]. Debido a que es un rango de tiempo de corta duración, los autores en [20] sugieren sintonizar la tasa de muestreo de las cámaras en el proceso de adquisición igual o superior a 1000 fps con el objeto de minimizar la probabilidad de pérdidas de descargas subsecuentes. Las cámaras utilizadas en el proceso de detección de la descarga permiten ser sintonizadas a una tasa de muestreo máxima de 90 fps (módulo Pi Camera v2). A raíz de esto y en vista que la cámara empleada en el proceso de grabación de la descarga posibilita configurarse a

una tasa de muestreo igual o superior a 1000 fps, la evaluación de la multiplicidad se realizó en una medición fuera de línea con los videos provistos por esta cámara.

### <span id="page-119-0"></span>**5.2 Recomendaciones**

Con el propósito de realizar la identificación de un objeto especifico a partir de técnicas de procesamiento de imágenes, es recomendable verificar inicialmente la respuesta del histograma de cada uno de los canales de color. Este proceso permite seleccionar el canal de color más adecuado de forma tal que aislar el objeto de interés del fondo de la imagen probablemente requiera el desarrollo de un algoritmo de menor complejidad. Normalmente los procedimientos encontrados en la literatura respecto a métodos de procesamiento aplicados a la identificación de objetos parten de una imagen en escala de grises, que en ocasiones no permite discriminar suficientemente los objetos de interés demandando por tanto el uso de una mayor cantidad de técnicas y a su vez un mayor tiempo de procesamiento por parte del sistema de cómputo.

La evaluación realizada en tiempo real con el objeto de establecer el desempeño de las técnicas de detección propuestas hizo uso de una cámara de video conectada a una plataforma de procesamiento y orientada a un monitor con despliegue de videos del fenómeno. Es recomendable llevar a cabo esta evaluación con el sistema basado en dos cámaras que enfoquen la misma área geográfica tal como se indicó en el Capítulo 4. Una de ellas conectada a la plataforma de procesamiento destinada al proceso de detección, la otra orientada a grabar y almacenar el video a alta velocidad una vez el sistema de detección de la descarga le provea un disparo de inicio de este proceso.

Se ha enunciado que la configuración y las características de las cámaras utilizadas en el proceso de adquisición visual de algunos videos de descargas fueron desconocidas. Sin embargo, las técnicas de detección suministraron un mejor desempeño en cuadros con fondos uniformes y tenues. Por tanto, en un proceso de detección en tiempo real de descargas es recomendable configurar la cámara de sensado con el objeto de adquirir la información visual a baja iluminación.

Esta investigación puede ser utilizada como base en el desarrollo de futuros trabajos que estén encaminados en la consecución de una nueva técnica de detección de descargas con el propósito de ser utilizada ya sea como herramienta de validación y evaluación en la calidad y eficiencia en la detección por parte de las redes de localización de descargas, o de ser incluida en las actuales redes permitiendo mejorar la precisión en el proceso de detección.

Adicionalmente, haciendo uso de los métodos de detección de descargas presentados en este documento en adición con técnicas de procesamiento de imágenes enfocadas en aplicaciones de triangulación, visión estereoscópica o similares, se podrían desarrollar investigaciones orientadas a estimar la ubicación geográfica de los puntos de impacto de las descargas.

Respecto a las características que provee el análisis de imágenes de descargas, este trabajo se enfocó únicamente en establecer el número de descargas subsecuentes presentes en el canal de la descarga. Investigaciones posteriores podrían estar orientadas en utilizar las técnicas de procesamiento presentadas con el fin de adecuar un algoritmo computacional que provea otras características como lo son el tiempo de duración de la corriente en la etapa inicial de la descarga, el intervalo de tiempo entre descargas subsecuentes, la velocidad promedio de propagación, el tiempo que perduran las corrientes en descargas subsecuentes, el intervalo de tiempo entre descargas, el tiempo total de la descarga y el número de impactos a tierra de las descargas.

# <span id="page-122-0"></span>**A. Anexo: Histogramas de imágenes en escala de grises correspondientes a videos de descargas**

En este anexo se muestran cuadros en escala de grises de videos de descargas con sus respectivos histogramas en los instantes antes y durante el suceso del evento, etiquetados como casos (a), (b), (c) y (d). Los ejemplos gráficos descritos a continuación proveen soporte en el desarrollo de la sección 2.1.1 Niveles de intensidad en imágenes de descargas. Todas las imágenes fueron obtenidas mediante código implementado en Python.

Figura A-1

![](_page_122_Figure_3.jpeg)

Figura A-2

![](_page_123_Figure_3.jpeg)

Figura A-3

![](_page_123_Figure_5.jpeg)

Figura A-4

![](_page_124_Figure_3.jpeg)

Figura A-5

![](_page_124_Figure_5.jpeg)

# <span id="page-126-0"></span>**B. Anexo: Conversión a espacios de color de imágenes asociadas a videos de descargas**

En este anexo se muestran cuadros de videos de descargas convertidos a componentes de color a fin de establecer los canales de color que provean mayor sensibilidad ante el suceso del fenómeno. Los ejemplos gráficos descritos a continuación proveen soporte en el desarrollo de la sección 2.1.2 Análisis del espacio de color en imágenes de descargas. Todas las imágenes fueron obtenidas mediante código implementado en Python.

Figura B-1

![](_page_126_Picture_3.jpeg)

Figura B-2

![](_page_126_Picture_5.jpeg)

Figura B-3

![](_page_127_Picture_3.jpeg)

Figura B-4

![](_page_127_Picture_5.jpeg)

Figura B-5

![](_page_127_Picture_7.jpeg)

La Tabla B-1 indica las etiquetas respecto a los canales de color utilizados en este proceso.

Tabla B-1

| Caso | Imagen                          | Caso | Imagen                         |
|------|---------------------------------|------|--------------------------------|
| (a)  | Modelo de color RGB             | (b)  | Segmentada manualmente         |
| (c)  | Escala de grises                | (d)  | Componente rojo -<br>color RGB |
| (e)  | Componente verde -<br>color RGB | (f)  | Componente azul -<br>color RGB |
| (g)  | Modelo de color XYZ             | (h)  | Componente X -<br>color XYZ    |
| (i)  | Componente Y -<br>color XYZ     | (j)  | Componente Z -<br>color XYZ    |
| (k)  | Modelo de color YCbCr           | (l)  | Componente Y -<br>color YCbCr  |

Tabla B-1 (Continuación)

| Caso | Imagen                         | Caso | Imagen                         |
|------|--------------------------------|------|--------------------------------|
| (m)  | Componente Cb -<br>color YCbCr | (n)  | Componente Cr -<br>color YCbCr |
| (o)  | Modelo de color HSV            | (p)  | Componente H -<br>color HSV    |
| (q)  | Componente S -<br>color HSV    | (r)  | Componente V -<br>color HSV    |
| (s)  | Modelo de color HLS            | (t)  | Componente H -<br>color HLS    |
| (u)  | Componente L -<br>color HLS    | (v)  | Componente S -<br>color HLS    |
| (w)  | Modelo de color Lab            | (x)  | Componente L -<br>color Lab    |
| (y)  | Componente a -<br>color Lab    | (z)  | Componente b -<br>color Lab    |
| (aa) | Modelo de color Luv            | (ab) | Componente L -<br>color Luv    |
| (ac) | Componente u -<br>color Luv    | (ad) | Componente v -<br>color Luv    |

# <span id="page-130-0"></span>**C. Anexo: Histogramas de imágenes en componentes de color seleccionados en videos de descargas**

En este anexo se muestran cuadros de videos de descargas y los histogramas relacionados a los canales de color seleccionados en los instantes antes y durante el suceso del evento. Los ejemplos gráficos descritos a continuación proveen soporte en el desarrollo de la sección 2.1.2 Análisis del espacio de color en imágenes de descargas. Todas las imágenes fueron obtenidas mediante código implementado en Python.

Figura C-1

![](_page_130_Figure_3.jpeg)

Figura C-2

![](_page_131_Figure_3.jpeg)

Figura C-3

![](_page_131_Figure_5.jpeg)

Figura C-4

![](_page_132_Figure_3.jpeg)

Figura C-5

![](_page_132_Figure_5.jpeg)

La Tabla C-1 indica los rótulos utilizados en cada histograma.

Tabla C-1

| Rótulo | Canal de color                  | Rótulo  | Canal de color                 |
|--------|---------------------------------|---------|--------------------------------|
| gris   | Escala de grises                | rojo    | Componente rojo -<br>color RGB |
| verde  | Componente verde -<br>color RGB | azul    | Componente azul -<br>color RGB |
| X      | Componente X -<br>color XYZ     | Y_XYZ   | Componente Y -<br>color XYZ    |
| Z      | Componente Z -<br>color XYZ     | Y_YCbCr | Componente Y -<br>color YCbCr  |
| valor  | Componente V -<br>color HSV     | L_HLS   | Componente L -<br>color HLS    |
| L_Lab  | Componente L -<br>color Lab     | L_Luv   | Componente L -<br>color Luv    |

# <span id="page-134-0"></span>**D. Anexo: Histogramas de imágenes en canal de color en escala de grises y componente Z**

En este anexo se muestran cuadros de videos de descargas y los histogramas relacionados al canal de color en escala de grises y componente Z en el rango de niveles de intensidad 200 – 255 en los instantes antes y durante el suceso del evento. Los ejemplos gráficos descritos a continuación proveen soporte en el desarrollo de la sección 2.1.2 Análisis del espacio de color en imágenes de descargas. Todas las imágenes fueron obtenidas mediante código implementado en Python.

Figura D-1

![](_page_134_Figure_3.jpeg)

Figura D-2

![](_page_135_Figure_3.jpeg)

Figura D-3

![](_page_135_Figure_5.jpeg)

Figura D-4

![](_page_136_Figure_3.jpeg)

Figura D-5

![](_page_136_Figure_5.jpeg)

- <span id="page-138-0"></span>[1] M. A. Uman, *The lightning discharge*, vol. 39. 1987.
- [2] H. H. Goh *et al.*, "A review of lightning protection system Risk assessment and application," *Indones. J. Electr. Eng. Comput. Sci.*, vol. 8, no. 1, pp. 221–229, 2017, doi: 10.11591/ijeecs.v8.i1.pp221-229.
- [3] E. Krausmann, E. Renni, M. Campedel, and V. Cozzani, "Industrial accidents triggered by earthquakes, floods and lightning: Lessons learned from a database analysis," *Nat. Hazards*, vol. 59, no. 1, pp. 285–300, 2011, doi: 10.1007/s11069-011-9754-3.
- [4] E. Renni, E. Krausmann, and V. Cozzani, "Industrial accidents triggered by lightning," *J. Hazard. Mater.*, vol. 184, no. 1–3, pp. 42–48, 2010, doi: 10.1016/j.jhazmat.2010.07.118.
- [5] D. M. Elsom, "Factors contributing to a long-term decrease in national lightning fatality rates: case study of the United Kingdom with wider implications," *Int. J. Disaster Risk Reduct.*, vol. 31, pp. 341–353, 2018, doi: 10.1016/j.ijdrr.2018.06.001.
- [6] R. L. Holle, "A summary of recent national-Scale lightning fatality studies," *Weather. Clim. Soc.*, vol. 8, no. 1, pp. 35–42, 2016, doi: 10.1175/WCAS-D-15-0032.1.
- [7] A. E. Ritenour, M. J. Morton, J. G. McManus, D. J. Barillo, and L. C. Cancio, "Lightning injury: A review," *Burns*, vol. 34, no. 5, pp. 585–594, 2008, doi: 10.1016/j.burns.2007.11.006.
- [8] A. Necci, G. Antonioni, V. Cozzani, E. Krausmann, A. Borghetti, and C. Alberto Nucci, "A model for process equipment damage probability assessment due to lightning," *Reliab. Eng. Syst. Saf.*, vol. 115, pp. 91–99, 2013, doi: 10.1016/j.ress.2013.02.018.
- [9] Y. Yasuda, S. Yokoyama, M. Minowa, and T. Satoh, "Classification of lightning damage to wind turbine blades," *IEEJ Trans. Electr. Electron. Eng.*, vol. 7, no. 6, pp. 559–566, 2012, doi: 10.1002/tee.21773.
- [10] M. Gagné and D. Therriault, "Lightning strike protection of composites," *Prog. Aerosp. Sci.*, vol. 64, pp. 1–16, 2014, doi: 10.1016/j.paerosci.2013.07.002.
- [11] J. E. Jerauld, M. A. Uman, V. A. Rakov, K. J. Rambo, D. M. Jordan, and G. H. Schnetzer, "Measured electric and magnetic fields from an unusual cloud-to-ground lightning flash containing two positive strokes followed by four negative strokes," *J. Geophys. Res. Atmos.*, vol. 114, no. D19, 2009, doi: 10.1029/2008jd011660.

- [12] M. M. F. Saba, C. Schumann, T. A. Warner, J. H. Helsdon Jr., W. Schulz, and R. E. Orville, "Bipolar cloud-to-ground lightning flash observations," *J. Geophys. Res. Atmos.*, vol. 118, no. 19, pp. 11,098-11,106, 2013, doi: 10.1002/jgrd.50804.
- [13] Y. Tian *et al.*, "Characteristics of a bipolar cloud-to-ground lightning flash containing a positive stroke followed by three negative strokes," *Atmos. Res.*, vol. 176–177, pp. 222–230, 2016, doi: 10.1016/j.atmosres.2016.02.023.
- [14] M. D. Tran and V. A. Rakov, "Initiation and propagation of cloud-to-ground lightning observed with a high-speed video camera," *Sci. Rep.*, vol. 6, no. 39521, 2016, doi: 10.1038/srep39521.
- [15] M. M. F. Saba *et al.*, "Upward lightning flashes characteristics from highspeed videos," *J. Geophys. Res. Atmos.*, vol. 121, no. 14, pp. 8493–8505, 2016, doi: 10.1002/2016JD025137.
- [16] J. Herrera, C. Younes, and L. Porras, "Cloud-to-ground lightning activity in Colombia: A 14-year study using lightning location system data," *Atmos. Res.*, vol. 203, pp. 164–174, 2018, doi: 10.1016/j.atmosres.2017.12.009.
- [17] G. Diendorfer *et al.*, "Review of CIGRE Report 'Cloud-to-Ground Lightning Parameters Derived from Lightning Location Systems – The Effects of System Performance,'" *Cigre*, no. 376, 2009.
- [18] M. M. F. Saba *et al.*, "High-speed video observations of positive lightning flashes to ground," *J. Geophys. Res. Atmos.*, vol. 115, no. D24, 2010, doi: 10.1029/2010JD014330.
- [19] A. M. Hussein, S. Kazazi, M. Anwar, M. Yusouf, and P. Liatos, "Characteristics of the most intense lightning storm ever recorded at the CN Tower," *J. Atmos. Solar-Terrestrial Phys.*, vol. 154, pp. 195–206, 2017, doi: 10.1016/j.jastp.2016.05.002.
- [20] A. C. V. Saraiva, M. M. F. Saba, O. Pinto Jr., K. L. Cummins, E. P. Krider, and L. Z. S. Campos, "A comparative study of negative cloud-to-ground lightning characteristics in São Paulo (Brazil) and Arizona (United States) based on high-speed video observations," *J. Geophys. Res. Atmos.*, vol. 115, no. D11, 2010, doi: 10.1029/2009JD012604.
- [21] L. S. Antunes *et al.*, "Day-to-day differences in the characterization of lightning observed by multiple high-speed cameras," *Electr. Power Syst. Res.*, vol. 118, pp. 93–100, 2015, doi: 10.1016/j.epsr.2014.07.030.
- [22] Y. Zhang, W. Lu, J. Li, W. Dong, D. Zheng, and S. Chen, "Luminosity characteristics of leaders in natural cloud-to-ground lightning flashes," *Atmos. Res.*, vol. 91, no. 2–4, pp. 326–332, 2009, doi: 10.1016/j.atmosres.2008.01.013.
- [23] M. M. F. Saba, C. Schumann, T. A. Warner, J. H. Helsdon, and R. E. Orville, "High-speed video and electric field observation of a negative upward leader connecting a downward positive leader in a positive cloud-to-ground flash," *Electr. Power Syst. Res.*, vol. 118, pp. 89–92, 2015, doi: 10.1016/j.epsr.2014.06.002.
- [24] L. Z. S. Campos, M. M. F. Saba, O. Pinto Jr., and M. G. Ballarotti,

"Waveshapes of continuing currents and properties of M-components in natural negative cloud-to-ground lightning from high-speed video observations," *Atmos. Res.*, vol. 84, no. 4, pp. 302–310, 2007, doi: 10.1016/j.atmosres.2006.09.002.

- [25] C. J. Biagi, K. L. Cummins, K. E. Kehoe, and E. P. Krider, "National Lightning Detection Network (NLDN) performance in southern Arizona, Texas, and Oklahoma in 2003-2004," *J. Geophys. Res. Atmos.*, vol. 112, no. 5, pp. 1–17, 2007, doi: 10.1029/2006JD007341.
- [26] O. Pinto, I. R. C. A. Pinto, and K. P. Naccarato, "Geographical variations of negative cloud-to-ground lightning parameters: A review," *2012 31st Int. Conf. Light. Prot. ICLP 2012*, 2012, doi: 10.1109/ICLP.2012.6344292.
- [27] D. De Jesus Perez-Perez, J. G. Herrera-Murcia, and E. Perez-Gonzalez, "Experimental detection efficiency evaluation for a lightning location system on a mountainous region," *2013 Int. Symp. Light. Prot. SIPDA 2013*, pp. 73– 78, 2013, doi: 10.1109/SIPDA.2013.6729235.
- [28] N. Shimoji, S. Kuninaka, and K. Izumi, "Evaluation of the brightness of lightning channels and branches using the magnitude system: Application of astronomical photometry," *Results Phys.*, vol. 7, pp. 2085–2095, 2017, doi: 10.1016/j.rinp.2017.06.013.
- [29] K. Berger, "Blitzstrom-Parameter von Aufwartsblitzen," *Bull. Schweiz. Elektrotech*, vol. 69, pp. 353–360, 1978.
- [30] S. P. A. Vayanganie, M. Fernando, U. Sonnadara, V. Cooray, and C. Perera, "Optical observations of electrical activity in cloud discharges," *J. Atmos. Solar-Terrestrial Phys.*, vol. 172, pp. 24–32, 2018, doi: 10.1016/j.jastp.2018.03.007.
- [31] M. Boecker, G. Corpuz, G. Hargrave, S. Das, N. Fischer, and V. Skendzic, "Line current differential relay response to a direct lightning strike on a phase conductor," *71st Annu. Conf. Prot. Relay Eng. CPRE 2018*, vol. 2018- Janua, pp. 1–12, 2018, doi: 10.1109/CPRE.2018.8349805.
- [32] Nasa, "Where Lightning Strikes," 2001. https://science.nasa.gov/sciencenews/science-at-nasa/2001/ast05dec\_1.
- [33] Lightning Protection Devices SA, "Características principales del proceso de descarga de un rayo." https://www.lpdargentina.com.ar/caracteristicasprincipales-del-proceso-de-descarga-de-un-rayo/.
- [34] J. L. Bermudez Arboleda, "Lightning Currents and Electromagnetic Fields Associated With Return Strokes To Elevated Strike Objects," vol. 2741, p. 178, 2003.
- [35] A. C. V. Saraiva *et al.*, "High-speed video and electromagnetic analysis of two natural bipolar cloud-to-ground lightning flashes," *J. Geophys. Res. Atmos.*, vol. 119, no. 10, pp. 6105–6127, 2014, doi: 10.1002/2013JD020974.
- [36] M. Azadifar, F. Rachidi, M. Rubinstein, V. A. Rakov, M. Paolone, and D. Pavanello, "Bipolar lightning flashes observed at the säntis tower: Do we need to modify the traditional classification?," *J. Geophys. Res.*, vol. 121,

- no. 23, pp. 14,117-14,126, 2016, doi: 10.1002/2016JD025461.
- [37] Y. Zhu, V. A. Rakov, and M. D. Tran, "Optical and electric field signatures of lightning interaction with a 257-m tall tower in Florida," *Electr. Power Syst. Res.*, vol. 153, pp. 128–137, 2017, doi: 10.1016/j.epsr.2016.08.036.
- [38] B. Wu *et al.*, "Synchronized Two-Station Optical and Electric Field Observations of Multiple Upward Lightning Flashes Triggered by a 310-kA +CG Flash," *J. Geophys. Res. Atmos.*, vol. 124, no. 2, pp. 1050–1063, 2019, doi: 10.1029/2018JD029378.
- [39] X. Kong, Y. Zhao, T. Zhang, and H. Wang, "Optical and electrical characteristics of in-cloud discharge activity and downward leaders in positive cloud-to-ground lightning flashes," *Atmos. Res.*, vol. 160, pp. 28–38, 2015, doi: 10.1016/j.atmosres.2015.02.014.
- [40] A. F. R. Leal, G. A. V. S. Ferreira, A. M. Morais, and A. R. A. Manito, "Automated low-cost setup for optical and E-field records of lightning," *J. Atmos. Solar-Terrestrial Phys.*, vol. 214, no. January, p. 105552, 2021, doi: 10.1016/j.jastp.2021.105552.
- [41] M. Arcanjo, M. Guimarães, and S. Visacro, "On the interpeak interval of unipolar pulses of current preceding the return stroke in negative CG lightning," *Electr. Power Syst. Res.*, vol. 173, pp. 13–17, 2019, doi: 10.1016/j.epsr.2019.03.028.
- [42] B. Fan, P. Yuan, X. Wang, Y. Zhao, J. Cen, and Y. Su, "Development characteristics of cloud-to-ground lightning with multiple grounding points," *Sci. China Earth Sci.*, vol. 61, no. 8, pp. 1127–1135, 2018, doi: 10.1007/s11430-017-9204-4.
- [43] C. Wang, Z. Sun, R. Jiang, Y. Tian, and X. Qie, "Characteristics of downward leaders in a cloud-to-ground lightning strike on a lightning rod," *Atmos. Res.*, vol. 203, pp. 246–253, 2018, doi: 10.1016/j.atmosres.2017.12.014.
- [44] Y. Li, S. Qiu, L. Shi, Z. Huang, T. Wang, and Y. Duan, "Three-Dimensional Reconstruction of Cloud-to-Ground Lightning Using High-Speed Video and VHF Broadband Interferometer," *J. Geophys. Res. Atmos.*, vol. 122, no. 24, pp. 13,420-13,435, 2017, doi: 10.1002/2017JD027214.
- [45] S. Visacro, M. Guimaraes, and M. H. Murta Vale, "Striking Distance Determined From High-Speed Videos and Measured Currents in Negative Cloud-to-Ground Lightning," *J. Geophys. Res. Atmos.*, vol. 122, no. 24, pp. 13,356-13,369, 2017, doi: 10.1002/2017JD027354.
- [46] M. M. F. Saba *et al.*, "Lightning attachment process to common buildings," *Geophys. Res. Lett.*, vol. 44, no. 9, pp. 4368–4375, 2017, doi: 10.1002/2017GL072796.
- [47] M. D. Tran and V. A. Rakov, "When does the lightning attachment process actually begin?," *J. Geophys. Res. Atmos.*, vol. 120, no. 14, pp. 6922–6936, 2015, doi: 10.1002/2015JD023155.
- [48] Q. Qi, W. Lu, Y. Ma, L. Chen, Y. Zhang, and V. A. Rakov, "High-speed video observations of the fine structure of a natural negative stepped leader at close distance," *Atmos. Res.*, vol. 178–179, pp. 260–267, 2016, doi:

- 10.1016/j.atmosres.2016.03.027.
- [49] W. Lu *et al.*, "Three-dimensional propagation characteristics of the leaders in the attachment process of a downward negative lightning flash," *J. Atmos. Solar-Terrestrial Phys.*, vol. 136, pp. 23–30, 2015, doi: 10.1016/j.jastp.2015.07.011.
- [50] H. Zhang *et al.*, "Single-Station-Based Lightning Mapping System with Electromagnetic and Thunder Signals," *IEEE Trans. Plasma Sci.*, vol. 47, no. 2, pp. 1421–1428, 2019, doi: 10.1109/TPS.2019.2891087.
- [51] C. Schumann *et al.*, "On the Triggering Mechanisms of Upward Lightning," *Sci. Rep.*, vol. 9, no. 9576, 2019, doi: 10.1038/s41598-019-46122-x.
- [52] H. Huang, D. Wang, T. Wu, and N. Takagi, "Formation Features of Steps and Branches of an Upward Negative Leader," *J. Geophys. Res. Atmos.*, vol. 123, no. 22, pp. 12,597-12,605, 2018, doi: 10.1029/2018JD028979.
- [53] S. Visacro, M. Guimaraes, and M. H. Murta Vale, "Features of upward positive leaders initiated from towers in natural cloud-to-ground lightning based on simultaneous high-speed videos, measured currents, and electric fields," *J. Geophys. Res. Atmos.*, vol. 122, no. 23, pp. 12,786-12,800, 2017, doi: 10.1002/2017JD027016.
- [54] S. Yuan, R. Jiang, X. Qie, D. Wang, Z. Sun, and M. Liu, "Characteristics of Upward Lightning on the Beijing 325 m Meteorology Tower and Corresponding Thunderstorm Conditions," *J. Geophys. Res. Atmos.*, vol. 122, no. 22, pp. 12,093-12,105, 2017, doi: 10.1002/2017JD027198.
- [55] D. R. Poelman *et al.*, "Global ground strike point characteristics in negative downward lightning flashes-Part 1: Observations," *Nat. Hazards Earth Syst. Sci.*, vol. 21, no. 6, pp. 1909–1919, 2021, doi: 10.5194/nhess-21-1909-2021.
- [56] F. H. Heidler and C. Paul, "High-Speed Video Observation, Currents, and EM-Fields From Four Negative Upward Lightning to the Peissenberg Tower, Germany," *IEEE Trans. Electromagn. Compat.*, pp. 18–25, 2020, doi: 10.1109/TEMC.2020.3032781.
- [57] L. Schwalt, S. Pack, and W. Schulz, "Ground truth data of atmospheric discharges in correlation with LLS detections," *Electr. Power Syst. Res.*, vol. 180, no. March 2019, 2020, doi: 10.1016/j.epsr.2019.106065.
- [58] M. Stolzenburg, T. C. Marshall, S. Karunarathne, N. Karunarathna, and R. E. Orville, "Leader observations during the initial breakdown stage of a lightning flash," *J. Geophys. Res. Atmos.*, vol. 119, no. 21, pp. 12,198- 12,221, Feb. 2014, doi: 10.1002/2014JD021994.
- [59] S. Karunarathne, T. C. Marshall, M. Stolzenburg, N. Karunarathna, and R. E. Orville, "Modeling stepped leaders using a time-dependent multidipole model and high-speed video data," *J. Geophys. Res. Atmos.*, vol. 120, no. 6, pp. 2419–2436, 2015, doi: 10.1002/2014JD022679.
- [60] M. D. Tran and V. A. Rakov, "A study of the ground-attachment process in natural lightning with emphasis on its breakthrough phase," *Sci. Rep.*, vol. 7, no. 15761, 2017, doi: 10.1038/s41598-017-14842-7.
- [61] R. Jiang, Z. Wu, X. Qie, D. Wang, and M. Liu, "High-speed video evidence

- of a dart leader with bidirectional development," *Geophys. Res. Lett.*, vol. 41, no. 14, pp. 5246–5250, 2014, doi: 10.1002/2014GL060585.
- [62] W. R. Gamerota, V. P. Idone, M. A. Uman, T. Ngin, J. T. Pilkey, and D. M. Jordan, "Dart-stepped-leader step formation in triggered lightning," *Geophys. Res. Lett.*, vol. 41, no. 6, pp. 2204–2211, 2014, doi: 10.1002/2014GL059627.
- [63] L. Z. S. Campos and M. M. F. Saba, "Visible channel development during the initial breakdown of a natural negative cloud-to-ground flash," *Geophys. Res. Lett.*, vol. 40, no. 17, pp. 4756–4761, 2013, doi: 10.1002/grl.50904.
- [64] X. Wang *et al.*, "Comparisons of optical characteristics of two upward lightning flashes triggered by a nearby positive cloud-to-ground lightning," *J. Atmos. Solar-Terrestrial Phys.*, vol. 198, no. October 2019, 2020, doi: 10.1016/j.jastp.2020.105193.
- [65] A. Srivastava *et al.*, "Intermittent Propagation of Upward Positive Leader Connecting a Downward Negative Leader in a Negative Cloud-to-Ground Lightning," *J. Geophys. Res. Atmos.*, vol. 124, no. 24, pp. 13763–13776, 2019, doi: 10.1029/2019JD031148.
- [66] Q. Qi *et al.*, "High-Speed Video Observations of Natural Lightning Attachment Process With Framing Rates up to Half a Million Frames per Second," *Geophys. Res. Lett.*, vol. 46, no. 21, pp. 12580–12587, 2019, doi: 10.1029/2019GL085072.
- [67] M. Stolzenburg, T. C. Marshall, S. Karunarathne, N. Karunarathna, T. A. Warner, and R. E. Orville, "Stepped-to-dart leaders preceding lightning return strokes," *J. Geophys. Res. Atmos.*, vol. 118, no. 17, pp. 9845–9869, 2013, doi: 10.1002/jgrd.50706.
- [68] M. Stolzenburg, T. C. Marshall, and S. Karunarathne, "On the Transition From Initial Leader to Stepped Leader in Negative Cloud-to-Ground Lightning," *J. Geophys. Res. Atmos.*, vol. 125, no. 4, pp. 0–2, 2020, doi: 10.1029/2019JD031765.
- [69] X. Wang, X. Zhao, H. Cai, G. Liu, M. Liao, and L. Qu, "Optical characteristics of branched downward positive leader associated with recoil leader activity," *J. Atmos. Solar-Terrestrial Phys.*, vol. 196, 2019, doi: 10.1016/j.jastp.2019.105158.
- [70] J. D. Hill *et al.*, "The attachment process of rocket-triggered lightning dartstepped leaders," *J. Geophys. Res. Atmos.*, vol. 121, no. 2, pp. 853–871, 2016, doi: 10.1002/2015JD024269.
- [71] M. Stolzenburg, T. C. Marshall, S. Bandara, B. Hurley, and R. Siedlecki, "Ultra-high speed video observations of intracloud lightning flash initiation," *Meteorol. Atmos. Phys.*, no. 2013, 2021, doi: 10.1007/s00703-021-00803-3.
- [72] Y. Zhang, Y. Zhang, C. Li, W. Lu, and D. Zheng, "Simultaneous optical and electrical observations of 'chaotic' leaders preceding subsequent return strokes," *Atmos. Res.*, vol. 170, pp. 131–139, 2016, doi: 10.1016/j.atmosres.2015.11.012.
- [73] R. Jiang *et al.*, "Characteristics of lightning leader propagation and ground attachment," *J. Geophys. Res. Atmos.*, vol. 120, no. 23, pp. 11,988-12,002,

- 2015, doi: 10.1002/2015JD023519.
- [74] L. Schwalt, S. Pack, W. Schulz, and G. Pistotnik, "Percentage of singlestroke flashes related to different thunderstorm types," *Electr. Power Syst. Res.*, vol. 194, no. January, p. 107109, 2021, doi: 10.1016/j.epsr.2021.107109.
- [75] W. Schulz, G. Diendorfer, S. Pedeboy, and D. Roel Poelman, "The European lightning location system EUCLID - Part 1: Performance analysis and validation," *Nat. Hazards Earth Syst. Sci.*, vol. 16, no. 2, pp. 595–605, 2016, doi: 10.5194/nhess-16-595-2016.
- [76] M. D. Tran and V. A. Rakov, "Attachment process in subsequent strokes and residual channel luminosity between strokes of natural lightning," *J. Geophys. Res.*, vol. 120, no. 23, pp. 12,248-12,258, 2015, doi: 10.1002/2015JD024032.
- [77] M. Guimaraes, M. Arcanjo, M. H. Murta Vale, and S. Visacro, "Unusual features of negative leaders' development in natural lightning, according to simultaneous records of current, electric field, luminosity, and high-speed video," *J. Geophys. Res. Atmos.*, vol. 122, no. 4, pp. 2325–2333, 2017, doi: 10.1002/2016JD025891.
- [78] M. Stolzenburg, T. C. Marshall, S. Karunarathne, and R. E. Orville, "Length estimations of presumed upward connecting leaders in lightning flashes to flat water and flat ground," *Atmos. Res.*, vol. 211, pp. 85–94, 2018, doi: 10.1016/j.atmosres.2018.04.020.
- [79] X. Wang *et al.*, "High-speed video observations of branching behaviors in downward stepped leaders and upward connecting leaders in negative natural lightning," *J. Atmos. Solar-Terrestrial Phys.*, vol. 183, pp. 61–66, 2019, doi: 10.1016/j.jastp.2018.12.010.
- [80] M. Stolzenburg, T. C. Marshall, S. Karunarathne, N. Karunarathna, and R. E. Orville, "Branched dart leaders preceding lightning return strokes," *J. Geophys. Res. Atmos.*, vol. 119, no. 7, pp. 4228–4252, 2014, doi: 10.1002/2013JD021254.
- [81] L. Huang *et al.*, "Correlation of Charge Distribution among Different Branches in a Natural Lightning Flash," *IEEE Access*, vol. 6, pp. 42829– 42836, 2018, doi: 10.1109/ACCESS.2018.2859399.
- [82] D. A. Kotovsky, M. A. Uman, R. A. Wilkes, and D. M. Jordan, "High-Speed Video and Lightning Mapping Array Observations of In-Cloud Lightning Leaders and an M Component to Ground," *J. Geophys. Res. Atmos.*, vol. 124, no. 3, pp. 1496–1513, 2019, doi: 10.1029/2018JD029506.
- [83] Y. Zhang, Y. Zhang, D. Zheng, and W. Lu, "Characteristics and Discharge Processes of M Events with Large Current in Triggered Lightning," *Radio Sci.*, vol. 53, no. 8, pp. 974–985, 2018, doi: 10.1029/2018RS006552.
- [84] M. Stolzenburg, T. C. Marshall, S. Karunarathne, N. Karunarathna, and R. E. Orville, "An M component with a concurrent dart leader traveling along different paths during a lightning flash," *J. Geophys. Res. Atmos.*, vol. 120, no. 19, pp. 10,267-10,284, 2015, doi: 10.1002/2015JD023417.

- [85] J. Montanyà, O. van der Velde, and E. R. Williams, "The start of lightning: Evidence of bidirectional lightning initiation," *Sci. Rep.*, vol. 5, no. 15180, 2015, doi: 10.1038/srep15180.
- [86] N. Shimoji and Y. Uehara, "Color analysis of lightning leaders: Application of astronomical photometry," *AIP Conf. Proc.*, vol. 1906, 2017, doi: 10.1063/1.5012310.
- [87] A. Sasithradevi, S. Mohamed Mansoor Roomi, and M. Mareeswari, "A vision based method for detecting lightning in surveillance videos," *Proc. IEEE Int. Conf. Emerg. Technol. Trends Comput. Commun. Electr. Eng. ICETT 2016*, pp. 0–4, 2017, doi: 10.1109/ICETT.2016.7873685.
- [88] S. H. Mun *et al.*, "Performance Analysis of Real Time Image Processing for Lightning Event Using Cython and Python Programming Languages," *IOP Conf. Ser. Earth Environ. Sci.*, vol. 228, no. 1, 2019, doi: 10.1088/1755- 1315/228/1/012009.
- [89] Y. C. J. Liu, K. J. Nixon, and I. R. Jandrell, "A method to determine the lightning termination points using digital images," *2011 7th Asia-Pacific Int. Conf. Light. APL2011*, pp. 828–832, 2011, doi: 10.1109/APL.2011.6110242.
- [90] R. Gin, R. Bianchi, and B. Pilon, "A computer vision system to analyse images of lightning flashes," in *Seventh Conference on Artificial Intelligence and its Applications to the Environmental Sciences*, 2009, pp. 1–4.
- [91] J. R. Smit, H. G. P. Huntt, T. Cross, C. Schumann, and T. A. Warner, "Generation of metrics by semantic segmentation of high speed lightning footage using machine learning," *2020 Int. SAUPEC/RobMech/PRASA Conf. SAUPEC/RobMech/PRASA 2020*, 2020, doi: 10.1109/SAUPEC/RobMech/PRASA48453.2020.9041123.
- [92] MathWorks, "Image Processing Toolbox," 2021. https://la.mathworks.com/products/image.html.
- [93] MathWorks, "Matlab," 2021. https://la.mathworks.com/.
- [94] J. B., "Close Lightning Strike Compilation," 2021. https://www.youtube.com/watch?v=YJubbxyhvtY.
- [95] Pexels, "Las mejores fotos y vídeos de stock compartidos por talentosos creadores," 2021. https://www.pexels.com/es-es/.
- [96] Pixabay, "Increíbles imágenes gratis para descargar," 2021. https://pixabay.com/es/.
- [97] Videvo, "Free Stock Video Footage," 2021. https://www.videvo.net/.
- [98] Python, "Python 3.8.0," 2019. https://www.python.org/downloads/release/python-380/.
- [99] OpenCV, "OpenCV 4.4.0," 2020. https://opencv.org/opencv-4-4-0/.
- [100] OpenCV, "Color conversions," 2021. https://docs.opencv.org/4.4.0/de/d25/imgproc\_color\_conversions.html.
- [101] OpenCV, "Sobel Derivatives," 2021. https://docs.opencv.org/4.4.0/d2/d2c/tutorial\_sobel\_derivatives.html.
- [102] OpenCV, "Laplace Operator," 2021. https://docs.opencv.org/4.4.0/d5/db5/tutorial\_laplace\_operator.html.
- [103] OpenCV, "Canny Edge Detector," 2021.

- https://docs.opencv.org/4.4.0/da/d5c/tutorial\_canny\_detector.html.
- [104] R. C. Gonzalez and R. E. Woods, *Digital Image Processing*, Third Edit. Pearson Prentice Hall, 2008.
- [105] OpenCV, "Basic Thresholding Operations," 2021. https://docs.opencv.org/4.4.0/db/d8e/tutorial\_threshold.html.
- [106] Y. Benezeth, P. M. Jodoin, B. Emile, H. Laurent, and C. Rosenberger, "Review and evaluation of commonly-implemented background subtraction algorithms," in *19th International Conference on Pattern Recognition*, 2008, pp. 2–5, doi: 10.1109/icpr.2008.4760998.
- [107] OpenCV, "How to Use Background Subtraction Methods," 2021. https://docs.opencv.org/4.4.0/d1/dc5/tutorial\_background\_subtraction.html.
- [108] A. Fernández Villán, *Mastering OpenCV 4 with Python: A Practical Guide Covering Topics from Image Processing, Augmented Reality to Deep Learning with OpenCV 4 and Python 3.7*, vol. 1. Birmingham: Packt Publishing Ltd., 2019.
- [109] OpenCV, "Finding contours in your image," 2021. https://docs.opencv.org/4.4.0/df/d0d/tutorial\_find\_contours.html.
- [110] A. Kowalczyk, *Support Vector Machines Succinctly*. Syncfusion, 2017.
- [111] Python, "CSV File Reading and Writing," 2021. https://docs.python.org/3/library/csv.html.
- [112] Scikit-learn, "C-Support Vector Classification," 2021. https://scikitlearn.org/stable/modules/generated/sklearn.svm.SVC.html.
- [113] Scikit-learn, "sklearn.metrics.precision\_recall\_fscore\_support," 2021. https://scikitlearn.org/stable/modules/generated/sklearn.metrics.precision\_recall\_fscore\_ support.html.
- [114] Joblib, "Joblib: running Python functions as pipeline jobs," 2021. https://joblib.readthedocs.io/en/latest/.
- [115] K. He, X. Zhang, S. Ren, and J. Sun, "Deep residual learning for image recognition," in *Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition*, 2016, vol. 2016-Decem, pp. 770– 778, doi: 10.1109/CVPR.2016.90.
- [116] M. Tan and Q. V Le, "EfficientNet: Rethinking model scaling for convolutional neural networks," in *36th International Conference on Machine Learning, ICML 2019*, 2019, vol. 2019-June, pp. 10691–10700.
- [117] TensorFlow, "Una plataforma de extremo a extremo de código abierto para el aprendizaje automático," 2021. https://www.tensorflow.org/.
- [118] Python, "Python Download the latest version," 2021. https://www.python.org/downloads/.
- [119] R. P. Foundation, "Raspberry Pi," 2021. https://www.raspberrypi.org/.
- [120] "Jetson Nano Developer Kit," 2021. https://developer.nvidia.com/embedded/jetson-nano-developer-kit.
- [121] Coral, "Build beneficial and privacy preserving AI," 2021. https://coral.ai/.
- [122] O. Pi, "What's Orange Pi Pc Plus?," 2021. http://www.orangepi.org/.

- [123] R. P. Foundation, "Raspberry Pi 3 Model B+." p. 5, [Online]. Available: https://static.raspberrypi.org/files/productbriefs/200206+Raspberry+Pi+3+Model+B+plus+Product+Brief+PRINT&DIGI TAL.pdf.
- [124] CNET, "Genius FaceCam 310 web camera Specs," 2021. https://www.cnet.com/products/genius-facecam-310-web-camera/.
- [125] R. P. Foundation, "Camera Module V2." https://www.raspberrypi.org/products/camera-module-v2/.
- [126] K. Technologies, "Chronos High-Speed Cameras User Manual Chronos 1.4 & Chronos 2.1-HD Software Version 0.5.1." [Online]. Available: https://www.krontech.ca/wp-content/uploads/2020/10/Chronos-1.4-2.1-HD-User-Manual-Full-version-Software-Version-0.5.1.pdf.