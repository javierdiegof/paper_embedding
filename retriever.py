import chromadb
from sentence_transformers import SentenceTransformer

# --- Configuration ---
DB_PATH = "paper_rag_db"
EMBED_MODEL_NAME = "all-mpnet-base-v2"
TOP_K = 3


def query_db(queries):
    print("--- Loading RAG System ---")

    # 1. Initialize Vector DB and Embedder
    chroma_client = chromadb.PersistentClient(path=DB_PATH)
    collection = chroma_client.get_collection(name="scientific_papers")
    embedder = SentenceTransformer(EMBED_MODEL_NAME)

    print(f"Loaded Collection with {collection.count()} chunks.\n")

    for i, user_query in enumerate(queries):
        print(f"ðŸ”Ž Query {i+1}: {user_query}")

        # 3. Embed Query
        query_embedding = embedder.encode(user_query).tolist()

        # 4. Retrieve
        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=TOP_K,
            include=["documents", "metadatas", "distances"],
        )

        # 5. Display Results
        best_doc = results["documents"][0][0]
        best_meta = results["metadatas"][0][0]
        score = results["distances"][0][0]

        print(f"   â–º Best Match Score (L2 Distance): {score:.4f}")
        print(f"   â–º Source Paper: {best_meta['source']}")

        # Show the Contextual Header (generated by Qwen/Llama)
        print(f"   â–º Context (LLM Generated):")
        print(f"     \"{best_meta['enriched_context']}\"")

        print(f"   â–º Snippet:")
        print(f'     "{best_doc[:300]}..."')  # Truncated for display

        # Show Citations Resolution
        print(f"   â–º Resolved Citations (Snowball targets):")
        citation_ids = eval(best_meta["citation_ids"])  # Stored as string list
        corpus_ids = eval(best_meta["citation_corpus_ids"])

        if citation_ids:
            for c_id, corp_id in zip(citation_ids, corpus_ids):
                print(f"     - PaperID: {c_id} | CorpusID: {corp_id}")
        else:
            print(f"     - No citations in this chunk.")

        print("-" * 60)
